{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c742819",
   "metadata": {},
   "source": [
    "# Лабораторная работа 3. Обучение без учителя\n",
    "\n",
    "Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете также должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n",
    "\n",
    "## Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 15 баллов. Сдавать задание после указанного срока сдачи нельзя. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму. Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, нам необходима ссылка на источник)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4267464f",
   "metadata": {},
   "source": [
    "## EM-алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec3aaa",
   "metadata": {},
   "source": [
    "### Краудсорсинг\n",
    "\n",
    "Разметка данных — одна из самых трудозатратных задач в машинном обучении. Краудсорсинг позволяет распределить эту задачу на тысячи исполнителей, каждый из которых подготавливает небольшую часть датасета (подробнее <a href=\"https://academy.yandex.ru/posts/chto-takoe-kraudsorsing-i-pochemu-emu-nuzhno-uchitsya\">тут</a>).\n",
    "\n",
    "Пользователи могут допускать ошибки при разметке, кроме того, среди пользователей могут быть боты. Если мы попросим разметить каждый объект только одного пользователя, то с большой вероятностью получим не достаточно качественную разметку. Обычно каждый объект размечают несколько пользователей.\n",
    "\n",
    "Результаты разметки нужно обработать. Самый простой метод *голос большинства*. Он заключается в том, что для каждого объекта нужно взять тот класс, который чаще всего ставили пользователи данному объекту. Это достаточно хороший метод, но он не учитывает различные особенности пользователей. Далее рассмотрим метод, который позволяет оценивать вероятность того, что разметчик ошибся.\n",
    "\n",
    "### Метод Дэвида-Скина (Dawid, Skene, 1979)\n",
    "\n",
    "Мы имеем в качестве данных $n_{ik}^u$ &mdash; количество раз, при которых разметчик $u \\in U$ поставил класс $k \\in K$ объекту $i \\in I$ (возможно, разметчик видел этот объект несколько раз). Обозначим $Y_{ik} = I\\{\\text{объект $i$ класса $k$}\\}$, это наши латентные величины. \n",
    "\n",
    "В качестве параметров имеем\n",
    "* $\\pi_{k\\ell}^u$ &mdash; вероятность того, что разметчик $u$ поставил класс $\\ell$ вместо правильного класса $k$. \n",
    "* $\\rho_k$ &mdash; вероятность класса $k$.\n",
    "\n",
    "Поймём, какой будет функция неполного правдоподобия в этой задаче. Прежде всего,\n",
    "\n",
    "$$p_{\\pi,p}(N, Y) = \\prod_{i\\in I}p(N_i, Y_i),$$\n",
    "\n",
    "Если $k$ - номер класса $i$-го объекта, то\n",
    "\n",
    "$$p(N_i, Y_i)=\\underbrace{p(\\text{объект $i$ класса $k$})}_{=\\rho_k}p(N_i\\mid\\text{объект $i$ класса $k$})$$\n",
    "\n",
    "(значения $Y_{it}$ однозначно определяются номером истинного класса, поэтому справа $Y_i$ пропадает). Далее, мы считаем, что разметчики действуют независимо, поэтому\n",
    "\n",
    "$$p(N_i\\mid\\text{объект $i$ класса $k$}) = \\prod_{u\\in U}p(N_i^u\\mid\\text{объект $i$ класса $k$}).$$\n",
    "\n",
    "Разберёмся с величиной $p(N_i^u\\mid\\text{объект $i$ класса $k$})$. Она отвечает за то, какие классы $u$-й разметчик ставил $i$-му объекту. Мы считаем, что встречи разметчика с объектом упорядочены по времени, тогда\n",
    "\n",
    "$$p(\\text{$u$-й разметчик отнёс $i$-й объект к классам $k'_1,\\ldots,k'_r$}\\mid\\text{объект $i$ класса $k$}) =$$\n",
    "\n",
    "$$=\\prod_{s}p(\\text{в $s$-ю встречу с $i$-м объектом $u$-й разметчик отнёс его к классу $k'_s$}\\mid\\text{объект $i$ класса $k$})$$\n",
    "\n",
    "Эту вероятность можно переписать в виде\n",
    "\n",
    "$$\\prod_{\\ell \\in K} \\left( \\pi_{k\\ell}^u \\right)^{n_{i\\ell}^u},$$\n",
    "\n",
    "а итоговое неполное правдоподобие предстаёт в виде\n",
    "\n",
    "$$p_{\\pi,p}(N, Y) = \\prod_{i\\in I}\\prod_{k \\in K} \\left( \\rho_k \\prod_{u\\in U} \\prod_{\\ell \\in K} \\left( \\pi_{k\\ell}^u \\right)^{n_{i\\ell}^u} \\right)^{Y_{ik}}$$\n",
    "\n",
    "Его нам нужно максимизировать по $\\pi$ и $\\rho$\n",
    "\n",
    "**Пояснение к формуле:** \n",
    "\n",
    "Вне больших скобок фиксируются объект и его класс, сама скобка возводится в степень 1, если рассматривается правильный класс объекта, и в степень 0 иначе. Внутри сначала записана вероятность того, что объект имеет данный класс, а затем &mdash; перебор по всем пользователям и всем классам, которые мог поставить данный пользователь. Наконец, записывается вероятность того, что пользователь нашему объекту поставил некоторый класс, которая возводится в степень того, сколько раз он поставил этот класс. Например, если пользователь видел изображение котика 5 раз, при этом 3 раза он сказал, что котик, а два раза &mdash; песик, то вероятность $\\pi_{cat,cat}^u$ для данного котика учтется 3 раза, а вероятность $\\pi_{cat,dog}^u$ &mdash; 2 раза."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb326b9",
   "metadata": {},
   "source": [
    "**Задание 1 (2 балл)**\n",
    "\n",
    "Распишите итерационную процедуру EM-алгоритма и значение ELBO в методе Дэвида-Скина."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473bb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DawidSkene:\n",
    "    def __init__(self, crowd_labels: pd.DataFrame):\n",
    "        self.crowd_labels = crowd_labels\n",
    "    \n",
    "    def initialize_params(self):\n",
    "        # your code here\n",
    "    \n",
    "    def predict(self):\n",
    "        # your code here\n",
    "        \n",
    "    def run(self, n_iter):\n",
    "        # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c0209d",
   "metadata": {},
   "source": [
    "**Задание 2 (3 балла)** \n",
    "\n",
    "Реализуйте следующие методы агрегации результатов разметки в краудсорсинге:\n",
    "\n",
    "* голосование по большинству;\n",
    "* метод Дэвида-Скина.\n",
    "\n",
    "Оба метода должны возвращать вероятность принадлежности объекта каждому из классов (итоговая метка получается выбором класса с наибольшей оценкой вероятности). \n",
    "\n",
    "Заметим, что метод голосования по большинству можно реализовать с помощью одной агрегирующей функцией `pandas.crosstab`, а метод Дэвида-Скина основывается на EM-алгоритме (при реализации стоит учесть, что EM-алгоритм сходится в локальные оптимумы, то есть его стоит запускать из разных начальных приближений).\n",
    "\n",
    "Примените эти два метода к датасетам *Toloka Aggregation Relevance 2* и *Toloka Aggregation Relevance 5*, которые можно скачать <a href=\"https://toloka.ai/ru/datasets\">тут</a>, и сравните их между собой. \n",
    "\n",
    "Обратите внимание, что в последнем датасете 5 различных меток, причем некоторые объекты в датасете имеют не один, а несколько правильных ответов. Любой из таких ответов считается правильным."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f2358e-3154-45c8-8879-a14475a82443",
   "metadata": {},
   "source": [
    "**В Я.Контест нужно загрузить только .csv файлы в следующем формате.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523abbfa-e72c-4af2-8fad-4811b58f82fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t100</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        prediction\n",
       "object            \n",
       "t0               1\n",
       "t1               1\n",
       "t10              1\n",
       "t100             0\n",
       "t1000            0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote_agg(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # your code here\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f5dce",
   "metadata": {},
   "source": [
    "**Задание 3 (1 балл)** \n",
    "\n",
    "Попробуйте в методе Дэвида-Скина в качестве начального приближения вероятностей классов для каждого объекта подавать те вероятности, которые посчитаны методом голосования по большинству, и провести сначала M-шаг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d566f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DawidSkeneWithMVInit(DawidSkene):\n",
    "    def initialize_params(self):\n",
    "        # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f9f9a8",
   "metadata": {},
   "source": [
    "Далее мы будем работать с таблицей `vacancies.csv` и нам нужно подготовить данные для работы, а именно сделайте следующее:\n",
    "    \n",
    "- Разбейте данные на обучающую выборку (строки, не содержащие метки кластеров) и тестовую (строки, содержащие метки кластеров)\n",
    "- Предобработайте текст, содержащийся в колонках *name* и *description* (уберите артефакты, нормализуйте и т.д.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784bbc1c",
   "metadata": {},
   "source": [
    "### Тематическое моделирование\n",
    "\n",
    "Тематическое моделирование заключается в поиске тем $T$, которые хорошо бы описывали документы $D$ со словарём $W$. Большинство тематических моделей оперирует данными в формате \"мешка слов\", т.е. учитывают только частоты слов в документах, а не их порядок. Одной из простейших тематических моделей является [PLSA](https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis), которая приводит к задаче стохастического матричного разложения: \n",
    "\n",
    "$$F \\approx \\Phi \\times \\Theta$$\n",
    "где\n",
    "- $F_{W \\times D}$— матрица распределений слов в документах (нормированные частоты)\n",
    "- $\\Phi_{W \\times T}$ — матрица распределений слов в темах (модель)\n",
    "- $\\Theta_{T \\times D}$ — матрица распределений тем в документах (результат применения модели к обучающим данным)\n",
    "\n",
    "Можно сказать, что алгоритмы тематического моделирования производят мягкую бикластеризацию данных:\n",
    " - *мягкую*, так как объекты относятся не строго к одному кластеру, а к нескольким с разными вероятностями\n",
    " - *бикластеризацию*, так как модель одновременно кластеризует слова по темам и темы по документам.\n",
    " \n",
    " С вероятностной точки зрения, задача обучения модели PLSA ставится как максимизация неполного правдоподобия по параметам $\\Phi$ и $\\Theta$. ЕМ-алгоритм для модели PLSA заключается в повторении двух шагов:\n",
    "\n",
    "- **Е-шаг** — оценка распределений тем для каждого слова в каждом документе по параметрам $\\Phi$ и $\\Theta$ (шаг 6);\n",
    "- **М-шаг** — обновление параметров $\\Phi$ и $\\Theta$ на основе полученных оценок (шаги 7 и 9).\n",
    "\n",
    "Существуют различные модификации итерационного процесса, позволяющие снизить расходы по памяти. В данном случае, мы избежим хранения трехмерной матрицы $p_{tdw}$, сразу пересчитывая $\\Theta$ для текущего документа и аккумулируя счетчики $n_{wt}$ для последующего пересчета $\\Phi$.\n",
    "\n",
    "Псевдокод алгоритма записывается следующим образом:\n",
    "\n",
    "1. Инициализировать $\\phi_{wt}^0$ для всех $w \\in W$, $t \\in T$ и $\\theta_{td}^0$ для всех $t \\in T$, $d \\in D$\n",
    "2. Внешний цикл по итерациям $i = 1 ... max\\_iter$:\n",
    "3. $\\quad$ $n_{wt}^i := 0$, $n_t^i := 0$ для всех $w \\in W$ и $t \\in T$ \n",
    "4. $\\quad$ Внутренний цикл по документам $d \\in D$  \n",
    "5. $\\qquad$ $Z_w := \\sum_{t \\in T} \\phi_{wt}^{i-1}\\theta_{td}^{i-1}$ для всех $w \\in d$ $\\cfrac{}{}$\n",
    "6. $\\qquad$ $p_{tdw} := \\cfrac{ \\phi_{wt}^{i-1}\\theta_{td}^{i-1} }{ Z_w }$ (**E-шаг**)\n",
    "7. $\\qquad$ $\\theta_{td}^{i} := \\cfrac{ \\sum_{w \\in d} n_{dw} p_{tdw} }{ n_d }$ для всех $t \\in T$ (**M-шаг**)\n",
    "8. $\\qquad$ Увеличить $n_{wt}^i$ и $n_t^i$ на $n_{dw} p_{tdw}$ для всех $w \\in W$ и $t \\in T$\n",
    "9. $\\quad \\phi_{wt}^i := \\cfrac{n_{wt}^i}{n_t^i}$ для всех $w \\in W$ и $t \\in T$ (**M-шаг**)\n",
    "\n",
    "Обозначения:\n",
    " - $p_{tdw}$ — вероятность темы $t$ для слова $w$ в документе $d$\n",
    " - $\\phi_{wt}$ — элемент матрицы $\\Phi$, соответствующий вероятности слова $w$ в теме $t$\n",
    " - $\\theta_{td}$ — элемент матрицы $\\Theta$, соответствующий вероятности темы $t$ в документе $d$\n",
    " - $n_{wt}$ — элемент матрицы счётчиков отнесения слова $w$ к теме $t$ (путем нормирования этой матрицы получается матрица $\\Phi$)\n",
    " - $Z_w$ — элемент вектора вспомогательных переменных, соответствующий слову $w$\n",
    " - $n_t$ — вектор нормировочных констант для матрицы $n_{wt}$\n",
    " - $n_d$ — вектор нормировочных констант для матрицы $n_{dw}$\n",
    " - $n$ — суммарное число слов в коллекции\n",
    "\n",
    "Для оценивания качества построенной модели и контроля сходимости процесса обучения обычно используют [перплексию](http://www.machinelearning.ru/wiki/images/8/88/Voron-iip9-talk.pdf):\n",
    "\n",
    "$$\\mathcal{P} = \\exp\\bigg(- \\frac{\\mathcal{L}}{n} \\bigg) = \\exp\\bigg(- \\cfrac{1}{n}\\sum_{d \\in D}\\sum_{w \\in d} n_{dw} \\ln \\big(\\sum_{t \\in T}\\phi_{wt}\\theta_{td} \\big)\\bigg)$$\n",
    "\n",
    "Это традиционная мера качества в тематическом моделировании, которая основана на правдоподобии модели $\\mathcal{L}$. Число итераций $max\\_iter$ в алгоритме обучения следует выбирать достаточным для того, чтобы перплексия перестала существенно убывать. Однако известно, что перплексия плохо отражает интерпретируемость найденных тем, поэтому помимо нее обычно используются дополнительные меры или экспертные оценки.\n",
    "\n",
    "**Рекомендации к реализации:**\n",
    "\n",
    "- При делении на нулевые значения нужно просто заменить частное на ноль.\n",
    "- ЕМ-алгоритм стоит реализовывать с использованием векторных операций. Для проверки корректности реализации сперва можно написать скалярную версию, после чего векторизовать её, удостоверившись, что обе реализации дают одинаковый результат. Невекторизованный алгоритм может работать в сотни раз медленнее векторизованного, и его использование может привести к невозможности выполнения задания.\n",
    "- Итерационный процесс следует начинать, инициализировав матрицы $\\Phi$ и $\\Theta$. Инициализация может быть случайной, важно не забыть отнормировать столбцы матриц.\n",
    "- Неэффективная реализация перплексии может в разы замедлить работу алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d5d52",
   "metadata": {},
   "source": [
    "**Задание 4 (3 балла)** \n",
    "\n",
    "Реализуйте описанный выше ЕМ-алгоритм для модели *PLSA* и добавьте в вашу реализацию подсчёт перплексии. \n",
    "\n",
    "Примените ваш алгоритм к подготовленным ранее данным (объедините текст из колонок *name* и *description*), рассмотрев число тем T = 5, а также:\n",
    "\n",
    "* Постройте график значения перплексии в зависимости от итерации (убедитесь в корректности реализации: график перплексии должен быть невозрастающим). \n",
    "* Выведите для каждой темы топ-20 наиболее вероятных слов.\n",
    "\n",
    "Посмотрите внимательно на полученные темы. Как вам кажется, получились ли они интерпретируемыми?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa99e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLSA:\n",
    "    def __init__(self, counts: np.matrix, T: int):\n",
    "        self.counts = counts\n",
    "        self.T = T\n",
    "\n",
    "        # your code here\n",
    "\n",
    "        initialize_params()\n",
    "    \n",
    "    def initialize_params(self):\n",
    "        self.Phi = # your code here\n",
    "        self.Theta = # your code here\n",
    "\n",
    "    def step(self):\n",
    "        # your code here\n",
    "\n",
    "    def perplexity(self) -> float:\n",
    "        # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06918bea",
   "metadata": {},
   "source": [
    "**Задание 5 (1 балл)** \n",
    "\n",
    "Рассмотрите большее число тем (10, 20) и несколько различных начальных приближений. Проанализируйте результаты и ответьте на следующие вопросы: \n",
    "\n",
    "- Mожно ли сказать, что интерпретируемость каждой темы изменяется с ростом их числа?\n",
    "- Устойчив ли алгоритм к начальному приближению на примере идентичности топовых слов в соответствующих темах?\n",
    "- Отражает ли перплексия качество получаемых моделей? В чём заключается причина хорошего/плохого соответствия?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c6265",
   "metadata": {},
   "source": [
    "## Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a685dd0",
   "metadata": {},
   "source": [
    "**Задание 6 (2 балла)** \n",
    "\n",
    "В данном задание следуют сравнить между собой алгоритмы [KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), [DBSCAN](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) и [Birch](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.Birch.html) используя подготовленные ранее данные.\n",
    "\n",
    "Поэксперементируйте с различными способами векторизации текста, например можно:\n",
    "\n",
    "- использовать только *name* / *description*, объединить их в один текст или сконкатенировать векторные представления,\n",
    "- использовать представление в виде мешка слов или какую-либо его модификацию,\n",
    "- сократить размерность векторного представления, используя PCA или векторные представления слов,\n",
    "\n",
    "или сделать что-то более интересное, что вы придумаете!\n",
    "\n",
    "Выберете лучшую комбинацию векторизации и алгоритма кластеризации и визуализируйте полученные кластеры (например, воспользовавшись облаком тегов, или предложите свой способ). Обоснуйте почему вы считаете, что выбранный вами подход для решения задачи кластеризации вакансий является лучшим.\n",
    "\n",
    "**Задание \"со звездочкой\" (1 балл)** \n",
    "\n",
    "Попробуйте обогатить векторное представление полученное из текстов другими признаками из таблицы `vacancies.csv` и добиться лучшей интерпретируемости кластеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1828ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c697e46",
   "metadata": {},
   "source": [
    "## Частичное обучение\n",
    "\n",
    "Часто у нас есть размеченная выборка только для небольшой части выборки. Тогда мы можем применить подходы _частичного обучения (semi-supervised learning)_. Более подробно про реализацию таких методов в sklearn можно прочитать в разделе [semi-supervised](http://scikit-learn.org/stable/modules/label_propagation.html#semi-supervised)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceffa132",
   "metadata": {},
   "source": [
    "**Задание 7 (2 балла)** \n",
    "\n",
    "В этом задание нужно сделать следующее: \n",
    "\n",
    "- Разделите объекты, у которых существуют метки, на обучающую и тестовую выборки (при этом не обязательно делить в соотношении 70% на 30%). Обогатите обучающую выборку объектами без меток.\n",
    "- Воспользовавшись опытом выполнения задания 6, возьмите \"лучшее\" векторное представление вакансий и обучите [LabelSpreading](http://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.LabelSpreading.html) (подберите лучшие параметры, опираясь на [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)).\n",
    "- Попробуйте запустить алгоритм несколько раз, отмечая известными различные объекты, а также меняя пропорции разбиения, посчитайте качество и визуализируйте результаты. Можно ли сказать что алгоритм сильно зависит от известных начальных объектов? Есть ли класс, для которого это больше всего заметно?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e44914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
