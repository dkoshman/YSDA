{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 27 ноября 2017, 23:59   \n",
    "**Штраф за опоздание:** -2 балла после 23:59  4 декабря, -4 балла после 23:59 11 декабря, -6 баллов после 23:59 18 декабря\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "Необходимо в slack создать таск в приватный чат:   \n",
    "/todo Фамилия Имя *ссылка на гитхаб* @alkhamush   \n",
    "Пример:   \n",
    "/todo Ксения Стройкова https://github.com/stroykova/spheremailru/stroykova_hw1.ipynb @alkhamush   \n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разбаловка:**   \n",
    "За задание можно получить 10 баллов. Для этого нужно следующее:\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает    \n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала качественнее, чем у дерева из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "1                 1                              0.766127   45   \n",
       "2                 0                              0.957151   40   \n",
       "3                 0                              0.658180   38   \n",
       "4                 0                              0.233810   30   \n",
       "5                 0                              0.907239   49   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "1                                     2   0.802982         9120.0   \n",
       "2                                     0   0.121876         2600.0   \n",
       "3                                     1   0.085113         3042.0   \n",
       "4                                     0   0.036050         3300.0   \n",
       "5                                     1   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "1                               13                        0   \n",
       "2                                4                        0   \n",
       "3                                2                        1   \n",
       "4                                5                        0   \n",
       "5                                7                        0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "1                             6                                     0   \n",
       "2                             0                                     0   \n",
       "3                             0                                     0   \n",
       "4                             0                                     0   \n",
       "5                             1                                     0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "1                 2.0  \n",
       "2                 1.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "5                 0.0  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./cs-training.csv', sep=',').dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df.as_matrix(columns=df.columns[1:])\n",
    "y = df.as_matrix(columns=df.columns[:1])\n",
    "y = y.reshape(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier_original(BaseEstimator):\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, \n",
    "                 min_samples_split=2,\n",
    "                 max_depth=None,\n",
    "                 sufficient_share=1.0,\n",
    "                 criterion='gini',\n",
    "                 max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print 'invalid criterion name'\n",
    "            raise Exception\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print 'invalid max_features name'\n",
    "            raise Exception\n",
    "            \n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return ((1 - ((l_c / l_s) ** 2).sum(axis=1)) * l_s.T + (1 - ((r_c / r_s) ** 2).sum(axis=1)) * r_s.T)[0]\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s): \n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return ((-((l_c / l_s) * np.log(np.where(l_c / l_s == 0, 1, l_c / l_s))).sum(axis=1)) * l_s.T - \\\n",
    "                (((r_c / r_s) * np.log(np.where(r_c / r_s == 0, 1, r_c / r_s))).sum(axis=1)) * r_s.T)[0]\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return ((1 - np.max(l_c, axis=1) / l_s) * l_s.T + (1 - np.max(r_c, axis=1) / r_s) * r_s.T)[0]\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.sqrt(n_feature))]\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.log2(n_feature))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return range(n_feature)\n",
    "    \n",
    "    def _sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def _div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def _find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода?\n",
    "        # Сортирует параметр x и использует полученный индекс для y,\n",
    "        # чтобы сохранить соответствие между значением параметра и целевой переменной.\n",
    "        # class_number - число различных классов, которым принадлежат элементы в узле\n",
    "        sorted_x, sorted_y = self._sort_samples(x, y)\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # Поскольку в листьях не может быть меньше min_samples_split элементов, мы можем делить только по индексам\n",
    "        # в splitted_sorted_y. В r_border_ids вычисляется индекс, где следующий класс не равен предыдущему и затем смещается,\n",
    "        # чтобы получить индексы, соответствующие возможным разбиениям в sorted_y, причем они указывают на первый элемент \n",
    "        # отличного класса.\n",
    "        splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "        \n",
    "        if len(r_border_ids) == 0:\n",
    "            return float('+inf'), None \n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # eq_el_count -- то, сколько элеметов принадлежит каждому следующему классу\n",
    "        # one_hot_code -- в каждой строчке записано то, какой класс будет крайним слева, если разделить по соответствущему \n",
    "        # id в r_borders_id\n",
    "        # class increments -- то же самое, но кроме id класса в каждой строчке можно понять, сколько \n",
    "        # элементов принадлежит каждой группе подряд идущих элементов одного класса.\n",
    "        # Причем в первой строчке также учитываются те элементы, которые есть в первых min_samples_split элементах\n",
    "        eq_el_count = r_border_ids - np.append([self.min_samples_split], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:self.min_samples_split],\n",
    "                                                                minlength=class_number)\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # l_class_count -- в каждой строчке написано, сколько элементов каждого класса будет в левом узле, если разбить\n",
    "        # по соответствующему элементу\n",
    "        # r_class_count -- то, сколько в правом узле\n",
    "        # l_sizes -- размеры левого узла при разбиениях\n",
    "        # r_sizes -- размеры правого\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "        r_class_count = np.bincount(sorted_y) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # Подсчитывается ошибка при каждом разбиении и берется то, при котором ошибка минимальна\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # left_el_id -- указывает на крайний элемент правого узла\n",
    "        # Функция возращает ошибку, которую даст лучшее разбиение и порог, по которому делится узел.\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx], (sorted_x[left_el_id] + sorted_x[left_el_id + 1]) / 2.0\n",
    "\n",
    "    def _fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        leaf = [\n",
    "            self.__class__.LEAF_TYPE, \n",
    "            np.argmax(np.bincount(y, minlength=self.num_class)), \n",
    "            np.bincount(y, minlength=self.num_class) * 1.0 / y.shape[0]\n",
    "        ]\n",
    "        \n",
    "        if depth == self.max_depth:\n",
    "            self.tree[node_id] = leaf\n",
    "            return\n",
    "        \n",
    "        feature_ids = self.get_feature_ids(x.shape[1])\n",
    "        \n",
    "        split_data = []\n",
    "        for feature in feature_ids:\n",
    "            error, threshold = self._find_threshold(x[:, feature], y)\n",
    "            split_data.append([feature, error, threshold])\n",
    "        best_split = min(split_data, key=lambda split: split[1])\n",
    "        x_l, x_r, y_l, y_r = self._div_samples(x, y, best_split[0], best_split[2])\n",
    "        if best_split[1] == np.inf or not all([i.shape[0] for i in [y_l, y_r]]):\n",
    "            self.tree[node_id] = leaf\n",
    "            return\n",
    "        self.tree[node_id] = (self.__class__.NON_LEAF_TYPE, best_split[0], best_split[2])\n",
    "        self._fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "        self._fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.tree = {}\n",
    "        self.num_class = np.unique(y).size\n",
    "        self._fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quality(model, quality_measure=accuracy_score):\n",
    "    time0 = time()\n",
    "    model.fit(x, y)\n",
    "    print \"Train time:\\t{}\".format(time() - time0)\n",
    "    print \"Train score:\\t{}\".format(quality_measure(y, model.predict(x)))\n",
    "    \n",
    "    gkf = KFold(n_splits=5, shuffle=True)\n",
    "    scores = []\n",
    "    for train, test in gkf.split(x, y):\n",
    "        X_train, y_train = x[train], y[train]\n",
    "        X_test, y_test = x[test], y[test]\n",
    "        model.fit(X_train, y_train)\n",
    "        scores.append(quality_measure(y_test, model.predict(X_test)))\n",
    "    \n",
    "    print \"Avg test score:\\t{}\".format(sum(scores) / len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим качество получившейся модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t0.427999973297\n",
      "Train score:\t0.935120438351\n",
      "Avg test score:\t0.931786265794\n"
     ]
    }
   ],
   "source": [
    "quality(MyDecisionTreeClassifier_original(min_samples_split=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним с моделью из sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t1.15300011635\n",
      "Train score:\t0.999983370611\n",
      "Avg test score:\t0.892075266314\n"
     ]
    }
   ],
   "source": [
    "quality(DecisionTreeClassifier(min_samples_split=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось, что наша модель обучается в 2 раза быстрее модели из sklearn, хуже обучается на данных, и при этом лучше предсказывает. Что здесь происходит?\n",
    "\n",
    "Сначала посмотрим на эти 2 строчки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В каждом листе будет не менее min_samples_split + 1 элементов, то есть то, что в коде называется min_samples_split является min_samples_leaf - 1 в sklearn. То есть модель, эквивалентная \n",
    "```python\n",
    "MyDecisionTreeClassifier_original(min_samples_split=2)\n",
    "```\n",
    "будет \n",
    "```python\n",
    "DecisionTreeClassifier(min_samples_leaf=3)\n",
    "```\n",
    "Посмотрим на разницу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t0.930000066757\n",
      "Train score:\t0.968354272506\n",
      "Avg test score:\t0.903690921787\n"
     ]
    }
   ],
   "source": [
    "quality(DecisionTreeClassifier(min_samples_leaf=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало немного больше похоже на нашу модель, но разница все еще велика.\n",
    "\n",
    "Посмотрим на дерево, которое строит наша модель, а точнее на самый первый узел:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 6, 1.0)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_original = MyDecisionTreeClassifier_original(min_samples_split=2)\n",
    "clf_original.fit(x, y)\n",
    "clf_original.tree[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что будет, если мы поделим по 6-ой фиче с порогом 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2413L,), (117856L,), (120269L,))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_l, x_r, y_l, y_r = clf_original._div_samples(x, y, 6, 1.0)\n",
    "y_l.shape, y_r.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "117856 из 120269 элементов будут отнесены к правому узлу. А правый узел ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, array([ 0.94046124,  0.05953876])]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_original.tree[0 * 2 + 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...является листом. То есть 98% всех элементов оказались в одном листе. Это объясняет скорость алгоритма, но как при этом получается приличное качество? Посмотрим на наши данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    111912\n",
       "1      8357\n",
       "dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных сильное смещение в сторону класса 0, и даже простое предсказание 'все нули' дает хорошее качество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.930514097564626"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.zeros(y.shape), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это ожидаемо, ведь accuracy_score плохо подходит для не сбалансированных классов. Лучше использовать f-measure или roc_auc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model\n",
      "\n",
      "F-measure\n",
      "Train time:\t0.431999921799\n",
      "Train score:\t0.187779743937\n",
      "Avg test score:\t0.151378463565\n",
      "\n",
      "ROC-AUC\n",
      "Train time:\t0.427999973297\n",
      "Train score:\t0.552411941422\n",
      "Avg test score:\t0.549941893078\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print 'Our model\\n\\nF-measure'\n",
    "quality(MyDecisionTreeClassifier_original(min_samples_split=2), f1_score)\n",
    "print '\\nROC-AUC'\n",
    "quality(MyDecisionTreeClassifier_original(min_samples_split=2), roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn model\n",
      "\n",
      "F-measure:\n",
      "Train time:\t0.880000114441\n",
      "Train score:\t0.751790597734\n",
      "Avg test score:\t0.272923686327\n",
      "\n",
      "ROC-AUC:\n",
      "Train time:\t0.917999982834\n",
      "Train score:\t0.838832174057\n",
      "Avg test score:\t0.603788054989\n"
     ]
    }
   ],
   "source": [
    "print 'sklearn model\\n\\nF-measure:'\n",
    "quality(DecisionTreeClassifier(min_samples_leaf=3), f1_score)\n",
    "print '\\nROC-AUC:'\n",
    "quality(DecisionTreeClassifier(min_samples_leaf=3), roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь уже видна сильная разница в качестве. Так почему качество нашей модели намного хуже? Почему она отнесла 98% всех элементов в один лист? Все дело в этой строчке:\n",
    "```python\n",
    "r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "```\n",
    "Дело в том, что мы хотим делить данные в местах, где меняется класс. Это правда, что если делить в местах смены класса ошибка будет минимальна, но ведь мы не проверили, что там можно делить. То есть может не существовать порога, который делит данные в том месте, где мы нашли минимальную ошибку. В частности алгоритм попытался разделить данные по 6-ой фиче и одному и тому же порогу два раза подряд, из-за чего и получось несбалансированное дерево.\n",
    "Напишем исправленный класс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier(MyDecisionTreeClassifier_original):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.min_samples_leaf = kwargs.pop('min_samples_leaf', 1)\n",
    "        super(MyDecisionTreeClassifier, self).__init__(**kwargs)\n",
    "        criterion_dict = {\n",
    "            'gini': self.__gini,\n",
    "            'entropy': self.__entropy,\n",
    "            'misclass': self.__misclass\n",
    "        }\n",
    "        self.G_function = criterion_dict.get(kwargs.get('criterion', 'gini'))\n",
    "        if self.G_function is None:\n",
    "            raise Exception('invalid criterion name')\n",
    "            \n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        return (1 - ((l_c.T / l_s) ** 2).sum(axis=0)) * l_s + (1 - ((r_c.T / r_s) ** 2).sum(axis=0)) * r_s\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        l_c_T = l_c.T\n",
    "        r_c_T = r_c.T\n",
    "        return (-((l_c_T / l_s) * np.log(np.where(l_c_T == 0, 1, l_c_T / l_s))).sum(axis=0)) * l_s - \\\n",
    "                (((r_c_T / r_s) * np.log(np.where(r_c_T == 0, 1, r_c_T / r_s))).sum(axis=0)) * r_s\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return (1 - np.max(l_c, axis=1) / l_s) * l_s + (1 - np.max(r_c, axis=1) / r_s) * r_s\n",
    "    \n",
    "    # Теперь x -- двумерный массив\n",
    "    def _find_threshold(self, x, y):\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        if class_number == 1:\n",
    "            return None, float('+inf')\n",
    "        \n",
    "        n_samples = y.shape[0]\n",
    "        x_args = np.argsort(x, axis=0)\n",
    "        sorted_x = x[x_args, np.arange(x.shape[1])[np.newaxis, :]]\n",
    "        sorted_y = y[x_args]\n",
    "        borders = ((np.arange(n_samples - 1) >= self.min_samples_leaf - 1) & \\\n",
    "                  (np.arange(n_samples - 1) <= n_samples - self.min_samples_leaf)).reshape((1, -1))\n",
    "        r_border_ids = (sorted_x[1:] != sorted_x[:-1]) & borders.T\n",
    "        if r_border_ids.sum() == 0:\n",
    "            return None, float('+inf')\n",
    "        \n",
    "        def classes_to_quality(arr):\n",
    "            arr = arr.astype(int)\n",
    "            one_hot = np.eye(class_number)[arr]\n",
    "            l_c = one_hot.cumsum(axis=0)\n",
    "            r_c = (l_c[-1] - l_c)[:-1]\n",
    "            l_c = l_c[:-1]\n",
    "\n",
    "            l_s = np.sum(l_c, axis=1)\n",
    "            r_s = arr.shape[0] - l_s\n",
    "            return self.G_function(l_c, l_s, r_c, r_s)\n",
    "    \n",
    "        quality = np.apply_along_axis(classes_to_quality, 0, sorted_y)\n",
    "        left_el_idx, feature = np.unravel_index(np.where(r_border_ids, quality, np.inf).argmin(), x.shape)\n",
    "        \n",
    "        # берем не простое среднее, а с весами, пропорциональными размеру узлов\n",
    "        return feature, sorted_x[left_el_idx, feature] * (left_el_idx + 1) / n_samples + \\\n",
    "               sorted_x[left_el_idx + 1, feature] * (1. - 1. * (left_el_idx + 1) / n_samples)\n",
    "\n",
    "    def _fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        leaf = [\n",
    "            self.__class__.LEAF_TYPE, \n",
    "            np.argmax(np.bincount(y, minlength=self.num_class)), \n",
    "            np.bincount(y, minlength=self.num_class) * 1.0 / y.shape[0]\n",
    "        ]\n",
    "        \n",
    "        if depth == self.max_depth or y.shape[0] < self.min_samples_split:\n",
    "            self.tree[node_id] = leaf\n",
    "            return\n",
    "        \n",
    "        feature_ids = self.get_feature_ids(x.shape[1])\n",
    "        feature, threshold = self._find_threshold(x[:, feature_ids], y)\n",
    "        if feature is None:\n",
    "            self.tree[node_id] = leaf\n",
    "            return\n",
    "        \n",
    "        x_l, x_r, y_l, y_r = self._div_samples(x, y, feature, threshold)\n",
    "        self.tree[node_id] = (self.__class__.NON_LEAF_TYPE, feature, threshold)\n",
    "        self._fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "        self._fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyDecisionTreeClassifier(min_samples_leaf=1)\n",
    "clf = DecisionTreeClassifier(min_samples_leaf=1)\n",
    "model.fit(x, y)\n",
    "clf.fit(x, y)\n",
    "\n",
    "(model.predict(x) != clf.predict(x)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исправленная модель обучилась на выборке точно также, как и модель из sklearn. Посмотрим на ее качество и скорость:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t0.411999940872\n",
      "Train score:\t0.187779743937\n",
      "Avg test score:\t0.170461975606\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "quality(MyDecisionTreeClassifier_original(min_samples_split=2), f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t8.38400006294\n",
      "Train score:\t0.781754574812\n",
      "Avg test score:\t0.261732823104\n"
     ]
    }
   ],
   "source": [
    "# new, same params\n",
    "quality(MyDecisionTreeClassifier(min_samples_leaf=3), f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t9.5720000267\n",
      "Train score:\t0.999880339835\n",
      "Avg test score:\t0.252502196653\n"
     ]
    }
   ],
   "source": [
    "# new, fit until same class in each leaf\n",
    "quality(MyDecisionTreeClassifier(min_samples_leaf=1), f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t0.977999925613\n",
      "Train score:\t0.999880339835\n",
      "Avg test score:\t0.262430656716\n"
     ]
    }
   ],
   "source": [
    "# sklearn model, fit until same class in each leaf\n",
    "quality(DecisionTreeClassifier(min_samples_leaf=1), f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель обучается теперь в 10 раз дольше, но и обучается, и предсказывает гораздо лучше. Вообще создавая модели с такими параметрами мы сильно переобучаем модель. По идее если останавливать обучение пораньше, скорость обучения и качество на тесте должны улучшиться:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t0.238999843597\n",
      "Train score:\t0.1938558248\n",
      "Avg test score:\t0.199660454028\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "quality(MyDecisionTreeClassifier_original(min_samples_split=100), f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t2.44400000572\n",
      "Train score:\t0.298175907531\n",
      "Avg test score:\t0.263360772858\n"
     ]
    }
   ],
   "source": [
    "# new\n",
    "quality(MyDecisionTreeClassifier2(min_samples_leaf=100), f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t0.634999990463\n",
      "Train score:\t0.298148984199\n",
      "Avg test score:\t0.263020755368\n"
     ]
    }
   ],
   "source": [
    "# sklearn model\n",
    "quality(DecisionTreeClassifier(min_samples_leaf=100), f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До скорости sklearn еще далеко, но зато качество теперь примерно такое же."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из экспериментов стало заметно, что _fit_threshold для 2-мерного массива x работает быстрее на маленьких выборок, а изначальный _fit_threshold для одномерного x -- на больших. Давайте воспользуемся этим и напишем класс, который использует один метод для больших x, и другой для маленьких:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier_v2(MyDecisionTreeClassifier):\n",
    "    \n",
    "    # одномерный x\n",
    "    def _find_threshold_big(self, x, y):\n",
    "        sorted_x, sorted_y = self._sort_samples(x, y)\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        n_samples = y.shape[0]\n",
    "        \n",
    "        borders = ((np.arange(n_samples - 1) >= self.min_samples_leaf - 1) & \\\n",
    "                  (np.arange(n_samples - 1) <= n_samples - self.min_samples_leaf))\n",
    "        x_borders = (sorted_x[1:] != sorted_x[:-1]) & borders\n",
    "        y_borders = (sorted_y[1:] != sorted_y[:-1]) & borders\n",
    "        \n",
    "        #проверяем, можно ли использовать y_borders для деления\n",
    "        if (y_borders == (x_borders & y_borders)).all():\n",
    "            r_border_ids = y_borders\n",
    "        else:\n",
    "            r_border_ids = x_borders\n",
    "\n",
    "        if ((r_border_ids).sum() == 0) or (class_number == 1):\n",
    "            return float('+inf'), None\n",
    "        \n",
    "        one_hot_code = np.eye(class_number)[sorted_y]\n",
    "        l_class_count = np.cumsum(one_hot_code, axis=0)[:-1][r_border_ids]\n",
    "        r_class_count = np.bincount(sorted_y, minlength=class_number) - l_class_count\n",
    "        l_sizes = l_class_count.sum(axis=1)\n",
    "        r_sizes = n_samples - l_sizes\n",
    "\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "        left_el_id = int(l_sizes[idx])\n",
    "        \n",
    "        if sorted_x[left_el_id - 1] == sorted_x[left_el_id]:\n",
    "            raise Exception\n",
    "        return gs[idx], sorted_x[left_el_id - 1] * left_el_id / sorted_y.shape[0] + \\\n",
    "               sorted_x[left_el_id] * (1. - 1. * left_el_id / sorted_y.shape[0])\n",
    "\n",
    "\n",
    "    def _fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        n_samples = y.shape[0]\n",
    "        leaf = [\n",
    "            self.__class__.LEAF_TYPE, \n",
    "            np.argmax(np.bincount(y, minlength=self.num_class)), \n",
    "            np.bincount(y, minlength=self.num_class) * 1.0 / n_samples\n",
    "        ]\n",
    "        \n",
    "        if depth == self.max_depth or n_samples < self.min_samples_split:\n",
    "            self.tree[node_id] = leaf\n",
    "            return\n",
    "        \n",
    "        feature_ids = self.get_feature_ids(x.shape[1])\n",
    "        if n_samples < 1000:\n",
    "            feature, threshold = self._find_threshold(x[:, feature_ids], y)    \n",
    "        else:\n",
    "            split_data = []\n",
    "            for feature in feature_ids:\n",
    "                error, threshold = self._find_threshold_big(x[:, feature], y)\n",
    "                split_data.append([feature, error, threshold])\n",
    "            feature, _, threshold = min(split_data, key=lambda split: split[1])\n",
    "            \n",
    "        if feature is None or threshold is None:\n",
    "            self.tree[node_id] = leaf\n",
    "            return\n",
    "        \n",
    "        x_l, x_r, y_l, y_r = self._div_samples(x, y, feature, threshold)\n",
    "        self.tree[node_id] = (self.__class__.NON_LEAF_TYPE, feature, threshold)\n",
    "        self._fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "        self._fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какой выигрыш мы получили по сравнению с предыдущей моделью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t9.32099986076\n",
      "Train score:\t0.999880339835\n",
      "Avg test score:\t0.257549439563\n"
     ]
    }
   ],
   "source": [
    "# предыдущая\n",
    "quality(MyDecisionTreeClassifier(min_samples_leaf=1), f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t7.98300004005\n",
      "Train score:\t0.999880339835\n",
      "Avg test score:\t0.256834378533\n"
     ]
    }
   ],
   "source": [
    "# новая\n",
    "quality(MyDecisionTreeClassifier_v2(min_samples_leaf=1), f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t3.51900005341\n",
      "Train score:\t0.298175907531\n",
      "Avg test score:\t0.26153526087\n"
     ]
    }
   ],
   "source": [
    "# предыдущая\n",
    "quality(MyDecisionTreeClassifier(min_samples_leaf=100), f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:\t2.33299994469\n",
      "Train score:\t0.298175907531\n",
      "Avg test score:\t0.262700334503\n"
     ]
    }
   ],
   "source": [
    "# новая\n",
    "quality(MyDecisionTreeClassifier_v2(min_samples_leaf=100), f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выигрыш по времени при полном обучении : 10%, при неполном: 30%"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
