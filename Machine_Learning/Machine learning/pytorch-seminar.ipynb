{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55114faf",
   "metadata": {},
   "source": [
    "# Pytorch ðŸ”¥\n",
    "\n",
    "Introduction to pytorch\n",
    "\n",
    "This notebook is assembled from these sources:\n",
    "- [practical-dl seminar](https://github.com/yandexdataschool/Practical_DL/blob/fall21/week02_autodiff/seminar_pytorch.ipynb)\n",
    "- [hse dl-course homework](https://github.com/aosokin/dl_cshse_ami/blob/master/2021-fall/homeworks_small/shw2/DL21-fall-shw2.ipynb)\n",
    "- [nyu dl course tensor tutorial](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/01-tensor_tutorial.ipynb)\n",
    "- [nyu dl course autograd tutorial](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/03-autograd_tutorial.ipynb)\n",
    "- [pytorch docs](https://pytorch.org/docs/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dbdfae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi | head -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13db100",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b4d45",
   "metadata": {},
   "source": [
    "Installing pytorch (easier then ever):\n",
    "\n",
    "- Better use virtualenv ([conda](https://docs.conda.io/en/latest/miniconda.html) **is ok**)\n",
    "- `pip3 install torch==1.10.2+cu113 torchvision==0.11.3+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html` (https://pytorch.org/get-started/locally/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fafe6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dimakoshman/.pyenv/versions/shad_env/lib/python3.9/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e52ecbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4441bf6",
   "metadata": {},
   "source": [
    "## Basics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff5b83",
   "metadata": {},
   "source": [
    "Jupyter lifehacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c7412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sq  # <Tab>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be410684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about all `*Tensor`s?\n",
    "# Press <esc> to get out of help\n",
    "torch.*Tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Module()  # <Shift>+<Tab>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4991a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate your functions / classes!\n",
    "torch.nn.Module?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2276b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Module??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ff9a63",
   "metadata": {},
   "source": [
    "### Tensor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b814e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a tensor of size 2x3x4\n",
    "t = torch.Tensor(2, 3, 4)\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of the tensor\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544cefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.size() is a classic tuple =>\n",
    "print('t size:', ' \\u00D7 '.join(map(str, t.size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints dimensional space and sub-dimensions\n",
    "print(f'point in a {t.numel()} dimensional space')\n",
    "print(f'organised in {t.dim()} sub-dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e404776",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mind the underscore!\n",
    "# Any operation that mutates a tensor in-place is post-fixed with an _.\n",
    "# For example: x.copy_(y), x.t_(), x.random_(n) will change x.\n",
    "t.random_(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f9479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This resizes the tensor permanently \n",
    "r = torch.Tensor(t)\n",
    "r.resize_(3, 8)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see zero_ would replace r with 0's which was originally filled with integers\n",
    "r.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5adf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This *is* important, sigh...\n",
    "s = r.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3babcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-place fill of 1's\n",
    "s.fill_(1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we cloned r, even though we did an in-place operation, this doesn't affect r\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf563c",
   "metadata": {},
   "source": [
    "### Vectors and matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c085beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 1D tensor of integers 1 to 4\n",
    "v = torch.Tensor([1, 2, 3, 4])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of dimensions (1D) and size of tensor\n",
    "print(f'dim: {v.dim()}, size: {v.size()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97000fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.Tensor([1, 0, 2, 0])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a2090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise multiplication\n",
    "v * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ac69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar product: 1*1 + 2*0 + 3*2 + 4*0\n",
    "v @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-place replacement of random number from 0 to 10\n",
    "x = torch.Tensor(5).random_(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'first: {x[0]}, last: {x[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed5d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sub-Tensor [from:to)\n",
    "x[1:2 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff797af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But :.(\n",
    "x[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b87146",
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1722e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with integers ranging from 1 to 5, excluding 5\n",
    "v = torch.arange(1, 4 + 1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d64b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square all elements in the tensor\n",
    "print(v.pow(2), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d980818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x4 tensor\n",
    "m = torch.Tensor([[2, 5, 3, 7],\n",
    "                  [4, 2, 1, 9]])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5225d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.size(0), m.size(1), m.size(), sep=' -- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ce911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the total number of elements, hence num-el (number of elements)\n",
    "m.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9faff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing row 0, column 2 (0-indexed)\n",
    "m[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing row 0, column 2 (0-indexed)\n",
    "m[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ebad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing column 1, all rows (returns size 2)\n",
    "m[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5fe4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing column 1, all rows (returns size 2x1)\n",
    "m[:, [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing columns 1 and 3, all rows (returns size 2x2)\n",
    "m[:, [1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0325a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexes row 0, all columns (returns 1x4)\n",
    "m[[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab5c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexes row 0, all columns (returns size 4)\n",
    "m[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f16e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensor of numbers from 1 to 5 (excluding 5)\n",
    "v = torch.arange(1., 4 + 1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1df228",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164de1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar product\n",
    "m @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac427e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated by 1*2 + 2*5 + 3*3 + 4*7\n",
    "m[[0], :] @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated by \n",
    "m[[1], :] @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126bd196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a random tensor of size 2x4 to m\n",
    "m + torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d124b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract a random tensor of size 2x4 to m\n",
    "m - torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply a random tensor of size 2x4 to m\n",
    "m * torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide m by a random tensor of size 2x4\n",
    "m / torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eeb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose tensor m, which is essentially 2x4 to 4x2\n",
    "m.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe4bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as\n",
    "m.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bde76f",
   "metadata": {},
   "source": [
    "### Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43115da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensor from 3 to 8, with each having a space of 1\n",
    "torch.arange(3., 8 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3140244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensor from 5.7 to -2.1 with each having a space of -3\n",
    "torch.arange(5.7, -2.1, -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a05be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a 1D tensor of steps equally spaced points between start=3, end=8 and steps=20\n",
    "torch.linspace(3, 8, 20).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor filled with 0's\n",
    "torch.zeros(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5605ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor filled with 1's\n",
    "torch.ones(3, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036d9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with the diagonal filled with 1\n",
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ff9ac",
   "metadata": {},
   "source": [
    "### Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e0b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to get what kind of tensor types\n",
    "torch.*Tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19faf8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efdfa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is basically a 64 bit float tensor\n",
    "m_double = m.double()\n",
    "m_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1efbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a tensor of type int8\n",
    "m_byte = m.byte()\n",
    "m_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6fb27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move your tensor to GPU device 0 if there is one (first GPU in the system)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ac353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts tensor to numpy array\n",
    "m_np = m.numpy()\n",
    "m_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d3741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-place fill of column 0 and row 0 with value -1\n",
    "m_np[0, 0] = -1\n",
    "m_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a979eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor of integers ranging from 0 to 4\n",
    "import numpy as np\n",
    "n_np = np.arange(5)\n",
    "n = torch.from_numpy(n_np)\n",
    "print(n_np, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-place multiplication of all elements by 2 for tensor n\n",
    "# Because n is essentiall n_np, not a clone, this affects n_np\n",
    "n.mul_(2)\n",
    "n_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff981c",
   "metadata": {},
   "source": [
    "### Named tensors\n",
    "\n",
    "New addition to pytorch: https://pytorch.org/docs/stable/named_tensor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce832815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a named tensor, just pass names for each dim\n",
    "imgs = torch.randn(1, 2, 2, 3 , names=('N', 'C', 'H', 'W'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11984109",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_imgs = imgs.rename(H='height', W='width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e287407",
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a626197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names propagate\n",
    "imgs.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding names to unnamed tensors\n",
    "tensor = torch.randn(2, 3, 5, 7, 11)\n",
    "tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
    "tensor.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cda3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name matching (and how it could be usefull?)\n",
    "x = torch.randn(3, names=('X',))\n",
    "y = torch.randn(3)\n",
    "z = torch.randn(3, names=('Z',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z + z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e89afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x + z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4affe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary ops unify names \n",
    "x = torch.randn(3, 3, names=('N', None))\n",
    "y = torch.randn(3, 3, names=(None, 'C'))\n",
    "\n",
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5644349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Won't work\n",
    "x = torch.randn(3, 3, names=('N', 'C'))\n",
    "y = torch.randn(3, names=('N',))\n",
    "\n",
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e53e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also won't work\n",
    "x = torch.randn(3, 3, names=('N', None))\n",
    "y = torch.randn(3, names=('N',))\n",
    "\n",
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284bb085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit align\n",
    "img = torch.randn(5,3,28,28, names=('N','C','H','W'))\n",
    "scale = torch.randn(3, names=('C',))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9909eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "img * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b39a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No more unsqueeze and [...,None]\n",
    "img * scale.align_as(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff92b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder\n",
    "img.align_to('H', 'W', ...).names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65377e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contract away dims\n",
    "img.sum(('H', 'W'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df904414",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.randn(10,10, names=('A', 'B'))\n",
    "v = torch.randn(10, names=('C',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddfc718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply\n",
    "m @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permute dims and vector multiply\n",
    "m.t() @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4644a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmm\n",
    "x = torch.randn(3, 10, 4, 5, names=('A', 'B', 'C', 'D'))\n",
    "y = torch.randn(10, 5, 8, names=('B', 'E', 'F'))\n",
    "z = torch.matmul(x, y)\n",
    "\n",
    "z.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fef528",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473beb79",
   "metadata": {},
   "source": [
    "**Note:** named tensors are still in development, some operations might not be supported, autograd support is also limited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b57fa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### KNN in pytorch  `[TODO]`\n",
    "\n",
    "Let's implement knn in pytorch `Tensor`'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107bb7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13a354",
   "metadata": {},
   "source": [
    "Let's implement a knn classifier:\n",
    "\n",
    "* Iterate through test_features (whole dataset probably wont fit in memory)\n",
    "    * For each batch compute l2 nearest neighbors `[batch_size, k_neighbors]`\n",
    "    * Retrieve each neighbors class `[batch_size, k_neighbors]`\n",
    "    * Compute 'probabilities' with `sum_neighbors(exp(-l2/T))` (just weighted sum for neighbors)\n",
    "    * return sorted classes `[test_size, n_classes]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e3edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def knn_classifier(\n",
    "    train_features, train_labels, test_features, k, T=1, num_classes=7\n",
    "):\n",
    "    n_test, num_chunks = test_features.shape[0], 50\n",
    "    n_per_chunk = n_test // num_chunks\n",
    "    retrieval_one_hot = torch.zeros(k, num_classes).to(train_features.device)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for index in range(0, n_test, n_per_chunk):\n",
    "        features = test_features[index : min(index + n_per_chunk, n_test)]\n",
    "        batch_size = \n",
    "        l2 = torch.cdist(features, train_features)\n",
    "        \n",
    "        dist, ids = torch.topk(dim=1, k=2, largest=False)\n",
    "        candidates = train_labels[None].expand(batch_size, -1)\n",
    "        neighbors = torch.gather(candidates, 1, idx).long()\n",
    "        neighbors[i]\n",
    "        \n",
    "\n",
    "    return torch.cat(predictions)\n",
    "\n",
    "\n",
    "def accuracy(inputs, targets):\n",
    "    return ((inputs == targets).sum() / inputs.shape[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60de6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "X, y = fetch_covtype(return_X_y=True); y -= 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "quantile = QuantileTransformer()\n",
    "\n",
    "X_train = quantile.fit_transform(X_train)\n",
    "X_test  = quantile.transform(X_test)\n",
    "\n",
    "# Convert to torch tensors\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test  = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "y_test  = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7f0bf8c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5w/gytwm8sd6vldh9ym3dvj_x_m0000gn/T/ipykernel_78305/2097570027.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/shad_env/lib/python3.9/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "X_train = X_train.to(\"cuda:2\")\n",
    "X_test  = X_test.to(\"cuda:2\")\n",
    "y_train = y_train.to(\"cuda:2\")\n",
    "y_test  = y_test.to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c0b158b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Your code here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5w/gytwm8sd6vldh9ym3dvj_x_m0000gn/T/ipykernel_78305/3243342111.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m predictions = knn_classifier(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/.pyenv/versions/shad_env/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5w/gytwm8sd6vldh9ym3dvj_x_m0000gn/T/ipykernel_78305/304225742.py\u001b[0m in \u001b[0;36mknn_classifier\u001b[0;34m(train_features, train_labels, test_features, k, T, num_classes)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your code here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Your code here"
     ]
    }
   ],
   "source": [
    "predictions = knn_classifier(\n",
    "    X_train, y_train, X_test,\n",
    "    k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fde230",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_test.cpu().numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(predictions[:,0], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c96372",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(torch.zeros_like(y_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62374975",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(torch.ones_like(y_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d0cc09",
   "metadata": {},
   "source": [
    "### More:\n",
    "\n",
    "- *Torch* full API should be read at least once.\n",
    "Hence, go [here](https://pytorch.org/docs/stable/index.html).\n",
    "You'll find 100+ `Tensor` operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc are described.\n",
    "- It's *almost* numpy, but not quite (but people are working on it https://data-apis.org/array-api/latest/purpose_and_scope.html)\n",
    "- Cool library (einops): https://openreview.net/forum?id=oapKSVM2bcj\n",
    "- Competition strong! https://github.com/google/jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea81d5",
   "metadata": {},
   "source": [
    "---\n",
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacfd4d9",
   "metadata": {},
   "source": [
    "Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 tensor with gradient-accumulation capabilities\n",
    "x = torch.tensor([[1, 2], [3, 4]], requires_grad=True, dtype=torch.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e39dfe",
   "metadata": {},
   "source": [
    "Do an operation on the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduct 2 from all elements\n",
    "y = x - 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1534bfd8",
   "metadata": {},
   "source": [
    "``y`` was created as a result of an operation, so it has a ``grad_fn``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97023728",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's happening here?\n",
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's dig further...\n",
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5012af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad_fn.next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b40e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad_fn.next_functions[0][0].variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do more operations on y\n",
    "z = y * y * 3\n",
    "a = z.mean()  # average\n",
    "\n",
    "print(z)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000524ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualise the computational graph! (thks @szagoruyko)\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66dbaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3047c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dot(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6200f7",
   "metadata": {},
   "source": [
    "### Gradients\n",
    "\n",
    "Let's backprop now `out.backward()` is equivalent to doing `out.backward(torch.tensor([1.0]))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee5ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop\n",
    "a.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2ba23",
   "metadata": {},
   "source": [
    "Print gradients $\\frac{\\text{d}a}{\\text{d}x}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute it by hand BEFORE executing this\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b8134",
   "metadata": {},
   "source": [
    "You can do many crazy things with autograd!\n",
    "> With Great *Flexibility* Comes Great Responsibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f7cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic graphs!\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "for i in range(10):\n",
    "    y = y * 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_dot(y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't run backward on a scalar we need to specify the grad_output\n",
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb73144",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable decides the tensor's range below\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both x and w that allows gradient accumulation\n",
    "x = torch.arange(1., n + 1, requires_grad=True)\n",
    "w = torch.ones(n, requires_grad=True)\n",
    "z = w @ x\n",
    "z.backward()\n",
    "print(x.grad, w.grad, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only w that allows gradient accumulation\n",
    "x = torch.arange(1., n + 1)\n",
    "w = torch.ones(n, requires_grad=True)\n",
    "z = w @ x\n",
    "z.backward()\n",
    "print(x.grad, w.grad, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both x and w that allows gradient accumulation\n",
    "x = torch.arange(1., n + 1, requires_grad=True)\n",
    "w = torch.ones(n, requires_grad=True)\n",
    "\n",
    "# Non leaf node\n",
    "h = w * x\n",
    "h.retain_grad()\n",
    "\n",
    "z = h.sum()\n",
    "z.backward()\n",
    "print(x.grad, w.grad, h.grad, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adaad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1., n + 1)\n",
    "w = torch.ones(n, requires_grad=True)\n",
    "\n",
    "# Regardless of what you do in this context, all torch tensors will not have gradient accumulation\n",
    "with torch.no_grad():\n",
    "    z = w @ x\n",
    "\n",
    "try:\n",
    "    z.backward()  # PyTorch will throw an error here, since z has no grad accum.\n",
    "except RuntimeError as e:\n",
    "    print('RuntimeError!!! >:[')\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee84dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def knn_classifier():\n",
    "    # Your evaluation code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21155662",
   "metadata": {},
   "source": [
    "### More:\n",
    "- Good blog post on backprop: https://colah.github.io/posts/2015-08-Backprop/\n",
    "- Advanced, but fun: https://minitorch.github.io/\n",
    "- Documentation of the automatic differentiation package is at\n",
    "http://pytorch.org/docs/autograd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a7a166",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae2b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "from sklearn.datasets import load_boston\n",
    "from IPython.display import clear_output\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "\n",
    "x = (X[:, -1] - X[:, -1].mean()) / X[:, -1].std()\n",
    "y = (y - y.mean()) / y.std()\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4609d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model tensors\n",
    "w = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# data tensors\n",
    "x = torch.from_numpy(x).type(torch.float)\n",
    "y = torch.from_numpy(y).type(torch.float)\n",
    "\n",
    "for vv in [w, b, x, y]:\n",
    "    print(vv.is_leaf, vv.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8543d",
   "metadata": {},
   "source": [
    "### `[TODO]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    #compute loss\n",
    "    y_pred = w * x  + b\n",
    "    loss = torch.mean((y_pred - y)**2)\n",
    "    \n",
    "    # backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # gradient descent step for weights\n",
    "    # take alpha about 0.1\n",
    "    raise NotImplementedError(\"Your code here\")\n",
    "\n",
    "    w.data -= 0.1 * w.grad\n",
    "    b.data -= 0.1 * b.grad\n",
    "\n",
    "    \n",
    "    #zero gradients\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "    #the rest of code is just bells and whistles\n",
    "    if (i + 1) % 5==0:\n",
    "        #draw linear regression prediction vs data\n",
    "        clear_output(True)\n",
    "        plt.axhline(0, color='gray')\n",
    "        plt.axvline(0, color='gray')\n",
    "        plt.scatter(x.numpy(),y.numpy())\n",
    "        plt.plot(x.numpy(),y_pred.data.numpy(),color='orange')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.item())\n",
    "        if loss.item() < 0.5:\n",
    "            print(\"Done!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2774447c",
   "metadata": {},
   "source": [
    "## Higher level APIs\n",
    "\n",
    "Above we've coded linear regression and basic gradient descent by hand. In practice it becomes cumbersome to manage parameters, their updates when you go beyond linear regression. Pytorch also has high-level api's with common nn building blocks, optimizers, distributed training utils and more. (see [docs](https://pytorch.org/docs/stable/) for examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e05323",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --quiet --show-progress \"https://raw.githubusercontent.com/aosokin/dl_cshse_ami/master/2021-fall/homeworks_small/shw2/util.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b24b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST again\n",
    "from util import load_mnist\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_mnist(flatten=True)\n",
    "\n",
    "fig = plt.figure(figsize=[6, 6], dpi=80)\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.title(\"Label: %i\" % y_train[i])\n",
    "    plt.imshow(X_train[i].reshape([28, 28]), cmap='gray');\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c099df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Module?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b8010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_size=40):\n",
    "        super(Net, self).__init__()\n",
    "        # here you construct weights for layers\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # here you describe usage of layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2f5db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb037e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32442ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(*map(lambda x: torch.from_numpy(x.copy()).to(\"cuda:2\"), [X_train, y_train]))\n",
    "test_ds = TensorDataset(*map(lambda x: torch.from_numpy(x.copy()).to(\"cuda:2\"), [X_test, y_test]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53976703",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_dl  = DataLoader(test_ds, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02625381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a train function\n",
    "def train(model, optimizer, batchsize=32):\n",
    "    loss_log, acc_log = [], []\n",
    "        \n",
    "    model.train()\n",
    "    for x_batch, y_batch in tqdm(train_dl, leave=False):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_batch)\n",
    "        loss = F.cross_entropy(output, y_batch)\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # make a step\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = torch.max(output, 1).indices\n",
    "        acc = (pred == y_batch).sum() / y_batch.shape[0]\n",
    "        acc_log.append(acc.item())\n",
    "\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log, acc_log\n",
    "\n",
    "\n",
    "# TODO: write a validation function\n",
    "@torch.inference_mode()\n",
    "def test(model):\n",
    "    loss_log, acc_log = [], []\n",
    "    model.eval()\n",
    "\n",
    "    for x_batch, y_batch in tqdm(test_dl, leave=False):\n",
    "        output = model(x_batch)\n",
    "        loss = F.cross_entropy(output, y_batch)\n",
    "\n",
    "        # compute gradients\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "        \n",
    "        pred = torch.max(output, 1).indices\n",
    "        acc = (pred == y_batch).sum() / y_batch.shape[0]\n",
    "        acc_log.append(acc.item())\n",
    "\n",
    "    return loss_log, acc_log\n",
    "\n",
    "\n",
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "\n",
    "    plt.title('{} at {} epoch'.format(title, epoch))\n",
    "    plt.plot(train_history, label='train', zorder=1)\n",
    "    \n",
    "    points = torch.tensor(val_history)\n",
    "    \n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cf94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "train_log, train_acc_log = [],[]\n",
    "val_log, val_acc_log = [],[]\n",
    "\n",
    "model = Net().to(\"cuda:2\")\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.0005, momentum=0.95)\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train(model, opt)\n",
    "    val_loss, val_acc = test(model)\n",
    "    \n",
    "    # store metrics\n",
    "    # <your code>\n",
    "    train_log.extend(train_loss)\n",
    "    train_acc_log.extend(train_acc)\n",
    "    \n",
    "    val_log.append((steps * (epoch + 1), mean(val_loss)))\n",
    "    val_acc_log.append((steps * (epoch + 1), mean(val_acc)))\n",
    "    \n",
    "    # plot all metrics (loss and acc for train/val)\n",
    "    # <your code>\n",
    "    clear_output()\n",
    "    plot_history(train_log, val_log)    \n",
    "    plot_history(train_acc_log, val_acc_log, title='accuracy')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90163dbe",
   "metadata": {},
   "source": [
    "### More:\n",
    "Also with all links from above:\n",
    "- https://pytorch.org/tutorials/\n",
    "- https://pytorch.org/ecosystem/\n",
    "- Pytorch examples - a repo that implements many cool DL models in pytorch - https://github.com/pytorch\n",
    "- More on new pytorch data-loading - https://github.com/pytorch/data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (DimaKoshman)",
   "language": "python",
   "name": "pycharm-39683df4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
