{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c996af0",
   "metadata": {},
   "source": [
    "### Случайность в моем понимании.\n",
    "\n",
    "В учебниках по теории вероятности случайность обычно определяют одним из двух способов: либо как врожденное свойство, присущее неопределенным процессам (\"...процессы, с которыми они \\[вопросы случайного характера\\] связаны , по самому их существу лишены полной определенности.\" - Гнеденко), либо как субъективную уверенность в верности суждения (байесовский подход). Второй способ не обладает надежной общей объективной базой, на которой можно было бы строить дальнейшую теорию. В первом же я не согласен с утверждением, что существуют неопределенные процессы. Ведь по мере развития науки во всех областях предсказания процессов становятся все точнее: то, что раньше описывалось вероятностно, теперь либо описывается точно, либо по крайней более точно, чем раньше. То есть заметна сильная тенденция по равномерному сокращению роли случайности в разрезе решений фиксированной задачи. Я не знаком ни с одним неопределенным процессом, в том смысле, что если зафиксировать все переменные и запустить процесс, то он может закончиться разными исходами. Единственное исключение - квантовая физика, но я уверен, что, поскольку это относительно новая область науки, то случайность там, как и прежде в других областях, используется как временное понятие, и на самом деле в этих процессах есть какая-то определенность, еще не обнаруженная в связи с ограничениями экспериментальных измерений или развитием теории. То есть поскольку наука постоянно развивается, у нее неизбежно будет существовать рубеж, на котором по определению нет других вариантов, кроме как объяснить происходящее случайностью. Эти наблюдения приводят меня к убеждению, что случайность - это чисто человеческое абстрактное понятие, не имеющее дословного воплощения в реальности, поэтому я не могу согласиться с утверждением, что существуют неопределенные по своему существу процессы. Поэтому я решил взяться за формулирование своей интерпретации случайности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92099dd",
   "metadata": {},
   "source": [
    "Что называют случайностью? От чего она возникает? В моем текущем представлении о мире, мир является детерминистичным по времени процессом. С точки зрения человека, мир в любой момент времени t $\\in \\mathbb{R}$ можно описать (несчетным) набором признаков: положения тел (функция $\\mathbb{R}^3 \\rightarrow \\{\\text{множество типов элементарных частиц}\\}$), их скорость, ускорение, ускорение ускорения итд; температура тел; состояние магнитного поля итд. Перечислить этот набор, или даже просто описать его, возможно и нельзя, но мне кажется разумно предположить, что он все-таки существует. Возьмем этот набор, добавим в него время, и получим, без потери общности, что мир - это подмножество декартова произведения бесконечномерных вещественнозначного, счетнозначного и конечнозначных пространств, которое гомоморфно просто бесконечномерному вещественнозначному пространству $\\mathbb{R}^{\\infty}$. Назовем это объемлющее множество вселенной $U$, а наш мир обозначим как $W$. Почему же я выделил время как какой-то особенный признак? Потому что мир не есть произвольное подмножество, это подмножество подчиняется правилам, таким как законы Ньютона, Архимеда, и в нем сохраняются инварианты, такие как сохранение энергии, массы. И так получилось, что в нашем мире время - это очень удобная независимая переменная, поскольку с точки зрения людей время движется равномерно и непрерывно, а также, что важно, если время стоит, то мир не меняется, то есть время однозначно определяет состояние мира. Тогда можно описать мир как такое множество $W\\subset U$, что: состояние мира сейчас принадлежит этому подмножеству: $x_{\\text{now}} \\in W$; проекция $W$ на временную ось есть инъективная функция, то есть проекция $W$ на время: $f_t(x) = x_t$ есть биективная на своем прообразе функция; и мир $W$ подчиняется инварианту $f_I$ в том смысле, что $f_I$ - функция на $U$, и $\\forall x_1, x_2 \\in W: f_I(x_1) = f_I(x_2) =: f_I(W)$. Именно биективность времени позволяет называть мир детерминистичным по времени процессом. Но на самом деле это свойство тоже можно включить в инвариант, сказав, что $f_I$ представима в виде $f_I(x) = F(f_t(x))$, где $F$ инъективна. Определим функцию, разбивающую подмножество вселенной на миры как $F_I: \\mathcal{P}(U) \\rightarrow \\mathcal{P}^2(U), F_I(S) = \\{ g \\subset S| \\forall x_1,x_2 \\in g : f_I(x_1) = f_I(x_2)\\} = G$. То есть моя модель абстрактного мира выглядит так: выбирается вселенная $U$, на ней выделяется множество законов, по которым этот мир существует, или, что (вроде бы) эквивалентно, инвариант $f_I$, который разбивает по своим значеним вселенную на миры - классы эквивалентности $F_I(U) = G$, и наш мир - $W\\in G: x_\\text{now} \\in W$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40b0db",
   "metadata": {},
   "source": [
    "Отсюда возникает вопрос: если состояние мира и правда однозначно определяется всего лишь одной переменной - временем, то откуда берется случайность? Почему понятие случайности стало нужным? Сначала заметим, что человек, даже с использованием компьютера, не может работать не то чтобы с бесконечномерным подпространством, но и счетным, и даже с подпространством уж слишком большой размерности. Это приводит к двум вещам: во-первых, человек не ставит перед собой задачу предсказать состояние $W$ в какой-то момент времени, а ограничивается какими-то понятными агрегациями. Простейший вид агрегаций - бинарный, например, когда задается вопрос, произойдет или нет какое-то событие, где под словами \"произойдет событие\" подразумевается, что дано какое-то подмножество вселенной $U$, например $S = \\{x\\in U | \\text{ температура в Баку превысит 30 градусов в следующем месяце }\\}$, и нас интересует $S \\cap W = \\emptyset$? Или более сложные вещественнозначные агрегации, такие как \"с какой скоростью нужно стартовать с орбиты, чтобы улететь из солнечной системы?\" и \"сколько времени прослужит этот реактивный двигатель?\". С первой точки зрения, оба последних вопроса довольно сложные, но при этом на первый ответ человечество может дать ответ гораздо большей точности, чем на второй. В чем же принципиальное различие этих вопросов? Это подводит нас ко второму следствию чрезмерной сложности реального мира: мы не можем напрямую работать ни с множеством $W$, ни даже с каким-то счетным его подмножеством. Человек моделирует мир в своей голове, или с помощью компьютера, или математической модели, и вследствие ограничений этих инструментов, он обязан сократить размерность реального мира при переносе его на модель, где-то огрубить, какие-то данные просто не доступны, какие-то следует умышленно отбросить, чтобы модель не оказалась черезчур сложной и чтобы она была полезной и удобной. На математическом языке это звучит так: что существует некая функция $f_{gv}^t: G \\rightarrow \\mathbb{R}^n$, которая отображает наш мир в множество наблюдений, или знаний, на момент времени $t$. Буду называть такие функции функциями наблюдений, а их значения - просто наблюдениями (не путать с так называемыми наблюдениями случайной величины, которые я позже назову реализациями). Заметим, что поскольку мир $W$ содержит все свои состояния во все моменты времени $t$, то зависимость от времени, если такая есть, нужно включать в функции. Например, когда шахматист думает, как сходить, его функция наблюдений скорее всего будет собирать информацию о последних k ходах, сколько времени у него осталось, состояние оппонента и иные факторы, имеющие отношения к игре. Он отбрасывает знания и мысли о том, какая сейчас погода за окном, во сколько обойдется такси до дома. Но в не зависимости от конкретной функции наблюдения, все они будут обладать одним свойством - они не инъективны. То есть часть информации о мире теряется при переходе от мира $W$ к наблюдениям $V = f_{gv}^t(W)$, и становится невозможно точно восстановить состояние мира по его наблюдениям. Так вот, я утверждаю, что невозможность восстановить состояние мира по наблюдениям и следует понимать как случайность. Например, если кто-то смотрит в окно во время вышеописанной шахматной партии, и ему задать, идет ли сейчас дождь, то он точно ответит - да или нет, с его точки зрения, или с точки зрения его функции наблюдения, событие, что сейчас идет дождь не является случайным, а детерминированным. С точки зрения же шахматиста, если он не обращал внимание на погоду, то для него этот же вопрос является вероятностным. Для него неразличимы те состояния мира, а точнее, в моей модели, разные миры $\\hat W$, похожие на наш, в том смысле, что дают такие же наблюдения $f_{gv}^t(W) = f_{gv}^t(\\hat W)$ с точки зрения функции наблюдения шахматиста, но с разной погодой. И его ответ будет отражать его уверенность, или его оценку вероятности, что сейчас идет дождь."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08915c34",
   "metadata": {},
   "source": [
    "Приведу еще пример: подбрасывание монетки считается эталоном случайного события. Но если бы за подбрасыванием монетки наблюдала камера замедленной съемки и ее данные передавались в физическую симуляцию, то в момент последнего контакта руки с монеткой, программа даст почти точный ответ, какой стороной монетка приземлится на пол. Значит ли это, что монетка перестала быть случайной в полете? Но с точки зрения человека, наблюдающего за подбрасыванием, исход становится известен только после приземления монетки. Моя интерпретация случайности дает ответ на этот вопрос: у компьютера во время полета монетки был доступ к хорошей дискретизирующей функции наблюдения, а у человека - нет, поэтому и их оценка случайности события соответственно различаются. Остается вопрос - если у человека был бы доступ ко всем необходимым данным для расчета траектории монетки, как бы это повлияло на его представление о случайности монетки? Здесь уже зависит от того, где проводить границу между функцией восприятия и решения. Если функция восприятия такая же, как у компьютера - то случайности нет, и человек ошибается из-за незнаний законов физики. А если считать, что человек не воспринимает эти данные, то его функция восприятия сокращается до той информации, которую он извлекает из наблюдений, и случайность сохраняется.\n",
    "\n",
    "Чтобы развить эту интерпретацию вероятности, и придать ей конкретный смысл, сформулируем ее математически и проведем параллели с теорией вероятности, как она толкуется в учебнике Гнеденко."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1d630d",
   "metadata": {},
   "source": [
    "Пусть нам дана вселенная $U \\subset \\mathbb{R}^n$, инвариант $f_I: U\\rightarrow \\mathbb{R}^m$ и функция наблюдения $f_{gv}: \\mathcal{P}(U) \\rightarrow \\mathbb{R}^k,\\, n >> k$. Cобираются наблюдения о нашем мире $f_{gv}(W) = V$. Берется полный прообраз наблюдений $V$ и разбивается на миры: $F_I(f_{gv}^{-1}(V)) =F_I(f_{gv}^{-1}\\circ f_{gv}(W)) = G$.\n",
    "\n",
    "Тогда $G$ есть множество элементарных событий. Алгебра событий - алгебра $\\mathfrak{S}_G$, порожденная $G$. Такая алгебра существует, поскольку элементы $G$ не пересекаются как классы эквивалентности по функции $f_I$. Вероятностная мера зависит от вселенной $U$, но в случае $U \\subset \\mathbb{R}^n$, это просто нормализованная мера Лебега. Вероятность события $S \\subset G: P(S) = \\frac{|S|}{|G|}$. С учетом того, что модель вселенной можно сделать достаточно обширной, чтобы она годилась для почти любой практической задачи, и того, что инвариант и наш мир фиксирован, а вероятностная мера подбирается для вселенной, то на практике вероятностное пространство порождается только функцией наблюдения.\n",
    "\n",
    "Введем понятие функции решений $f_{vy}$ для фиксированных случайной величины $f_{gy}$ и функции наблюдений $f_{gv}$ как $f_{vy}: V \\rightarrow \\mathbb{R}$, где композиция $f_{vy}\\circ f_{gv}$ приближает случайную величину $f_{gy}$ в смысле некоторой меры качества $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920acdc2",
   "metadata": {},
   "source": [
    "Конкретизируем вселенную $U$, для этого поймем, в каком множестве лежат состояния нашего мира $W$. Будем моделировать его окрестностью из $n$ ближайших к Земле атомов, или в более общем случае, элементарных частиц. Каждую частицу будем описывать $a$ параметрами, такие как ее тип, положение, заряд, масса, скорость, вращение и так далее. Добавив в модель время $t$, и ограничив значения, которые могут принимать координаты, получим в качестве вселенной многомерный прямоугольник $U = \\{x \\in \\mathbb{R}^{na + 1} |\\text{ первая координата $x^0$ - время, дальше координаты элементарных частиц }, x^i \\in [u^\\text{low}_i, u^\\text{high}_i], i \\in[ 0\\dots an]  \\}$. А наш мир принимает вид: $W = \n",
    "\\{x \\in U | f_I(x) = c_W, x_\\text{now} \\in W \\}$. Но чтобы говорить о координатах, нужно указать систему отсчета. Для определенности возьмем за 0 по времени начало нашей эры, за центр трехмерных (неинерциональных) координат - центр массы Земли, причем первая ось совпадает с северным направлением, вторая - по направлению к точке на земной поверхности с широтой и долготой 0, а третья ось выбрана так, чтобы ориентация ортогональных осей была правой. В качестве единиц измерения возьмем метрические единицы.  Учитывая функциональность относительно времени миров, порожденных инвариантом $f_I$, каждый мир можно представить в виде $W = \\{(t, x) \\in U| t\\in \\mathbb{R}, x\\in \\mathbb{R}^{na}, x = f_W(t)\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcfa47c",
   "metadata": {},
   "source": [
    "Хорошо, а как в такой интерпретации измерить случайность? Как сравнить две случайные величины и прикинуть, какая из них более случайна, чтобы как-то упорядочить случайные величины, придать им понятные характеристики? С этой целью предлагаю определить меру случайности следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032fda4a",
   "metadata": {},
   "source": [
    "Пусть нам дано множество событий $G$, вероятностная мера $|G| = \\int_G dg$, функция наблюдения $f_{gv}$ и случайная величина $f_{gy}$. В случае дискетного $G$ определим меру случайности следующим образом:\n",
    "\n",
    "$$Chance(G, f_{gy},f_{gv}) = \\cfrac{\\sum_{g_1, g_2 \\in G} [f_{gy}(g_1) \\neq f_{gy}(g_2)] [f_{gv}(g_1) = f_{gv}(g_2)]}{|G|^2}$$\n",
    "\n",
    "Заметим, что если $\\exists f_{vy}: \\forall g \\in G: f_{gy}(g) = f_{vy}(f_{gv}(g))$, то $Chance=0$, то есть значения случайной величины можно восстановить по значениям функции наблюдений. А максимальное значение $Chance$ для фиксированной случайной величины достигается при $f_{gv} = const$, и равно \n",
    "\n",
    "$$\\max Chance = \\cfrac{\\sum_{g_1, g_2 \\in G} [f_{gy}(g_1) \\neq f_{gy}(g_2)]}{|G|^2}=\n",
    "\\cfrac{|G|^2 - \\sum_{g_1, g_2 \\in G} [f_{gy}(g_1) = f_{gy}(g_2)]}{|G|^2}=\n",
    "1 - \\sum_{c_i} (P(f_{gy} = c_i))^2\n",
    "$$\n",
    "\n",
    "где $c_i$ - множество значений случайной величины.\n",
    "\n",
    "Обобщая на несчетные множества событий, и на непрерывные случайные величины и функции наблюдений, получаем:\n",
    "\n",
    "$$Chance(G, f_{gy},f_{gv}) = \n",
    "\\cfrac{\\int_{g_1, g_2 \\in G}\n",
    "[f_{gy}(g_1) \\neq f_{gy}(g_2)] [f_{gv}(g_1) = f_{gv}(g_2)]\n",
    "d g_1 d g_2}{|G|^2}\n",
    "$$\n",
    "\n",
    "Заметим, что если $f_{gv}$ константна, а $f_{gy}$ принимает одинаковые значения только на множестве меры 0, то значение $Chance$ максимально. И наоборот, если $f_{gv}$ принимает одинаковые значения только на множестве меры 0, то есть локально обратима в каждой точке, то $Chance=0$ в не зависимости от агрегационной функции, и за функцию решения можно взять $f_{vy} = f_{gv}^{-1} \\circ f_{xy} $.\n",
    "\n",
    "Интуитивно можно сказать, что если функция наблюдений хорошо согласована со случайной величиной на данном множестве событий, то есть принимает разные значения одновременно со случайной величиной, то значение Chance будет низким."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bac7e1",
   "metadata": {},
   "source": [
    "Попробуем применить эту интерпретацию к вычислению вероятности выпадений чисел на кубике. Случайная величина - значение на верхней грани кубика при его остановке, $f_{gy}: G \\rightarrow \\{1,2,3,4,5,6\\}$, функция наблюдения - индикатор того, что произошел бросок кубика, $f_{gv}: G \\rightarrow [\\text{Кубик был брошен}]$. Нас не интересует, с какой высоты он был брошен, в какой ориентации и другие подробности. А вот множество событий играет определяющую роль – возьмем в его качестве множество бросков кубика во всех возможных ориентациях, с высоты до 2 метров, всевозможными ограниченными векторами скоростей и ограниченными осевыми вращениями, $G =\\{g \\in \\mathbb{R}^k | \\forall i = 1\\dots k: c_i^1 <= g_i <= c_i^2\\} $. Получившееся множество событий является компактом, и из симметрии кубика его можно разбить на 6 равных непересекающихся подмножеств, мера каждого из которых равна 1/6 меры совокупности, и по формуле вероятности тому же равны и вероятности всех выпадающих значений кубика, и $Chance = 1 - \\sum_{i=1}^6 (\\frac{1}{6})^2 = \\frac{5}{6}$. А что, если кубик несиммертичный, и в среднем четные числа выпадают в 2 раза чаще нечетных? То есть нам сразу дано, что $P(f_{gy} - \\text{четное}) = \\frac{2}{3}, (f_{gy} - \\text{нечетное}) = \\frac{1}{3}$,\n",
    "$Chance\n",
    "= \\cfrac{\\int_{g_1, g_2 \\in G}\n",
    "[f_{gy}(g_1) \\neq f_{gy}(g_2)] [f_{gv}(g_1) = f_{gv}(g_2)]\n",
    "d g_1 d g_2}{|G|^2}\n",
    "= \\cfrac{\\int_{g_1, g_2 \\in G}\n",
    "[f_{gy}(g_1) \\neq f_{gy}(g_2)]\n",
    "d g_1 d g_2}{|G|^2} = \\\\\n",
    "= \\cfrac{\n",
    "2|\\{g_1 - \\text{четное}, g_2 - \\text{нечетное}\\}| +\n",
    "2|\\{g_1, g_2 - \\text{четные, и } g_1 < g_2\\}| + \n",
    "2|\\{g_1, g_2 - \\text{нечетные, и } g_1 < g_2\\}|\n",
    "}{|G|^2} = \\\\\n",
    "= 2 \\cdot \\frac{2}{3} \\cdot \\frac{1}{3} +\n",
    "2 \\cdot C_3^2 \\cdot \\frac{2}{9} \\cdot \\frac{2}{9} + \n",
    "2 \\cdot C_3^2 \\cdot \\frac{1}{9} \\cdot \\frac{1}{9}\n",
    "= \\frac{4}{9} + \\frac{8}{27} + \\frac{2}{27} = \\frac{22}{27} = \\frac{5}{6} - \\frac{1}{54}\n",
    "$\n",
    "\n",
    "Исходя из значений Chance, случайность уменьшилась, что согласуется с интуитивными ожиданиями, а также в этих вычислениях можно увидеть сходства с энтропией."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539dd12e",
   "metadata": {},
   "source": [
    "А что можно сказать про так называемую статистическую устойчивость случайных событий? Например, почему, если подбрасывать монетку много раз, частота орлов сходится к 1/2? Здесь нужно вдуматься в сам вопрос. Что имеется в виду, когда говорится \"подбрасывать монетку много раз\"? Обычно это формулируют как \"возможность проведения неограниченной последовательности независимых испытаний в неизменных условиях\". Но, согласно моей точки зрения о детерминистичной картине мира, если бы условия действительно были бы неизменны, то и исход был бы один и тот же. Еще раз: исход эксперимента однозначно определяется начальными условиями. А какие начальные условия подразумеваются, когда говорится о подбрасывании монетки? Во-первых, монетку подбрасывает человек, и у того, как именно он это делает - с какой силой, в каком положении - тоже есть свое распределение, и даже если подбрасывать будет идеальный робот, он по крайней мере не сможет это делать в один и тот же момент времени, а если роботов будет несколько, то они будут отличаться хотя бы тем, что находятся в разных местах, для разных бросков будет разная структура воздуха, через который они летят, разное состояние магнитного поля. Все эти детали имеют значение, и без них задача не является корректно сформулированной. А корректно поставленный вопрос звучит так: почему, если подбрасывать монетку так, что частота орлов будет сходится к 1/2, частота орлов сходится к 1/2? В такой формулировке становится очевидным, что монетка здесь совсем не при чем, она просто транслирует распределение начальных условий эксперимента на его исход, она является индикатором, агрегационной функцией, или случайной величиной. Но сразу после такой переформулировки встает закономерный вопрос - а почему начальные условия имеют такое распределение? Можно попытаться как-то ответить на этот вопрос, но за ним неизбежно последует новый вопрос, и так далее, пока, как и в любой теории, не придется опереться на какие-то аксиомы или предположения, а качество самой теории, ее полезность и применимость, проверять экспериментально. Я считаю, что такой вопрос выходит за рамки теории вероятностей, и хоть какая-то информация о распределении начальных условий должна быть включена в формулировку задачи. Например, в данном случае с монеткой можно предположить, заглядывая вперед и опираясь на экспериментальные наблюдения, что сила, с которой подбрасывают монетку, высота падения, скорость вращения и все остальные факторы имеют нормальное распределение. Тогда, из-за непрерывности почти везде отображения состояния мира в исход эксперимента, симметрии монетки и чувствительности исхода эксперимента (если бы монетка была настолько тяжелой и инертной, что человек не смог бы ее закрутить, или отпускали монетку в 1 см от стола, к 1/2 не сходилось бы), получим объяснение наблюдаемой статистической устойчивости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3331da26",
   "metadata": {},
   "source": [
    "Во многих теоретических выводах предполагается, что мы имеем дело с так называемой последовательностью независимых одинаково распределенных случайных величин, в дальнейшем просто sequence. Получается, чтобы применять теоретические выводы, связанные с sequence, нужно определиться, что можно считать за sequence в реальном мире. Теория вероятностей и статистика часто применяется к наблюдениям одного и того же события в разные моменты времени - предсказание количества осадков на завтра, падение доллара ниже конкретного уровня в течение дня, диагностирование конкретного заболевания для разных людей. То, что мы наблюдаем одно и то же явление, дает уверенность, что случайные величины действительно одинаково распределены. Теоретически все такие sequence, состоящие из одного и того же наблюдения (случайной величины $f_i$) в разные моменты времени можно описать так: $\\forall i, j: \\exists  t_{ij}: f_i(g) = f_j(g + t_{ij})$, или, в несимметричной форме: $f_i(g) = f(g + t_{i})$. Попробуем построить модель, которая свяжет sequence в теории с практикой на примере задачи предсказания количества осадков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acece6fd",
   "metadata": {},
   "source": [
    "Нам дана функция наблюдения, которая отображает мир в релевантные для задачи наблюдения до момента времени $t$: $f_{gv}= f_{gv}^t: G \\rightarrow V\\subset\\mathbb{R}^d$, которые включают базовые наблюдения, которые присущи большинству задач и которые можно описать как коллективные память, представления и знания человечества о мире на момент времени $t$, и более конкретные наблюдения, имеющие отношение к предсказанию уровня осадков в каком-то месте к времени $t$, такие как освещенность за последнюю неделю, влажность и так далее. То есть нас интересуют все миры, которые с точки зрения человека на момент времени $t$ похожи до некоторой степени, например если в каком-то мире не существует Земли, или она в нем есть, но в 2 раза больше, то такие миры в генеральную совокупность не войдут. А вот миры, почти такие же как наш, но в которых Солнце на несколько километров ближе к Земле, или в которых вчера было незаметно больше облаков, войдут в генеральную совокупность. Также нам не подойдут миры, в которых на момент времени $t$ другое время суток, а вот те миры, которые ровно на год старше или моложе, можно взять. А точнее, в качестве генеральной совокупности возьмем $G =f_{gv}^{-1}(f_{gv}(W))$ и разобьем ее инвариантом $f_I$ на миры: $G = \\{g \\subset G | \\forall x_1,x_2 \\in g: f_I(x_1) = f_I(x_2)\\}$.\n",
    "\n",
    "Нам дана случайная величина $f_{gy}=f_{gy}^t: G \\rightarrow \\mathbb{R}$, отображающая миры в количество осадков на следующий день в определенном месте относительно времени $t$. Тогда возьмем последовательность случайных величин $f_i = f_{gy}^{t_i}$, измеряющих осадки в моменты времени $t_i$. В каком случае их можно считать за sequence?\n",
    "\n",
    "Во-первых, нужно, чтобы $f_i$ были одинаково распределены. Назовем множество тех $tt$, для которых распределение величины $f_{gy}^{tt}$ на $G$ совпадает с распределением $f_{gy}^t$, областью применения, и обозначим за $T$. Для предсказания осадков на следующий день в область применения войдут, очевидно, все те $tt$, которые находятся в одном дне с $t$ - для них следующий день просто совпадает. А дальше все зависит от множества $G$, или, что эквивалентно, от функции наблюдения. Если наблюдения не точные - например, мы просто прикидываем, нужно ли класть зонтик у прихожей на случай дождя завтра, то в $G$ окажется много миров с самыми разными уровнями осадков, и область применения окажется широкой, например любой день в текущем месяце в окрестности нескольких лет. А если мы предсказываем погоду для погодного сервиса, то примем во внимание показания множества датчиков по всему миру за последние недели, и $G$ заметно сузится, распределение $f_{gy}^t$ сконцентрируется, и соответсвенно область применения так и останется одним днем.\n",
    "\n",
    "Во-вторых, $f_i$ должны быть независимы в совокупности. Это требование сразу отсекает из области применения $T$ те $tt$, которые находятся с $t$ в одном дне. Предположим, что в мирах с нашим инвариантом можно считать, что если случайные величины вида $f_i(g) = f(g + t_{i})$ независимы попарно, то они почти наверняка независимы в совокупности, а два наблюдения независимы, если отстают друг от друга как минимум на $\\Delta t$. Дальше все также зависит от функции наблюдения. Если в наблюдениях не было количества осадков в прошлом, или зависимых с осадками наблюдений, то почти все дни из области применения можно брать в качестве $t_i$.\n",
    "\n",
    "Как видно, мне пришлось делать много предположений, чтобы связать теорию с практикой, что неудивительно, но позволяет сказать, что нет особого смысла в том, чтобы формулировать точные вероятностные теоремы, поскольку при их переносе на практику эта точность теряется в погрешностях и предположениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08128ad4",
   "metadata": {},
   "source": [
    "В итоге получаем, что для поставленной задачи нужно найти область применения $T$, а также выделить из этой области последовательность $t_i$, для которой величины $f_{gy}^{t_i}$ можно считать независимыми. В большинстве случаев  можно выделить такой минимальный порог $\\Delta t$, чтобы $t_{i+1}-t_i > \\Delta t$. Тогда в качестве sequence получаем $f_i(g) = f_{gy}^{t_i}(g) = f_{gy}^{t}(g + t - t_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb9ac6d",
   "metadata": {},
   "source": [
    "Здесь можно сказать, почему монетки и кубики так популярны - на их исход влияют очень локальные параметры по сравнению с другими экспериментами, вследствие этого у них все значения времени можно считать за область применения, а поскольку два броска практически не влиют друг на друга, то кидать их можно в любые моменты времени, и получать из них sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64343864",
   "metadata": {},
   "source": [
    "Здесь можно обратить внимание, что мы не строим точное множество событий $G$, которое позволило бы выводить свойства определенных на нем случайных величин. Этому есть несколько причин, во-первых это весьма сложная задача, а во-вторых, на практике мы отталкиваемся не от множества $G$, а просто принимаем как данное, что у нас уже есть случайные величины с какими-то свойствами, и что существует разумное множество событий, на котором эти свойства будут выполняться. А построение $G$ нас не интересует, так как оно не есть предмет изучения, и зачастую оно остается за кулисами. Но все же такие примеры, как парадокс Бертрана, показывают, что интуиция имеет довольно узкие границы применения, и следует держать в уме ту теоретическую конструкцию, которую мы используем для решения задач, и насколько она применима в том или ином случае."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e98ae5",
   "metadata": {},
   "source": [
    "Хочется понять на интуитивном уровне, почему нормальное распределение так часто встречается в наблюдениях. Согласно центральной предельной теореме, $S_n \\approx N(n\\mu, n\\sigma^2)$ при $n \\rightarrow \\infty$, где $S_n = \\sum_i^n \\xi_i$ - сумма iid случайных величин. Откуда появляется это распределение? Что в нем особенного? Какими уникальными свойствами оно обладает? Можно воспринимать нормальное распределение как пределельный переход биномиального распределения при $n \\rightarrow \\infty: Bin(n,p) \\approx N(np, npq)$. Рассмотрим дискретные случайные величины $\\xi_i$ с множеством значений $c_k$, тогда их можно разложить как сумму $\\xi_i(x) = \\sum_k^\\infty c_k [x \\in \\xi_i^{-1}(c_k)]$. Тогда $S_n = \\sum_i^n\\sum_k^\\infty c_k [x \\in \\xi_i^{-1}(c_k)]= \\sum_k^\\infty c_k \\sum_i^n[x \\in \\xi_i^{-1}(c_k)]= \\sum_k^\\infty c_k \\eta_k$, где $P(\\eta_k = a) = C_n^a p_k^a (1-p_k)^{n-a}, \\, p_k = P(x \\in \\xi_i^{-1}(c_k))$. Получается, что $S_n$ - взвешенная сумма биномиальных величин, $S_n = \\sum_k^\\infty c_k Bin(n,p_k)$ со средними $n p_k$ и дисперсиями $np_k(1-p_k)$, и при $n \\rightarrow \\infty$, эти биномиальные распределения сливаются в одно. Хочется здесь напомнить, что рассуждения здесь не претендуют на строгость, все это есть моя попытка связать теорию и интуицию, практику."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7c0d4",
   "metadata": {},
   "source": [
    "В программировании равномерное распределение можно симулировать целочисленной последовательностью: $a_i = b\\cdot (t_{\\text{now}} + i) \\text{ mod } c, \\gcd(b,c) = 1$, где $t_{\\text{now}}$ - текущее время, а стандартное нормальное распределение симулируется как $\\sqrt{-2\\ln a_i}\\cos(2\\pi a_{i+1})$. Как это чисто практическое решение согласуется с теорией?  Насколько верным будет утверждать, что $a_i$ - iid случайные величины с целочисленным равномерным распределением $U[0, c-1]$? Но ведь случайная величина - это функция, как она связана с членом последовательности? Иногда употребляется выражение \"реализация случайной величины\", может это оно и есть? Строгого математического определения реализации случайной величины я не смог найти, несмотря на популярность этого словесного оборота, поэтому предлагаю дать определение реализации случайной величины как значение случайной величины на определенном элементе генеральной совокупности: $f(g),\\, g \\in G$, то есть некорректно говорить о реализации случайной величины без указания элемента, на котором берется значение. Тем не менее там, где не сказано иначе, будем считать, что реализация берется на нашем мире, то есть элементе $W \\in G$. А последовательность $a_i$ можно превратить в последовательность функций, если рассматривать функции от функций $f_i(f) = f(i)$, и $a_i$ - это реализация этой последовательности на функции $f(i) =  b\\cdot (t_{\\text{now}} + i) \\text{ mod } c$, а за элементарные события взять некоторое множество функций, например параметрическиое семейство функций вида $f$ с параметрами $b,c$.\n",
    "\n",
    "Пусть мы рассматриваем последовательность таких случайных величин $f_i$. Но ведь она же однозначно определена, детерминирована относительно параметров $b,c$ и времени $t_\\text{now}$? Но в моем представлении она ничем не отличается от любой другой случайной величины - подбрасывания монетки, например - все они детерминированы, если знать начальные параметры и функцию отображения этих параметров в значение случайной величины. Просто для обычных случайных величин параметров много и функция сложная, но принципиально они не отличаются от $f_i$. Здесь, как и в случае с монеткой, все зависит от функции наблюдения - если знать функцию и параметры, случайности нет. А если человек не знает ни того, ни другого, или даже хотя бы параметров $b,c$, то с его точки зрения $f_i$ действительно является sequence. Еще раз - свойство последовательности быть sequence зависит от множества событий, поэтому одни и те же случайные величины могут для разных функций наблюдений быть sequence, или же диаметральной противоположностью - детерминированными функциями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa15ee7",
   "metadata": {},
   "source": [
    "Здесь следует провести параллель с тем, что в учебнике Гнеденко называется результатами наблюдений $x_1,x_2,\\dots x_n$ некоторой случайной величины $\\xi$. Что это означает в моей интерпретации? Ведь если случайная величина фиксирована, то на нашем мире она всегда будет давать одно и то же значение. Я утверждаю, что на самом деле в экспериментах мы имеем дело не с одной случайной величиной, а с последовательностью $\\xi_1,\\xi_2,\\dots \\xi_n$, предположительно представляющую sequence, которые обычно по времени и/или по пространству отличаются друг от друга: $\\xi_i(W) = \\xi_j(W +\\Delta t_{ij} +\\Delta s_{ij})$, и $x_i$ - их значения на нашем мире $W$. Либо можно проделать такое преобразование, что, например, время превратится из параметра функции в координату элементарных событий, и тогда случайная функция действительно будет фиксирована, и $x_1,x_2,\\dots x_n$ - это значения этой случайной функции на некоторых элементарных событиях $\\tilde W_i = (W, t_i) \\in U \\times R$, где $t_i$ означает время, в которое вычисляется случайная величина, $f_{gy}^t(W) = f_{gy}(W, t)$. Такое преобразование будет оправдывать упоминание лишь одной случайной величины $\\xi$, но тогда это не будет вязаться с теоретическими выводами, где почти всегда негласно работают с sequence и их значениями, а не с последовательностью элементарных событий, поэтому я буду придерживаться первой интерпретации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e67cd",
   "metadata": {},
   "source": [
    "На практике невозможность предсказать реализацию следующего элемента последовательности приравнивается к независимости, а точнее если распределение любой случайной величины оценивается одинаково с учетом знаний реализаций предыдущих величин. (Как это согласуется с теорией?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a933c8",
   "metadata": {},
   "source": [
    "В данном случае значения функции без знания вида самой функции трудно предсказать, пока значения не начнут повторяться. И даже зная форму функции, система уравнений $a_i = bi \\text{ mod } c ,\\, i \\in [1 \\dots k]$ относительно $b,c$ имеет много решений, поэтому без знаний $b,c$ и до приближения к периоду с точки зрения человека она все равно что sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af33e3",
   "metadata": {},
   "source": [
    "$t_\\text{now}$ - нужно для того, чтобы разные последовательности были независимы между собой, а не члены последовательности. Иначе если в функцию наблюдения входили бы предыдущие последовательности, то с точки зрения этой функции последовательность уже не sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f74a39",
   "metadata": {},
   "source": [
    "А чем нас не устраивает константная функция в качестве эмуляции равномерной? Это связано с тем, что большинство знаний людей тоже на самом деле не являются детерминированными. Например, если спросить кого-то, какой диаметр Земли, человек скорее всего ответит примерно x километров, подразумевая не то, что диаметр Земли (средний) в точности равен x, а то что x есть математическое ожидание диаметра Земли как случайной величины на окрестности нашего мира, являющейся прообразом его знаний о мире, то есть его функции наблюдения, а распределение имеет вид, близкий к нормальному. Также и с последовательностью случайных величин. Перед тем, как человек увидит реализации этих случайных величин, у него есть некие априорные знания об этих величинах, которые тоже в свою очередь являются случайными величинами. Возьмем подбрасывание монетки, и два варианта - первый, что до эксперимента человек сам подбрасывал монетку, и из 10 раз у него выпало 5 орлов, и второй вариант - что ту же самую монетку ему только что дал известный шулер. Оценка вероятности выпадения орла в первом варианте будет иметь примерно форму нормального распределения с центром в 0.5 и малой дисперсией, тогда как во втором варианте вероятность выпадения орла будет иметь примерно форму бета-распределения с центром в 0.5 и большой дисперсией. Далее человек подбрасывает монетку 10 раз, и орел выпал 0 раз. В первом варианте человек будет более склонен считать, что это просто случайность(???), и почти не изменит свое представление о вероятности орла, тогда как во втором случае апостериорное бета-распределение сильно сместится в сторону нуля. Вот мы и подошли к байесовской интепретации вероятности, а точнее пусть у нас в начале есть так называемое априорные знания, или априорное распределение вероятности, с учетом того, что знания есть случайная величина. Мы наблюдаем реализации каких-то случайных величин на нашем мире, что как-то меняет наши знания, а точнее нашу функцию наблюдения, после чего наши знания обновляются до апостериорных. Или точнее, в каждый момент времени $t$ и для каждого человека $h$ есть функция наблюдения $f_{gv}^{ht}$, которая порождает генеральную совокупность: $G_{ht} = F_I((f_{gv}^{ht})^{-1}(f_{gv}^{ht}(W)))$, $P_{ht}(A) = \\cfrac{|A \\cap G_{ht}|}{|G_{ht}|}$. Пусть эксперимент, в данном случае это десять подбрасываний монетки, начался в момент времени $t_0$ и закончился в $t_1$, тогда априорная вероятность - это вероятность $P_{ht_0}$, апостериорная - $P_{ht_1}$. Рассмотрим событие $A$ - что монетка при подкидывании в какой-то любой момент приземлится орлом, и событие $B$ - наш эксперимент, а точнее, что монетка выпала орлом 10 раз подряд. Тогда предполагается, что апостериорная вероятность преобразуется по закону Байеса: $P_{ht_1}(A)=\n",
    "P_{ht_0}(A|B)=\\cfrac{P_{ht_0}(A\\cap B)}{P_{ht_0}(B)}$. Пусть наши априорные знания состоят в том, что у нас есть плотность распределения вероятности орла $f(p)$, тогда с учетом независимости бросков кубика, получаем: $\\cfrac{P_{ht_0}(A\\cap B)}{P_{ht_0}(B)} = \\cfrac{\\int_0^1 p^{11}f(p)dp}{\\int_0^1 p^{10}f(p)dp}$. Посмотрим, как это согласуется с нашей моделью. В первом случае вероятность выпадения орла распределена примерно нормально, $f_1(p) \\approx \\cfrac{e^{-\\frac{1}{2} (\\frac{x-0.5}{\\sigma})^2}}{\\sigma\\sqrt{2\\pi}}$, во втором - по бета-распределению, $f_2(p) = p^{2\\beta - 1}(1-p)^{\\beta -1}$. Рассмотрим предельный случай - когда в первом случае мы очень уверены в честности монетки, тогда $f_1(p)$ вырождается в $\\delta(p-0.5)$, $P_{ht_1}(A) = \\frac{0.5^{11}}{0.5^{10}} = 0.5$, то есть наши знания не изменятся. И еще один предельный случай - когда во втором варианте мы абсолютно не уверены в наших знаниях, и распределение вырождается в $U[0,1]$, $P_{ht_1}(A) = \\frac{1}{1} = 1$, то есть наши знания сформировались только исходя из эксперимента, и мы думаем, что монетка всегда приземляется орлом. Эти согласованные с интуицией результаты поддерживают байесовский подход к вероятности. Возвращаясь к константной функции в качестве эмуляции равномерной - здесь все зависит от наших априорных знаний - функции наблюдений $f_{gv}^{t_0}$, и того, как часто она меняется по мере реализаций последовательности случайных величин. То есть если мы изначально не были уверены в равномерности распределения, увидели первые 10 одинаковых значений, то наша апостериорная оценка распределения уже не будет равномерной. Если же мы верим в равномерность распределения, то даже после первых наблюдений будем ожидать, что все-таки с какого-то момента реализации начнут равномерно распределяться."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79739013",
   "metadata": {},
   "source": [
    "У меня еще остается вопрос про непрерывные случайные величины. Для непрерывных величин вероятность любой реализации равна нулю, и тем самым любая последовательность реализаций равновероятна. Получается, что теория говорит, что вероятность последовательности реализаций $[1000, 1000, 1000]$ независимых стандартных нормальных распределений так же вероятна, как последовательность $[0, 0.01, -0.1]$? Как это согласуется с практикой, интуицией? Хочется доопределить вероятность реализации как плотность распределения в этой точке, но разве это не сломает теорию? Возможно, здесь проблема в том, что человеку трудно воспринимать все, что связано с бесконечностью, и значения непрерывных функций относятся к этой категории. Если бы мы рассматривали вероятность того, что реализация будет лежать в окрестностях перечисленных точек, то теоретические результаты были бы согласованы с интуитивными. Такой подход обоснован, ведь мы и правда всегда работаем с погрешностями вещественных чисел. Что еще мы можем сделать - это определить отношение вероятности двух элементарных событий как отношение их вероятностей или значений функции плотности в них. Тогда отношение вероятности позволит нам сказать, что первая последовательность менее вероятна, чем вторая, в случае нормального распределения. Или можно предполагать, что мы всегда работаем не с точными числами, а с окрестностями вокруг чисел с радиусом в некоторую погрешность, тогда вероятности наблюдений будут ненулевые."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b4f2bc",
   "metadata": {},
   "source": [
    "Проведем следующий мысленный эксперимент. Построим следующую чепочку: есть монетка, человека спрашивают, какой стороной она приземлится, он говорит орлом. После чего его спрашивают, насколько он уверен в своей оценке, и тут появляется вероятность, он говорит 50 на 50, то есть вероятность орла равна 1/2. А что будет, если спросить, насколько он уверен, что вероятность равна 1/2? По логике опять должна возникнуть вероятность. И что я бы ответил на такой вопрос? Вроде бы нельзя сказать абсолютно уверен, может эта нечестная монетка, и абсолютно не уверен тоже, потому что это противоречит моему первому ответу - зачем я сказал 1/2, если этот ответ ничем не лучше любого другого? То есть это должно быть число от 0 до 1, может это 1/2? На самом деле этот вопрос некорректно поставлен по той же причине, почему парадокс Бертрана является парадоксом - на вопрос нельзя однозначно ответить, пока не определено вероятностное пространство, а в этом случае нет естественного продолжения вероятностного пространства на множестве вероятностней. Рассмотренный пример может служить очередным напоминанием, что хоть вероятность и опирается на интуицию и предположения при применении теории на практике, все же надо быть аккуратным и проверять, что теоритическая модель согласована с реальностью."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c394634",
   "metadata": {},
   "source": [
    "В чем разница между уверенностью, про которую говорят в байесовском подходе, и вероятностью? Поскольку я не нашел принципиальной разницы, то я, следуя Оккаму, буду считать уверенность и вероятность синонимом, но уверенность на самом деле лучше раскрывает суть дела, поскольку она подразумевает, что вероятность субъективна, что верно, поскольку вероятность зависит от субъективной функции восприятия."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f30e5",
   "metadata": {},
   "source": [
    "Также я хочу прояснить путаницу, которая возникает при определении выборки и статистики. С одной стороны, утверждается, что выборка - это множество элементов генеральной совокупности, с другой - что это последовательность случайных величин. Я буду придерживаться второго определения, а точнее, что выборка - это по умолчанию sequence, но возможно, без свойства независимости, если это отдельно оговорено. А статистика - это функция на реализации выборки $s:\\mathbb{R}^n \\rightarrow \\mathbb{R}$, то есть строго говоря, это не есть случайная величина. Но это можно легко исправить, если рассматривать не саму статистику, а композицию из статистики и выборки, то есть $s^*(W) = s(\\xi_1(W),\\dots ,\\xi_n(W))$, и тогда $s^*$ уже будет случайной величиной. Чтобы отличить $s^*$, буду называть ее выборочной статистикой, а чтобы указать, что речь идет о значении этих функций на нашем мире - добавлять в начале слово \"реализация\". Но для удобства и там, где из контекста ясно, о чем идет речь, буду называть все эти четыре сущности статистиками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901223d",
   "metadata": {},
   "source": [
    "Так все-таки, как реализации связаны со случайной величиной? Что мы вообще про них знаем? Как вероятность связана с частотой появления? Если мы ожидаем, что гистограмма реализаций будет в каком-то смысле повторять функцию распределения, разве это не противоречит тому, что в каждом отдельном эксперименте вероятнее всего наблюдать моду? А как же то, что любой исход непрерывной величины имеет вероятность ноль, выходит, что все исходы равновероятны, как это соотносится с интуицией?\n",
    "\n",
    "На самом деле про реализации сказать ничего конкретно нельзя, кроме области, в которой они лежат. Теория вероятности не может ответить на вопрос, в формулировке которого нет слова \"вероятность\". И чтобы применять ее на практике, необходимо делать теоретически необоснованные предположения и формулировать задачи исходя из субъективных представлений. И это нормально, ведь теория это просто инструмент, и насколько бы идеальным не был инструмент, он бесполезен, пока не будет использован в неидеальных условиях. Конечно, чем обширнее применение инструмента и чем он точнее, тем лучше, но все же инструмент это лишь один из звеньев цепочки достижения какой-то цели, а цепь не надежнее своего слабейшего звена. Поэтому мало смысла добиваться от теории вероятности точных ответов, если для формулировки запроса пришлось делать субъективные, неточные предположения. Развитие теории безусловно полезно, но относительно малоэффективно, если другие звенья цепи, такие как формулировка адекватной (бизнес) задачи, сбор данных и оценка качества, являются более слабыми. Поэтому не стоит брезговать переносить строгие выводы теории вероятности на реальные задачи, делая это на основании лишь собственной интуиции, ведь зачастую другого варианта просто нет.\n",
    "\n",
    "Возвращаясь к вопросу о связи вероятности с частотой, и о гистограмме, то большинство выводов, таких как ЗБЧ, ЦПТ, теоремы Маркова, Бернулли, Пуассона, Колмогорова, связаны с пределами, то есть бесконечностью. А все, что связано с бесконечностью, в принципе неприменимо на практике, не доказуемо экспериментально, и это можно сказать не только про теорию вероятности, но в первую очередь про матанализ, например пределы, непрерывность, асимптотические оценки, и также множество иных неконструктивных выводов, которые только доказывают существование чего-то, но не предоставляют построение, например теорема Лагранжа. И есть качественно другой класс конструктивных выводов, таких как неравенство Чебышева, правило дифференцирования композиции функций, ортогонализация Грама - Шмидта, которые прямо применимы на практике. В чем же тогда ценность связанных с бесконечностью выводов? Ведь на практике всегда может случиться так, что пренебрежение асимптотически малыми оценками выйдет боком. А как вынести пользу из неконструктивных выводов? Выходит, что они в принципе не предназначены для практики, а только для общего понимания, интуиции. Выходит, что теория вероятности не является чем-то из ряда вон выходящим в том смысле, что в ее выводах присутствует неопределенность, просто в теории вероятности она выходит на первый план, является объектом изучения, тогда как в других областях она скрыта в таких понятиях, как бесконечность и существование. И в бесконечности же лежит ответ на вопрос про нулевую вероятность исходов непрерывной величины - непрерывность связана с бесконечностью, а значит интуиция здесь может не работать, и равновероятность исходов хоть и кажется странным, но ничему не противоречит. То же можно сказать про гистограмму - в случае со случайными величинами с конечным образом, повторение моды не будет самым вероятной последовательностью реализаций, поскольку гистограмма - симметрическая функция, и попадает под ЗБЧ, и там все понятно расписывается через число сочетаний. С непрерывными же величинами все исходы имеют вероятность ноль, поэтому нельзя сказать, какой набор исходов наиболее вероятен."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feca6c1",
   "metadata": {},
   "source": [
    "Вообще теория вероятности предназначена для оценки вероятностей каких-то событий, и на практике это полезно в первую очередь для принятия решений. А если задача стоит более конкретно как предсказание каких-то событий, то на языке теории вероятности это звучит как оценка распределения случайной величины, и этим занимается статистика. На практике типичные задачи статистики можно описать так:\n",
    "\n",
    "1. Дано конечное количество реализаций sequence $Y = \\{y_i\\}, \\, y_i = f_{gy}^i(W) = f_{gy}(W +\\Delta t_{i} + \\Delta s_{i})$. Оценить распределение $f_{gy}$, построив некую функцию распределения $F_{gy}$.\n",
    "\n",
    "1. Даны соответствующие реализациям sequence наблюдения $V = \\{v_i\\}, \\, v_i = f_{gv}^i(W) = f_{gv}(W +\\Delta t_{i} + \\Delta s_{i})$. Построить функцию предсказаний $f_{vy}: V \\rightarrow Y$, такую, что композиция $f_{gv}\\circ f_{vy}$ приближает $f_{gy}$.\n",
    "\n",
    "На языке машинного обучения первая задача является задачей без учителя, вторая - с учителем. Заметим, что в таком виде задачи являются некорректно поставленными, поскольку непонятно, что значит оценить распределение, и что значит приблизить функцию. Обычно доопределение задач зависит от конкретного случая, и в конечном счете делается на основе интуитивных представлений. Зачастую формально задача доопределяется с помощью вещественнозначного функционала качества $Q_1(Y, F_{gy})$ в первой задаче и $Q_2(V, Y, f_{vy})$ во второй, и тогда мы ищем соответственно $F_{gy} = \\arg\\max Q_1(Y, \\cdot)$ и $f_{vy} = \\arg\\max Q_2(V, Y, \\cdot)$. Далее, часто предпологается, что нам дано некое параметрическое семейство, то есть функция $F_1(\\theta) = f_{vy}$ и $F_2(\\theta) = f_{gy}$, где $\\theta\\in \\mathbb{R}^n $, и задача сводится к нахождению максимума многомерной вещественной функции, и может решаться общими методами, не связанными со статистикой. Роль статистики же в этой задачи состоит в основном именно в определении параметрического семейства, то есть понимание статистики позволяет интуитивно выбирать подходящие семейства, и выборе функционала качества. Также статистика обладает набором удобных способов решений часто встречающихся на практике задач."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
