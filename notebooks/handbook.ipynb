{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5088d688",
   "metadata": {},
   "source": [
    "- [Packages](#Packages_)\n",
    "- [Tips](#Tips_)\n",
    "- [Markdown syntax](#Markdown_syntax_)\n",
    "- [Tex syntax](#Tex_syntax_)\n",
    "- [Python syntax](#Python_syntax_)\n",
    "- [Python styleguide](#Styleguide_)\n",
    "- [Jupyter extensions](#Jupyter-extensions,-magic)\n",
    "- [Utils](#Utils_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc6092b",
   "metadata": {},
   "source": [
    "### Packages <span id=Packages_></span>\n",
    "\n",
    "- [Parsimonious](https://github.com/erikrose/parsimonious) an explicit re alternative `string`\n",
    "- [Gradio](https://www.gradio.app/docs/interface) web apps for ml `app`\n",
    "- [Streamlit](https://streamlit.io) gradio alternative `app`\n",
    "- [Ray](https://docs.ray.io) a mid-level parallel processing package geared toward ml `parallel, monitor`\n",
    "- [Seaborn](https://seaborn.pydata.org) a higher level matplotlib `plot`\n",
    "- [Seaborn.objects](https://seaborn.pydata.org/tutorial/objects_interface.html) a composable approach to plotting `plot`\n",
    "- [Bokeh](http://bokeh.org) interactive plots `plot`\n",
    "- [Ruff](https://docs.astral.sh/ruff/integrations) a fast linter `lint`\n",
    "- [Uv](https://github.com/astral-sh/uv) a fast package manager `package manager`\n",
    "- [Poetry](https://python-poetry.org/docs/) poetic package manager `package manager`\n",
    "- [Pipreqs](https://pypi.org/project/pipreqs/) create requirements.txt for given project `package manager`\n",
    "- [Click](https://click.palletsprojects.com/en/8.1.x) a cli interfacer `cli`\n",
    "- [PyArrow](https://arrow.apache.org/docs/python/index.html) in-memory data analytics `data`\n",
    "- [Polars](https://docs.pola.rs/#key-features) faster pandas `data`\n",
    "- [Pydantic](https://docs.pydantic.dev/latest/) data validation tools `data`\n",
    "- [Dask](https://docs.dask.org/en/stable) parallel computing, works well with python ecosystem `parallel`\n",
    "- [Darts](https://unit8co.github.io/darts/) time series models `model, time series`\n",
    "- [PySpark](https://spark.apache.org/docs/latest/api/python/index.html) high load distributed pandas, works well with Apache ecosystem `parallel`\n",
    "- [Shap](https://shap.readthedocs.io/en/latest) ml interpretability `plot, monitor`\n",
    "- [Plotly](https://plotly.com/python/plotly-express/) `plot`\n",
    "- [Dash](https://dash.plotly.com) dashboards integrated with the plotly package `plot`\n",
    "- [Annoy](https://github.com/spotify/annoy) approximate nearest neighbors `cluster`\n",
    "- [Faiss](https://github.com/facebookresearch/faiss/wiki) similarity search and clustering `cluster`\n",
    "- [Sklearn](https://scikit-learn.org/stable) classic ml `model, math`\n",
    "- [Scipy](https://docs.scipy.org/doc/scipy/tutorial/index.html#user-guide) scientific python `model, math`\n",
    "- [Numpy](https://numpy.org/doc/stable/user/index.html#user) numerical python `model, math`\n",
    "- [Numba](https://numba.readthedocs.io/en/stable/user/index.html) compiled numerical python `parallel`\n",
    "- [Pytest](https://docs.pytest.org/en/7.3.x/how-to/index.html#how-to) testing framework `monitor, test`\n",
    "- [Tox](https://tox.wiki) testing environment orchestrator `test`\n",
    "- [Spacy](https://spacy.io) a pipeline-based production-oriented text processing library `nlp, model`\n",
    "- [Nltk](https://www.nltk.org) a rule-focused natural language library, providing tokenization, stemming, chunking, pos tagging, ner, grammatical tools, logical contructs, semantic analysis, and more. It is somewhat slow and documentation sucks `nlp, model`\n",
    "- [Gensim](https://radimrehurek.com/gensim/auto_examples/index.html#documentation) a nlp library with algorithms for topic modeling, text encodings, word and document similarities `nlp, model`\n",
    "- [Smart-open](https://github.com/piskvorky/smart_open/tree/develop) drop-in replacement for open() that works with large cloud storage `util`\n",
    "- [Hydra](https://hydra.cc/docs/intro) library for all your config needs, including automatically parsing command line args to a python dict-like object `config, test`\n",
    "- [Sympy](https://docs.sympy.org/latest/index.html) symbolic mathematics (expression simplification, symbolic differentiation, geometry - similar to wolframalpha) `math`\n",
    "- [Evidently](https://docs.evidentlyai.com) monitor data and models `monitor, plot`\n",
    "- [Databutton](https://docs.databutton.com) all-in-one online workspace for building data apps `app, monitor`\n",
    "- [Langchain](https://python.langchain.com/docs/get_started/introduction.html) utilize llms in apps `nlp, model`\n",
    "- [Lightning](https://lightning.ai/docs/pytorch/stable) high-level model training `monitor, train, config`\n",
    "- [Sqlalchemy](https://www.sqlalchemy.org) pythonic interface to SQL databases `data`\n",
    "- [Pymongo](https://pymongo.readthedocs.io/en/stable/#overview) pythonic interface to NoSQL database `data`\n",
    "- [Lm-eval](https://github.com/EleutherAI/lm-evaluation-harness) evaluating llms `monitor`\n",
    "- [Tiktoken](https://github.com/openai/tiktoken) OpenAI tokenizer `nlp`\n",
    "- [Statsmodels](https://www.statsmodels.org/stable/index.html) more stat models `math`\n",
    "- [Pytorch](https://pytorch.org) numerical python with gradients `model, math`\n",
    "- [Functorch](https://pytorch.org/functorch/stable) vectorize (or batchify) functions (or nn.modules) `parallel`\n",
    "- [Transformers](https://huggingface.co/course/chapter0/1?fw=pt) pretrained models `model, nlp`\n",
    "- [Transformers_agents](https://huggingface.co/docs/transformers/transformers_agents) langchain alternative `model, nlp`\n",
    "- [Scrapy](https://scrapy.org) Web scraper `web`\n",
    "- [Beautiful-soup](https://beautiful-soup-4.readthedocs.io/en/latest) Web parser `web`\n",
    "- [Catboost](https://catboost.ai) gradient boosted trees `model`\n",
    "- [Eli5](https://eli5.readthedocs.io/en/latest/overview.html) ml interpretability `plot, monitor`\n",
    "- [Evidently](https://docs.evidentlyai.com) analyze data quality and drift `plot, monitor`\n",
    "- [Black](https://black.readthedocs.io/en/stable) nice formatter `lint`\n",
    "- [Pylint](https://pylint.readthedocs.io/en/stable) static code analyzer `lint`\n",
    "- [Pypika](https://pypika.readthedocs.io/en/latest) sql query builder `sql` \n",
    "- [Pyreverse](https://pylint.readthedocs.io/en/latest/pyreverse.html) builds uml diagrams from source code `lint`\n",
    "- [Pydocstringformatter](https://github.com/DanielNoord/pydocstringformatter) format doc strings `lint`\n",
    "- [Pytype](https://google.github.io/pytype) pylint alternative `lint`\n",
    "- [Captum](https://captum.ai/docs/introduction) deep models interpretability `plot, monitor`\n",
    "- [Plotly](https://plotly.com/python) high-level, interactive plots `plot`\n",
    "- [Tqdm](https://tqdm.github.io) progress bar `monitor`\n",
    "- [Pendulum](https://pendulum.eustace.io/docs/) datetime `util`\n",
    "- [Wandb](https://docs.wandb.ai/ref/python/) experiment tracking, model and data versioning `plot, monitor`\n",
    "- [Mlflow](https://mlflow.org/docs/latest/index.html) open source wandb altenative `plot, monitor`\n",
    "- [Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) aws api `data`\n",
    "- [Airflow](https://airflow.apache.org/docs/apache-airflow/) schedule and monitor workflows `monitor, schedule`\n",
    "- [Deepspeed](http://www.deepspeed.ai/training/) accelerated gradient model training and inference `model, train, parallel`\n",
    "- [Optuna](https://optuna.org) hyperparameter optimizing `model, train`\n",
    "- [Alibi](https://docs.seldon.io/projects/alibi/en/stable) model interpretation `monitor`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac717db0",
   "metadata": {},
   "source": [
    "## Tips <span id=Tips_></span>\n",
    "\n",
    "- If Notebook hangs, it may be because of large amount of cell outputs, so `Cell -> All Output -> Clear` may help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fcb445",
   "metadata": {},
   "source": [
    "## Markdown syntax <span id=Markdown_syntax_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1263131",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Collapsible</summary>\n",
    "\n",
    "**bold text**\n",
    "    \n",
    "*italicized text*\n",
    "\n",
    "### section id\n",
    "    \n",
    "> blockquote\n",
    "\n",
    "1. First item\n",
    "2. Second item\n",
    "3. Third item\n",
    "\n",
    "- First item\n",
    "- Second item\n",
    "- Third item\n",
    "\n",
    "`code`\n",
    "\n",
    "\n",
    "\n",
    "```c++ \n",
    "// formatted code according to specified language\n",
    "public static String monthNames[] = {\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"};\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "[Section link](#section-id)\n",
    "\n",
    "[Markdown Guide](https://www.markdownguide.org)\n",
    "\n",
    "![alt text](https://www.markdownguide.org/assets/images/tux.png \"Image Title\")\n",
    "<figcaption> Caption </figcaption>\n",
    "\n",
    "[Example of a relative link](/tree/YSDA/notebooks/Portfolio.ipynb)\n",
    "    \n",
    "    \n",
    "| Default | Left align | Center align |\n",
    "| - | :- | :-: |\n",
    "| Header | Title | - |\n",
    "| Paragraph | Text | NA|\n",
    "\n",
    "```\n",
    "{\n",
    "  \"firstName\": \"John\",\n",
    "  \"lastName\": \"Smith\",\n",
    "  \"age\": 25\n",
    "}\n",
    "```\n",
    "\n",
    "Monospaced\n",
    "\n",
    "<samp>The quick brown fox jumps over the lazy dog.</samp>\n",
    "\n",
    "Underlined\n",
    "\n",
    "<ins>The quick brown fox jumps over the lazy dog.</ins>\n",
    "\n",
    "Strike-through\n",
    "\n",
    "~~The quick brown fox jumps over the lazy dog.~~\n",
    "\n",
    "\n",
    "Boxed\n",
    "\n",
    "<table><tr><td>The quick brown fox jumps over the lazy dog.</td></tr></table>\n",
    "\n",
    "Subscript <sub>The quick brown fox jumps over the lazy dog.</sub>\n",
    "\n",
    "Superscript <sup>The quick brown fox jumps over the lazy dog.</sup>\n",
    "\n",
    "- [x] Fix Bug 223\n",
    "- [ ] Add Feature 33\n",
    "- [ ] Add unit tests\n",
    "\n",
    "\n",
    "  \n",
    "  ### Heading\n",
    "  1. Foo\n",
    "  2. Bar\n",
    "     * Baz\n",
    "     * Qux\n",
    "\n",
    "  ### Some Code\n",
    "  ```js\n",
    "  function logSomething(something) {\n",
    "    console.log('Something', something);\n",
    "  }\n",
    "  ```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e12e83",
   "metadata": {},
   "source": [
    "## Tex syntax <span id=Tex_syntax_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11d762",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Tex probability commands shortlist</summary>\n",
    "  \n",
    "```\n",
    "$\\newcommand{\\Sum}{\\sum\\limits}\n",
    "\\newcommand{\\Int}{\\int\\limits}\n",
    "\\newcommand{\\Intf}{\\int\\limits_{-\\infty}^{+\\infty}}\n",
    "\\newcommand{\\Prod}{\\prod\\limits}\n",
    "\\newcommand{\\Max}{\\max\\limits}\n",
    "\\newcommand{\\Min}{\\min\\limits}\n",
    "\\newcommand{\\Lim}{\\lim\\limits}\n",
    "\\newcommand{\\Var}{\\mathbb{V}}\n",
    "\\newcommand{\\Exp}{\\mathbb{E}}\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\argmax}{\\arg\\max}\n",
    "\\newcommand{\\Cov}{\\text{Cov}}\n",
    "\\newcommand{\\makebold}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\newcommand{\\mean}[1]{\\overline{#1}}\n",
    "\\newcommand{\\avg}[1]{\\langle #1 \\rangle}\n",
    "\\newcommand{\\angmean}[1]{\\langle #1 \\rangle}\n",
    "\\newcommand{\\Prob}{\\mathcal{P}}\n",
    "\\newcommand{\\se}{\\text{se}}\n",
    "\\newcommand{\\lp}{\\left}\n",
    "\\newcommand{\\rp}{\\right}\n",
    "\\newcommand{\\boldx}{\\boldsymbol{x}}\n",
    "\\newcommand{\\boldy}{\\boldsymbol{y}}\n",
    "\\newcommand{\\boldz}{\\boldsymbol{z}}\n",
    "\\newcommand{\\boldX}{\\boldsymbol{X}}\n",
    "\\newcommand{\\boldY}{\\boldsymbol{Y}}\n",
    "\\newcommand{\\boldZ}{\\boldsymbol{Z}}\n",
    "\\newcommand{\\Poisson}{\\mathrm{Poisson}}\n",
    "\\newcommand{\\Triangle}{\\mathrm{Triangle}}\n",
    "\\newcommand{\\Uniform}{\\mathrm{Uniform}}\n",
    "\\newcommand{\\Binomial}{\\mathrm{Binomial}}\n",
    "\\newcommand{\\Bernoulli}{\\mathrm{Bernoulli}}\n",
    "\\newcommand{\\Gammap}{\\mathrm{Gamma}}\n",
    "\\newcommand{\\Normal}{\\mathcal{N}}\n",
    "\\newcommand{\\LogN}{\\mathrm{LogN}}\n",
    "\\newcommand{\\Exponential}{\\mathrm{Exp}}\n",
    "\\newcommand{\\Erlang}{\\mathrm{Erlang}}\n",
    "\\newcommand{\\Cauchy}{C}\n",
    "\\newcommand{\\Dir}{\\mathrm{Dir}}\n",
    "\\newcommand{\\Beta}{\\mathrm{Beta}}\n",
    "\\newcommand{\\Pareto}{\\mathrm{Pareto}}\n",
    "\\newcommand{\\lf}{\\left\\{}\n",
    "\\newcommand{\\rf}{\\right\\}}\n",
    "\\newcommand{\\lp}{\\left(}\n",
    "\\newcommand{\\rp}{\\right)}\n",
    "\\newcommand{\\Ecdf}[1]{\\hat{F}_n(#1)}\n",
    "\\newcommand{\\OPT}{\\text{OPT}}\n",
    "\\newcommand{\\opt}{\\text{opt}}\n",
    "\\newcommand{\\boot}{\\text{boot}}\n",
    "\\newcommand{\\bias}{\\text{bias}}\n",
    "\\newcommand{\\se}{\\text{se}}\n",
    "\\newcommand{\\MSE}{\\text{MSE}}\n",
    "\\newcommand{\\qm}{\\text{qm}}\n",
    "\\newcommand{\\as}{\\text{as}}\n",
    "\\newcommand{\\trace}{\\text{trace}}\n",
    "\\newcommand{\\esttheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\estlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\estmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\estsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\estalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\estbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\estxi}{\\hat{\\xi}}\n",
    "\\newcommand{\\esttau}{\\hat{\\tau}}\n",
    "\\newcommand{\\estpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\esta}{\\hat{a}}\n",
    "\\newcommand{\\estb}{\\hat{b}}\n",
    "\\newcommand{\\estc}{\\hat{c}}\n",
    "\\newcommand{\\estd}{\\hat{d}}\n",
    "\\newcommand{\\estp}{\\hat{p}}\n",
    "\\newcommand{\\estT}{\\hat{T}}\n",
    "\\newcommand{\\estR}{\\hat{R}}\n",
    "\\newcommand{\\estF}{\\hat{F}}\n",
    "\\newcommand{\\estf}{\\hat{f}}\n",
    "\\newcommand{\\estC}{\\hat{C}}\n",
    "\\newcommand{\\estS}{\\hat{S}}\n",
    "\\newcommand{\\estY}{\\hat{Y}}\n",
    "\\newcommand{\\esty}{\\hat{y}}\n",
    "\\newcommand{\\estVar}{\\hat{\\Var}}\n",
    "\\newcommand{\\estExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\estSe}{\\hat{\\se}}\n",
    "\\newcommand{\\hatp}{\\hat{p}}\n",
    "\\newcommand{\\hatF}{\\hat{F}}\n",
    "\\newcommand{\\hatT}{\\hat{T}}\n",
    "\\newcommand{\\hattheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\hatse}{\\hat{\\se}}$\n",
    "```\n",
    "    \n",
    "<\\details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da4191",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Tex commands extended list</summary>\n",
    "  \n",
    "```\n",
    "$\n",
    "% The list of general commands\n",
    "\\newcommand{\\PI}{3.141592654}\n",
    "\\newcommand{\\Sum}{\\sum\\limits}\n",
    "\\newcommand{\\Int}{\\int\\limits}\n",
    "\\newcommand{\\Lim}{\\lim\\limits}\n",
    "\\newcommand{\\Prod}{\\prod\\limits}\n",
    "\\newcommand{\\Intf}{\\int\\limits_{-\\infty}^{+\\infty}}\n",
    "\\newcommand{\\Sumclap}[1]{\\Sum_{\\mathclap{#1}}}\n",
    "\\newcommand{\\Intclap}[1]{\\Int_{\\mathclap{#1}}}\n",
    "\\newcommand{\\Prodclap}[1]{\\Prod_{\\mathclap{#1}}}\n",
    "\\newcommand{\\Aprod}{\\bigodot}\n",
    "\\newcommand{\\aprod}{\\odot}\n",
    "\\newcommand{\\Max}{\\max\\limits}\n",
    "\\newcommand{\\Min}{\\min\\limits}\n",
    "\\newcommand{\\argmax}{\\arg\\max}\n",
    "\\newcommand{\\argmin}{\\arg\\min}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\lp}{\\left(}\n",
    "\\newcommand{\\rp}{\\right)}\n",
    "\\newcommand{\\lf}{\\left\\{}\n",
    "\\newcommand{\\rf}{\\right\\}}\n",
    "\\newcommand{\\ls}{\\left[}\n",
    "\\newcommand{\\rs}{\\right]}\n",
    "\\newcommand{\\lv}{\\left|}\n",
    "\\newcommand{\\rv}{\\right|}\n",
    "\\newcommand{\\la}{\\left\\langle}\n",
    "\\newcommand{\\ra}{\\right\\rangle}\n",
    "\\\n",
    "% Обозначения из предметной области: теории вероятностей и статистики\n",
    "\\newcommand{\\Distr}{\\mathsf{D}}\n",
    "\\newcommand{\\Var}{\\mathbb{V}}\n",
    "\\newcommand{\\Exp}{\\mathbb{E}}\n",
    "\\newcommand{\\Cov}{\\mathbb{C}\\mathrm{ov}}\n",
    "\\newcommand{\\Loss}{\\mathcal{L}}\n",
    "\\newcommand{\\loss}{\\ell}\n",
    "\\newcommand{\\LogLike}{\\mathcal{L}}\n",
    "\\newcommand{\\Like}{\\ell}\n",
    "\\newcommand{\\Risk}{\\mathcal{R}}\n",
    "\\newcommand{\\makebold}[1]{\\boldsymbol{#1}}\n",
    "\\\n",
    "\\newcommand{\\mean}[1]{\\overline{#1}}\n",
    "\\newcommand{\\avg}[1]{\\overline{#1}}\n",
    "\\newcommand{\\angmean}[1]{\\left\\langle #1 \\right\\rangle}\n",
    "\\newcommand{\\barmean}[1]{\\overline{#1}}\n",
    "\\\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\renewcommand{\\epsilon}{\\varepsilon}\n",
    "\\newcommand{\\Ind}{I}\n",
    "\\newcommand{\\Fisher}{I}\n",
    "\\\n",
    "\\newcommand{\\HOT}{\\text{\\textbf{H.O.T.}}}\n",
    "\\\n",
    "\\newcommand{\\partfrac}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\ttt}[1]{\\texttt{#1}}\n",
    "\\newcommand{\\term}[1]{\\textbf{#1}}\n",
    "$\n",
    "$\n",
    "\\\n",
    "\\renewcommand{\\phi}{\\varphi}\n",
    "\\\n",
    "\\newcommand{\\CC}{\\mathbb{C}}\n",
    "\\newcommand{\\NN}{\\mathbb{N}}\n",
    "\\newcommand{\\PP}{\\mathbb{P}}\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\XX}{\\mathbb{X}}\n",
    "\\newcommand{\\ZZ}{\\mathbb{Z}}\n",
    "\\renewcommand{\\AA}{\\mathbb{A}}\n",
    "\\\n",
    "\\newcommand{\\Xbb}{\\mathbb{X}}\n",
    "\\newcommand{\\Ybb}{\\mathbb{Y}}\n",
    "\\newcommand{\\Zbb}{\\mathbb{Z}}\n",
    "\\\n",
    "% Empirical values\n",
    "\\newcommand{\\Ecdf}[1]{\\hat{F}_n(#1)}\n",
    "\\newcommand{\\OPT}{\\ensuremath{\\mathrm{OPT}\\xspace}}\n",
    "\\newcommand{\\opt}{\\ensuremath{\\mathrm{opt}\\xspace}}\n",
    "\\newcommand{\\boot}{\\ensuremath{\\mathrm{boot}\\xspace}}\n",
    "\\newcommand{\\bias}{\\ensuremath{\\mathrm{bias}\\xspace}}\n",
    "\\newcommand{\\se}{\\ensuremath{\\mathrm{se}\\xspace}}\n",
    "\\newcommand{\\MSE}{\\ensuremath{\\mathrm{MSE}\\xspace}}\n",
    "\\newcommand{\\RSS}{\\ensuremath{\\mathrm{RSS}\\xspace}}\n",
    "\\newcommand{\\qm}{\\ensuremath{\\mathrm{qm}\\xspace}}\n",
    "\\newcommand{\\as}{\\ensuremath{\\mathrm{as}\\xspace}}\n",
    "\\newcommand{\\trace}{\\ensuremath{\\mathrm{tr}\\xspace}}\n",
    "\\newcommand{\\const}{\\ensuremath{\\mathrm{const}\\xspace}}\n",
    "\\newcommand{\\sign}{\\ensuremath{\\mathrm{sign}\\xspace}}\n",
    "\\newcommand{\\tr}{\\mathrm{tr}}\n",
    "\\newcommand{\\new}{\\mathrm{new}}\n",
    "\\newcommand{\\lasso}{\\mathrm{lasso}}\n",
    "\\newcommand{\\old}{\\mathrm{old}}\n",
    "\\newcommand{\\diag}{\\mathrm{diag}}\n",
    "\\newcommand{\\rank}{\\mathrm{rg}}\n",
    "\\newcommand{\\ML}{\\mathrm{ML}}\n",
    "\\newcommand{\\MP}{\\mathrm{MP}}\n",
    "\\newcommand{\\KL}{\\mathrm{KL}}\n",
    "\\newcommand{\\NV}{\\mathrm{NV}}\n",
    "\\newcommand{\\MV}{\\mathrm{MV}}\n",
    "\\newcommand{\\NP}{\\mathrm{MP}}   % Нейман-Пирсон\n",
    "\\newcommand{\\vs}{\\mathrm{vs}}   % versus\n",
    "\\newcommand{\\LOO}{\\mathrm{LOO}}\n",
    "\\newcommand{\\IGMV}{\\mathrm{IGMV}}\n",
    "\\newcommand{\\MM}{\\mathrm{MM}}\n",
    "\\newcommand{\\nat}{\\mathrm{nat}\\xspace}\n",
    "\\newcommand{\\grad}{\\mathrm{grad}\\xspace}\n",
    "% Оценки\n",
    "\\newcommand{\\esttheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\estlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\estmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\estsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\estalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\estbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\estxi}{\\hat{\\xi}}\n",
    "\\newcommand{\\esttau}{\\hat{\\tau}}\n",
    "\\newcommand{\\estpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\esta}{\\hat{a}}\n",
    "\\newcommand{\\estb}{\\hat{b}}\n",
    "\\newcommand{\\estc}{\\hat{c}}\n",
    "\\newcommand{\\estd}{\\hat{d}}\n",
    "\\newcommand{\\estf}{\\hat{f}}\n",
    "\\newcommand{\\estp}{\\hat{p}}\n",
    "\\newcommand{\\esty}{\\hat{y}}\n",
    "\\newcommand{\\estT}{\\hat{T}}\n",
    "\\newcommand{\\estR}{\\hat{R}}\n",
    "\\newcommand{\\estF}{\\hat{F}}\n",
    "\\newcommand{\\estC}{\\hat{C}}\n",
    "\\newcommand{\\estS}{\\hat{S}}\n",
    "\\newcommand{\\estY}{\\hat{Y}}\n",
    "\\newcommand{\\estVar}{\\hat{\\Var}}\n",
    "\\newcommand{\\estExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\estSe}{\\hat{\\se}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\ecdf}{\\hat{F}}\n",
    "\\\n",
    "\\newcommand{\\hata}{\\hat{a}}\n",
    "\\newcommand{\\hatb}{\\hat{b}}\n",
    "\\newcommand{\\hatc}{\\hat{c}}\n",
    "\\newcommand{\\hatd}{\\hat{d}}\n",
    "\\newcommand{\\hatf}{\\hat{f}}\n",
    "\\newcommand{\\hatg}{\\hat{g}}\n",
    "\\newcommand{\\hatk}{\\hat{k}}\n",
    "\\newcommand{\\hatp}{\\hat{p}}\n",
    "\\newcommand{\\hatr}{\\hat{r}}\n",
    "\\newcommand{\\hatt}{\\hat{t}}\n",
    "\\newcommand{\\haty}{\\hat{y}}\n",
    "\\newcommand{\\hatw}{\\hat{w}}\n",
    "\\\n",
    "\\newcommand{\\hatC}{\\hat{C}}\n",
    "\\newcommand{\\hatF}{\\hat{F}}\n",
    "\\newcommand{\\hatJ}{\\hat{J}}\n",
    "\\newcommand{\\hatK}{\\hat{K}}\n",
    "\\newcommand{\\hatP}{\\hat{P}}\n",
    "\\newcommand{\\hatS}{\\hat{S}}\n",
    "\\newcommand{\\hatT}{\\hat{T}}\n",
    "\\newcommand{\\hatY}{\\hat{Y}}\n",
    "\\newcommand{\\hatV}{\\hat{V}}\n",
    "\\newcommand{\\hatU}{\\hat{U}}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\hateps}{\\hat{\\eps}}\n",
    "\\newcommand{\\hatalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\hatbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\hatpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\hatlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\hattheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\hatsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\hatmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\hatnu}{\\hat{\\nu}}\n",
    "\\newcommand{\\hatSigma}{\\hat{\\Sigma}}\n",
    "\\newcommand{\\hatSe}{\\hat{\\se}}\n",
    "\\newcommand{\\hatExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\hatVar}{\\hat{\\Var}}\n",
    "\\\n",
    "\\newcommand{\\tilx}{\\tilde{x}}\n",
    "\\newcommand{\\tily}{\\tilde{y}}\n",
    "\\newcommand{\\tilX}{\\tilde{X}}\n",
    "\\newcommand{\\tilY}{\\tilde{Y}}\n",
    "\\newcommand{\\tilK}{\\tilde{K}}\n",
    "\\newcommand{\\tilU}{\\tilde{U}}\n",
    "\\newcommand{\\tilV}{\\tilde{V}}\n",
    "\\newcommand{\\tilSigma}{\\tilde{\\Sigma}}\n",
    "\\newcommand{\\tiltau}{\\tilde{\\tau}}\n",
    "\\newcommand{\\tiltheta}{\\tilde{\\theta}}\n",
    "\\newcommand{\\tillambda}{\\tilde{\\lambda}}\n",
    "\\newcommand{\\tilsigma}{\\tilde{\\sigma}}\n",
    "\\newcommand{\\tilpsi}{\\tilde{\\psi}}\n",
    "\\newcommand{\\tilmu}{\\tilde{\\mu}}\n",
    "\\\n",
    "\\newcommand{\\MLE}{\\text{MLE}}\n",
    "\\newcommand{\\mlexi}{\\xi_{MLE}}\n",
    "\\newcommand{\\mletheta}{\\theta_{MLE}}\n",
    "\\newcommand{\\mlelambda}{\\lambda_{MLE}}\n",
    "\\newcommand{\\mlesigma}{\\sigma_{MLE}}\n",
    "\\newcommand{\\mlepsi}{\\psi_{MLE}}\n",
    "\\newcommand{\\mlemu}{\\mu_{MLE}}\n",
    "\\newcommand{\\mlenu}{\\nu_{MLE}}\n",
    "\\\n",
    "\\newcommand{\\mmxi}{\\xi_{MM}}\n",
    "\\newcommand{\\mmtheta}{\\theta_{MM}}\n",
    "\\newcommand{\\mmlambda}{\\lambda_{MM}}\n",
    "\\newcommand{\\mmsigma}{\\sigma_{MM}}\n",
    "\\newcommand{\\mmpsi}{\\psi_{MM}}\n",
    "\\newcommand{\\mmalpha}{\\alpha_{MM}}\n",
    "\\newcommand{\\mmbeta}{\\beta_{MM}}\n",
    "\\\n",
    "% Классы распределений\n",
    "\\newcommand{\\Poisson}{\\mathrm{Poisson}\\xspace}\n",
    "\\newcommand{\\Triangle}{\\mathrm{Triangle}\\xspace}\n",
    "\\newcommand{\\Uniform}{\\mathrm{Uniform}\\xspace}\n",
    "\\newcommand{\\Binomial}{\\mathrm{Binomial}\\xspace}\n",
    "\\newcommand{\\Multinomial}{\\mathrm{Multinomial}\\xspace}\n",
    "\\newcommand{\\Bernoulli}{\\mathrm{Bernoulli}\\xspace}\n",
    "\\newcommand{\\Gammap}{\\mathrm{Gamma}\\xspace}\n",
    "\\newcommand{\\Normal}{\\mathcal{N}\\xspace}\n",
    "\\newcommand{\\Student}{\\mathcal{T}\\xspace}\n",
    "%\\newcommand{\\Student}{\\mathrm{Student}\\xspace}\n",
    "\\newcommand{\\LogN}{\\mathrm{LogN}\\xspace}\n",
    "\\newcommand{\\Exponential}{\\mathrm{Exp}\\xspace}\n",
    "\\newcommand{\\Erlang}{\\mathrm{Erlang}\\xspace}\n",
    "\\newcommand{\\Cauchy}{C\\xspace}\n",
    "\\newcommand{\\Dir}{\\mathrm{Dir}\\xspace}\n",
    "\\newcommand{\\Beta}{\\mathrm{Beta}\\xspace}\n",
    "\\newcommand{\\Pareto}{\\mathrm{Pareto}\\xspace}\n",
    "$\n",
    "$\n",
    "%\n",
    "\\newcommand{\\Family}{\\mathfrak{F}}\n",
    "\\\n",
    "% Гипотезы\n",
    "\\newcommand{\\RejectRegion}{R}\n",
    "\\newcommand{\\pvalue}{\\text{p-value}\\xspace}\n",
    "\\newcommand{\\llr}{\\ell}\n",
    "\\newcommand{\\Llr}{\\mathcal{L}}\n",
    "\\\n",
    "% Регрессия\n",
    "\\newcommand{\\RRS}{\\mathrm{RSS}\\xspace}\n",
    "\\\n",
    "\\newcommand{\\redtext}[1]{\\textcolor{red}{#1}}\n",
    "\\newcommand{\\addtask}[1]{\\hyperref[#1]{\\redtext{Задача~\\ref*{#1}}}}\n",
    "\\newcommand{\\solution}{\\redtext{\\textbf{Решение.}}}\n",
    "\\newcommand{\\ignore}[1]{\\xspace}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\NumOfSamples}{\\mathcal{N}}\n",
    "\\newcommand{\\NumOfDims}{\\mathcal{D}}\n",
    "\\newcommand{\\NumOfHidden}{\\mathcal{H}}\n",
    "\\newcommand{\\NumOfClasses}{\\mathcal{K}}\n",
    "\\newcommand{\\NumOfChannels}{\\mathcal{C}}\n",
    "\\newcommand{\\NumOfFilters}{\\mathcal{F}}\n",
    "\\newcommand{\\HiddenSize}{\\mathcal{H}}\n",
    "\\\n",
    "\\newcommand{\\boldzero}{\\boldsymbol{0}}\n",
    "\\newcommand{\\boldones}{\\boldsymbol{1}}\n",
    "\\newcommand{\\boldone}{\\boldsymbol{1}}\n",
    "\\\n",
    "\\newcommand{\\bolda}{\\boldsymbol{a}}\n",
    "\\newcommand{\\boldb}{\\boldsymbol{b}}\n",
    "\\newcommand{\\boldc}{\\boldsymbol{c}}\n",
    "\\newcommand{\\boldd}{\\boldsymbol{d}}\n",
    "\\newcommand{\\bolde}{\\boldsymbol{e}}\n",
    "\\newcommand{\\boldf}{\\boldsymbol{f}}\n",
    "\\newcommand{\\boldg}{\\boldsymbol{g}}\n",
    "\\newcommand{\\boldh}{\\boldsymbol{h}}\n",
    "\\newcommand{\\boldi}{\\boldsymbol{i}}\n",
    "\\newcommand{\\boldj}{\\boldsymbol{j}}\n",
    "\\newcommand{\\boldk}{\\boldsymbol{k}}\n",
    "\\newcommand{\\boldl}{\\boldsymbol{l}}\n",
    "\\newcommand{\\boldm}{\\boldsymbol{m}}\n",
    "\\newcommand{\\boldn}{\\boldsymbol{n}}\n",
    "\\newcommand{\\boldo}{\\boldsymbol{o}}\n",
    "\\newcommand{\\boldp}{\\boldsymbol{p}}\n",
    "\\newcommand{\\boldq}{\\boldsymbol{q}}\n",
    "\\newcommand{\\boldr}{\\boldsymbol{r}}\n",
    "\\newcommand{\\bolds}{\\boldsymbol{s}}\n",
    "\\newcommand{\\boldt}{\\boldsymbol{t}}\n",
    "\\newcommand{\\boldu}{\\boldsymbol{u}}\n",
    "\\newcommand{\\boldv}{\\boldsymbol{v}}\n",
    "\\newcommand{\\boldw}{\\boldsymbol{w}}\n",
    "\\newcommand{\\boldx}{\\boldsymbol{x}}\n",
    "\\newcommand{\\boldy}{\\boldsymbol{y}}\n",
    "\\newcommand{\\boldz}{\\boldsymbol{z}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\boldA}{\\boldsymbol{A}}\n",
    "\\newcommand{\\boldB}{\\boldsymbol{B}}\n",
    "\\newcommand{\\boldC}{\\boldsymbol{C}}\n",
    "\\newcommand{\\boldD}{\\boldsymbol{D}}\n",
    "\\newcommand{\\boldE}{\\boldsymbol{E}}\n",
    "\\newcommand{\\boldF}{\\boldsymbol{F}}\n",
    "\\newcommand{\\boldH}{\\boldsymbol{H}}\n",
    "\\newcommand{\\boldJ}{\\boldsymbol{J}}\n",
    "\\newcommand{\\boldK}{\\boldsymbol{K}}\n",
    "\\newcommand{\\boldL}{\\boldsymbol{L}}\n",
    "\\newcommand{\\boldM}{\\boldsymbol{M}}\n",
    "\\newcommand{\\boldN}{\\boldsymbol{N}}\n",
    "\\newcommand{\\boldI}{\\boldsymbol{I}}\n",
    "\\newcommand{\\boldP}{\\boldsymbol{P}}\n",
    "\\newcommand{\\boldQ}{\\boldsymbol{Q}}\n",
    "\\newcommand{\\boldR}{\\boldsymbol{R}}\n",
    "\\newcommand{\\boldS}{\\boldsymbol{S}}\n",
    "\\newcommand{\\boldT}{\\boldsymbol{T}}\n",
    "\\newcommand{\\boldO}{\\boldsymbol{O}}\n",
    "\\newcommand{\\boldU}{\\boldsymbol{U}}\n",
    "\\newcommand{\\boldV}{\\boldsymbol{V}}\n",
    "\\newcommand{\\boldW}{\\boldsymbol{W}}\n",
    "\\newcommand{\\boldX}{\\boldsymbol{X}}\n",
    "\\newcommand{\\boldY}{\\boldsymbol{Y}}\n",
    "\\newcommand{\\boldZ}{\\boldsymbol{Z}}\n",
    "\\newcommand{\\boldXY}{\\boldsymbol{XY}}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\boldalpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\boldbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\boldtheta}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\boldmu}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\boldxi}{\\boldsymbol{\\xi}}\n",
    "\\newcommand{\\boldeta}{\\boldsymbol{\\eta}}\n",
    "\\newcommand{\\boldpi}{\\boldsymbol{\\pi}}\n",
    "\\newcommand{\\boldsigma}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\boldphi}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\boldpsi}{\\boldsymbol{\\psi}}\n",
    "\\newcommand{\\boldlambda}{\\boldsymbol{\\lambda}}\n",
    "\\newcommand{\\boldgamma}{\\boldsymbol{\\gamma}}\n",
    "\\newcommand{\\bolddelta}{\\boldsymbol{\\delta}}\n",
    "\\newcommand{\\boldeps}{\\boldsymbol{\\eps}}\n",
    "\\newcommand{\\boldPhi}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\boldPsi}{\\boldsymbol{\\Psi}}\n",
    "\\newcommand{\\boldLambda}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\boldSigma}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\boldTheta}{\\boldsymbol{\\Theta}}\n",
    "\\newcommand{\\boldOmega}{\\boldsymbol{\\Omega}}\n",
    "\\\n",
    "\\newcommand{\\hatboldx}{\\hat{\\boldx}}\n",
    "\\newcommand{\\hatboldk}{\\hat{\\boldk}}\n",
    "\\newcommand{\\hatboldw}{\\hat{\\boldw}}\n",
    "\\newcommand{\\hatboldp}{\\hat{\\boldp}}\n",
    "\\newcommand{\\hatboldK}{\\hat{\\boldK}}\n",
    "\\newcommand{\\hatboldC}{\\hat{\\boldC}}\n",
    "\\newcommand{\\hatboldS}{\\hat{\\boldS}}\n",
    "\\newcommand{\\hatboldU}{\\hat{\\boldU}}\n",
    "\\newcommand{\\hatboldV}{\\hat{\\boldV}}\n",
    "\\newcommand{\\hatboldX}{\\hat{\\boldX}}\n",
    "\\newcommand{\\hatboldSigma}{\\hat{\\boldSigma}}\n",
    "\\newcommand{\\hatboldLambda}{\\hat{\\boldLambda}}\n",
    "\\newcommand{\\hatboldy}{\\hat{\\boldy}}\n",
    "\\newcommand{\\hatboldmu}{\\hat{\\boldmu}}\n",
    "\\newcommand{\\hatboldalpha}{\\hat{\\boldalpha}}\n",
    "\\newcommand{\\hatboldbeta}{\\hat{\\boldbeta}}\n",
    "\\newcommand{\\hatboldgamma}{\\hat{\\boldgamma}}\n",
    "\\newcommand{\\hatboldtheta}{\\hat{\\bold\\theta}}\n",
    "\\newcommand{\\hatboldeps}{\\hat{\\boldeps}}\n",
    "\\newcommand{\\hatbolddelta}{\\hat{\\bolddelta}}\n",
    "\\\n",
    "\\newcommand{\\tilboldbeta}{\\tilde{\\boldbeta}}\n",
    "\\newcommand{\\tilboldw}{\\tilde{\\boldw}}\n",
    "\\newcommand{\\tilboldmu}{\\tilde{\\boldmu}}\n",
    "\\\n",
    "\\newcommand{\\xs}[1]{\\boldx^{#1}}\n",
    "\\newcommand{\\ys}[1]{\\boldy^{#1}}\n",
    "\\newcommand{\\zs}[1]{\\boldz^{#1}}\n",
    "\\newcommand{\\Xs}[1]{\\boldX^{#1}}\n",
    "\\newcommand{\\Ys}[1]{\\boldY^{#1}}\n",
    "\\newcommand{\\Zs}[1]{\\boldZ^{#1}}\n",
    "\\\n",
    "\\newcommand{\\Ndim}{N}\n",
    "\\newcommand{\\Ddim}{D}\n",
    "\\newcommand{\\Mdim}{M}\n",
    "\\newcommand{\\Kdim}{K}\n",
    "\\newcommand{\\Adim}{A}\n",
    "\\newcommand{\\Qdim}{Q}\n",
    "\\newcommand{\\Rdim}{R}\n",
    "\\\n",
    "\\newcommand{\\mcalA}{\\mathcal{A}}\n",
    "\\newcommand{\\mcalB}{\\mathcal{B}}\n",
    "\\newcommand{\\mcalC}{\\mathcal{C}}\n",
    "\\newcommand{\\mcalD}{\\mathcal{D}}\n",
    "\\newcommand{\\mcalE}{\\mathcal{E}}\n",
    "\\newcommand{\\mcalF}{\\mathcal{F}}\n",
    "\\newcommand{\\mcalI}{\\mathcal{I}}\n",
    "\\newcommand{\\mcalL}{\\mathcal{L}}\n",
    "\\newcommand{\\mcalP}{\\mathcal{P}}\n",
    "\\newcommand{\\mcalQ}{\\mathcal{Q}}\n",
    "\\newcommand{\\mcalX}{\\mathcal{X}}\n",
    "\\newcommand{\\hatmcalB}{\\hat{\\mcalB}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\setA}{\\mathcal{A}}\n",
    "\\newcommand{\\setB}{\\mathcal{B}}\n",
    "\\newcommand{\\setC}{\\mathcal{C}}\n",
    "\\newcommand{\\setE}{\\mathcal{E}}\n",
    "\\newcommand{\\setD}{\\mathcal{D}}\n",
    "\\newcommand{\\setS}{\\mathcal{S}}\n",
    "\\newcommand{\\setT}{\\mathcal{T}}\n",
    "\\newcommand{\\setV}{\\mathcal{V}}\n",
    "\\newcommand{\\setW}{\\mathcal{W}}\n",
    "\\\n",
    "\\newcommand{\\matA}{A}\n",
    "\\newcommand{\\matB}{B}\n",
    "\\newcommand{\\matC}{C}\n",
    "\\newcommand{\\matD}{D}\n",
    "\\newcommand{\\matE}{E}\n",
    "\\newcommand{\\matI}{I}\n",
    "\\newcommand{\\matU}{U}\n",
    "\\newcommand{\\matV}{V}\n",
    "\\newcommand{\\matW}{W}\n",
    "\\newcommand{\\matPhi}{\\Phi}\n",
    "\\newcommand{\\matPsi}{\\Psi}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\Factors}{F}\n",
    "\\newcommand{\\Variables}{X}\n",
    "\\newcommand{\\Eye}{I}\n",
    "\\newcommand{\\Zero}{O}\n",
    "\\newcommand{\\Energy}{\\mathcal{E}}\n",
    "\\newcommand{\\Entropy}{\\mathcal{H}}\n",
    "\\newcommand{\\Fenergy}{F}\n",
    "\\newcommand{\\Edges}{E}\n",
    "\\newcommand{\\edge}{e}\n",
    "\\newcommand{\\Vertices}{V}\n",
    "\\newcommand{\\vertex}{v}\n",
    "\\newcommand{\\Graph}{\\mathcal{G}}\n",
    "\\newcommand{\\Tree}{\\mathcal{T}}\n",
    "\\newcommand{\\Children}{\\mathcal{C}}\n",
    "\\newcommand{\\Parents}{\\mathcal{P}}\n",
    "\\newcommand{\\Adjacent}{\\mathcal{A}}\n",
    "\\newcommand{\\Pa}{\\mathrm{Pa}}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\state}{z}\n",
    "\\newcommand{\\State}{\\boldz}\n",
    "\\newcommand{\\StateR}{\\boldZ}\n",
    "\\\n",
    "\\newcommand{\\Covariance}{\\Sigma}\n",
    "\\newcommand{\\CovX}{\\Covariance_{\\boldX}}\n",
    "\\newcommand{\\CovY}{\\Covariance_{\\boldY}}\n",
    "\\newcommand{\\CovZ}{\\Covariance_{\\boldZ}}\n",
    "\\newcommand{\\CovXY}{\\Covariance_{\\boldX\\boldY}}\n",
    "\\\n",
    "\\newcommand{\\hatCovariance}{\\hat{\\Covariance}}\n",
    "\\newcommand{\\hatCovX}{\\hatCovariance_{\\boldX}}\n",
    "\\newcommand{\\hatCovY}{\\hatCovariance_{\\boldY}}\n",
    "\\newcommand{\\hatCovZ}{\\hatCovariance_{\\boldZ}}\n",
    "\\newcommand{\\hatCovXY}{\\hatCovariance_{\\boldX\\boldY}}\n",
    "\\\n",
    "\\newcommand{\\tildeCovariance}{\\tilde{\\Covariance}}\n",
    "\\newcommand{\\tildeCovX}{\\tildeCovariance_{\\boldX}}\n",
    "\\newcommand{\\tildeCovY}{\\tildeCovariance_{\\boldY}}\n",
    "\\newcommand{\\tildeCovZ}{\\tildeCovariance_{\\boldZ}}\n",
    "\\newcommand{\\tildeCovXY}{\\tildeCovariance_{\\boldX\\boldY}}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\hatState}{\\hat{\\State}}\n",
    "\\newcommand{\\StateNum}{N}\n",
    "\\newcommand{\\StateDim}{K}\n",
    "\\newcommand{\\StateSet}{\\ZZ}\n",
    "\\newcommand{\\StatesSet}{\\StateSet}\n",
    "\\newcommand{\\NumStates}{N}\n",
    "\\newcommand{\\StateToState}{A}\n",
    "\\newcommand{\\StateCov}{\\Sigma}\n",
    "\\newcommand{\\StateJac}{A}\n",
    "\\\n",
    "\\newcommand{\\hatStateCov}{\\hat{\\StateCov}}\n",
    "\\newcommand{\\StateMean}{\\boldmu}\n",
    "\\newcommand{\\hatStateMean}{\\hat{\\StateMean}}\n",
    "\\newcommand{\\StateToStateHistory}{\\boldA}\n",
    "\\newcommand{\\StateNoise}{\\boldr}\n",
    "\\newcommand{\\StateNoiseCov}{R}\n",
    "\\newcommand{\\StateHistory}{\\boldZ}\n",
    "\\newcommand{\\StatesHistory}{\\StateHistory}\n",
    "\\newcommand{\\StateToObserv}{C}\n",
    "\\newcommand{\\StateToobserv}{\\boldc}\n",
    "\\newcommand{\\StateToObservHistory}{\\boldC}\n",
    "\\\n",
    "\\newcommand{\\DState}{\\bolddelta}\n",
    "\\newcommand{\\hatDState}{\\hat{\\DState}}\n",
    "\\newcommand{\\DStateMean}{\\boldlambda}\n",
    "\\newcommand{\\hatDStateMean}{\\hat{\\DStateMean}}\n",
    "\\newcommand{\\DStateCov}{\\Lambda}\n",
    "\\newcommand{\\hatDStateCov}{\\hat{\\DStateCov}}\n",
    "\\\n",
    "\\newcommand{\\DObserv}{\\boldgamma}\n",
    "\\newcommand{\\hatDObserv}{\\hat{\\DObserv}}\n",
    "\\\n",
    "\\newcommand{\\observ}{x}\n",
    "\\newcommand{\\Observ}{\\boldsymbol{\\observ}}\n",
    "\\newcommand{\\ObservCov}{\\Lambda}\n",
    "\\newcommand{\\observMean}{\\lambda}\n",
    "\\newcommand{\\ObservMean}{\\boldlambda}\n",
    "\\newcommand{\\hatobserv}{\\hat{\\observ}}\n",
    "\\newcommand{\\hatObserv}{\\hat{\\Observ}}\n",
    "\\newcommand{\\hatObservCov}{\\hat{\\ObservCov}}\n",
    "\\newcommand{\\hatobservMean}{\\hat{\\observMean}}\n",
    "\\newcommand{\\hatObservMean}{\\hat{\\ObservMean}}\n",
    "\\\n",
    "\\newcommand{\\ObservSet}{\\XX}\n",
    "\\newcommand{\\ObservNum}{N}\n",
    "\\newcommand{\\ObservDim}{D}\n",
    "\\newcommand{\\ObservSourceNum}{M}\n",
    "\\newcommand{\\ObservHistory}{\\boldX}\n",
    "\\newcommand{\\ObservsHistory}{\\ObservHistory}\n",
    "\\newcommand{\\Timestamps}{\\boldT}\n",
    "\\newcommand{\\ObservJac}{H}\n",
    "% Шум наблюдений\n",
    "\\newcommand{\\observNoise}{q}\n",
    "\\newcommand{\\ObservNoise}{\\boldq}\n",
    "\\newcommand{\\ObservNoiseCov}{Q}\n",
    "\\newcommand{\\ObservNoiseCovHistory}{\\boldQ}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\control}{u}\n",
    "\\newcommand{\\Control}{\\boldu}\n",
    "\\newcommand{\\ControlNum}{N}\n",
    "\\newcommand{\\ControToState}{B}\n",
    "\\newcommand{\\ControlToStateHistory}{\\boldB}\n",
    "\\newcommand{\\ControlHistory}{\\boldU}\n",
    "\\\n",
    "\\newcommand{\\Jacobian}{\\boldJ}\n",
    "\\\n",
    "\\newcommand{\\Kalman}{K}\n",
    "\\newcommand{\\kalman}{\\boldk}\n",
    "\\\n",
    "\\newcommand{\\vel}{v}\n",
    "$\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0edc3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def add_example(string):\n",
    "    return re.sub(\n",
    "        r\"\\\\newcommand{(\\\\.+?)}(.+?)\\n\", r\"\\\\text{\\1} \\\\quad \\1 x \\\\\\\\\\n\", string\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0331a8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Tex commands examples</summary>\n",
    "\n",
    "$\n",
    "% The list of general commands\n",
    "\\text{\\PI} \\quad \\PI x \\\\\n",
    "\\text{\\Sum} \\quad \\Sum x \\\\\n",
    "\\text{\\Int} \\quad \\Int x \\\\\n",
    "\\text{\\Lim} \\quad \\Lim x \\\\\n",
    "\\text{\\Prod} \\quad \\Prod x \\\\\n",
    "\\text{\\Intf} \\quad \\Intf x \\\\\n",
    "\\text{\\Sumclap} \\quad \\Sumclap x \\\\\n",
    "\\text{\\Intclap} \\quad \\Intclap x \\\\\n",
    "\\text{\\Prodclap} \\quad \\Prodclap x \\\\\n",
    "\\text{\\Aprod} \\quad \\Aprod x \\\\\n",
    "\\text{\\aprod} \\quad \\aprod x \\\\\n",
    "\\text{\\Max} \\quad \\Max x \\\\\n",
    "\\text{\\Min} \\quad \\Min x \\\\\n",
    "\\text{\\argmax} \\quad \\argmax x \\\\\n",
    "\\text{\\argmin} \\quad \\argmin x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\lp} \\quad \\lp x \\\\\n",
    "\\text{\\rp} \\quad \\rp x \\\\\n",
    "\\text{\\lf} \\quad \\lf x \\\\\n",
    "\\text{\\rf} \\quad \\rf x \\\\\n",
    "\\text{\\ls} \\quad \\ls x \\\\\n",
    "\\text{\\rs} \\quad \\rs x \\\\\n",
    "\\text{\\lv} \\quad \\lv x \\\\\n",
    "\\text{\\rv} \\quad \\rv x \\\\\n",
    "\\text{\\la} \\quad \\la x \\\\\n",
    "\\text{\\ra} \\quad \\ra x \\\\\n",
    "\\\n",
    "% Обозначения из предметной области: теории вероятностей и статистики\n",
    "\\text{\\Distr} \\quad \\Distr x \\\\\n",
    "\\text{\\Var} \\quad \\Var x \\\\\n",
    "\\text{\\Exp} \\quad \\Exp x \\\\\n",
    "\\text{\\Cov} \\quad \\Cov x \\\\\n",
    "\\text{\\Loss} \\quad \\Loss x \\\\\n",
    "\\text{\\loss} \\quad \\loss x \\\\\n",
    "\\text{\\LogLike} \\quad \\LogLike x \\\\\n",
    "\\text{\\Like} \\quad \\Like x \\\\\n",
    "\\text{\\Risk} \\quad \\Risk x \\\\\n",
    "\\text{\\makebold} \\quad \\makebold x \\\\\n",
    "\\\n",
    "\\text{\\mean} \\quad \\mean x \\\\\n",
    "\\text{\\avg} \\quad \\avg x \\\\\n",
    "\\text{\\angmean} \\quad \\angmean x \\\\\n",
    "\\text{\\barmean} \\quad \\barmean x \\\\\n",
    "\\\n",
    "\\text{\\eps} \\quad \\eps x \\\\\n",
    "\\renewcommand{\\epsilon}{\\varepsilon}\n",
    "\\text{\\Ind} \\quad \\Ind x \\\\\n",
    "\\text{\\Fisher} \\quad \\Fisher x \\\\\n",
    "\\\n",
    "\\text{\\HOT} \\quad \\HOT x \\\\\n",
    "\\\n",
    "\\text{\\partfrac} \\quad \\partfrac x \\\\\n",
    "\\text{\\ttt} \\quad \\ttt x \\\\\n",
    "\\text{\\term} \\quad \\term x \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\\n",
    "\\renewcommand{\\phi}{\\varphi}\n",
    "\\\n",
    "\\text{\\CC} \\quad \\CC x \\\\\n",
    "\\text{\\NN} \\quad \\NN x \\\\\n",
    "\\text{\\PP} \\quad \\PP x \\\\\n",
    "\\text{\\RR} \\quad \\RR x \\\\\n",
    "\\text{\\XX} \\quad \\XX x \\\\\n",
    "\\text{\\ZZ} \\quad \\ZZ x \\\\\n",
    "\\renewcommand{\\AA}{\\mathbb{A}}\n",
    "\\\n",
    "\\text{\\Xbb} \\quad \\Xbb x \\\\\n",
    "\\text{\\Ybb} \\quad \\Ybb x \\\\\n",
    "\\text{\\Zbb} \\quad \\Zbb x \\\\\n",
    "\\\n",
    "% Empirical values\n",
    "\\text{\\Ecdf} \\quad \\Ecdf x \\\\\n",
    "\\text{\\OPT} \\quad \\OPT x \\\\\n",
    "\\text{\\opt} \\quad \\opt x \\\\\n",
    "\\text{\\boot} \\quad \\boot x \\\\\n",
    "\\text{\\bias} \\quad \\bias x \\\\\n",
    "\\text{\\se} \\quad \\se x \\\\\n",
    "\\text{\\MSE} \\quad \\MSE x \\\\\n",
    "\\text{\\RSS} \\quad \\RSS x \\\\\n",
    "\\text{\\qm} \\quad \\qm x \\\\\n",
    "\\text{\\as} \\quad \\as x \\\\\n",
    "\\text{\\trace} \\quad \\trace x \\\\\n",
    "\\text{\\const} \\quad \\const x \\\\\n",
    "\\text{\\sign} \\quad \\sign x \\\\\n",
    "\\text{\\tr} \\quad \\tr x \\\\\n",
    "\\text{\\new} \\quad \\new x \\\\\n",
    "\\text{\\lasso} \\quad \\lasso x \\\\\n",
    "\\text{\\old} \\quad \\old x \\\\\n",
    "\\text{\\diag} \\quad \\diag x \\\\\n",
    "\\text{\\rank} \\quad \\rank x \\\\\n",
    "\\text{\\ML} \\quad \\ML x \\\\\n",
    "\\text{\\MP} \\quad \\MP x \\\\\n",
    "\\text{\\KL} \\quad \\KL x \\\\\n",
    "\\text{\\NV} \\quad \\NV x \\\\\n",
    "\\text{\\MV} \\quad \\MV x \\\\\n",
    "\\text{\\NP} \\quad \\NP x \\\\\n",
    "\\text{\\vs} \\quad \\vs x \\\\\n",
    "\\text{\\LOO} \\quad \\LOO x \\\\\n",
    "\\text{\\IGMV} \\quad \\IGMV x \\\\\n",
    "\\text{\\MM} \\quad \\MM x \\\\\n",
    "\\text{\\nat} \\quad \\nat x \\\\\n",
    "\\text{\\grad} \\quad \\grad x \\\\\n",
    "% Оценки\n",
    "\\text{\\esttheta} \\quad \\esttheta x \\\\\n",
    "\\text{\\estlambda} \\quad \\estlambda x \\\\\n",
    "\\text{\\estmu} \\quad \\estmu x \\\\\n",
    "\\text{\\estsigma} \\quad \\estsigma x \\\\\n",
    "\\text{\\estalpha} \\quad \\estalpha x \\\\\n",
    "\\text{\\estbeta} \\quad \\estbeta x \\\\\n",
    "\\text{\\estxi} \\quad \\estxi x \\\\\n",
    "\\text{\\esttau} \\quad \\esttau x \\\\\n",
    "\\text{\\estpsi} \\quad \\estpsi x \\\\\n",
    "\\text{\\esta} \\quad \\esta x \\\\\n",
    "\\text{\\estb} \\quad \\estb x \\\\\n",
    "\\text{\\estc} \\quad \\estc x \\\\\n",
    "\\text{\\estd} \\quad \\estd x \\\\\n",
    "\\text{\\estf} \\quad \\estf x \\\\\n",
    "\\text{\\estp} \\quad \\estp x \\\\\n",
    "\\text{\\esty} \\quad \\esty x \\\\\n",
    "\\text{\\estT} \\quad \\estT x \\\\\n",
    "\\text{\\estR} \\quad \\estR x \\\\\n",
    "\\text{\\estF} \\quad \\estF x \\\\\n",
    "\\text{\\estC} \\quad \\estC x \\\\\n",
    "\\text{\\estS} \\quad \\estS x \\\\\n",
    "\\text{\\estY} \\quad \\estY x \\\\\n",
    "\\text{\\estVar} \\quad \\estVar x \\\\\n",
    "\\text{\\estExp} \\quad \\estExp x \\\\\n",
    "\\text{\\estSe} \\quad \\estSe x \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{\\ecdf} \\quad \\ecdf x \\\\\n",
    "\\\n",
    "\\text{\\hata} \\quad \\hata x \\\\\n",
    "\\text{\\hatb} \\quad \\hatb x \\\\\n",
    "\\text{\\hatc} \\quad \\hatc x \\\\\n",
    "\\text{\\hatd} \\quad \\hatd x \\\\\n",
    "\\text{\\hatf} \\quad \\hatf x \\\\\n",
    "\\text{\\hatg} \\quad \\hatg x \\\\\n",
    "\\text{\\hatk} \\quad \\hatk x \\\\\n",
    "\\text{\\hatp} \\quad \\hatp x \\\\\n",
    "\\text{\\hatr} \\quad \\hatr x \\\\\n",
    "\\text{\\hatt} \\quad \\hatt x \\\\\n",
    "\\text{\\haty} \\quad \\haty x \\\\\n",
    "\\text{\\hatw} \\quad \\hatw x \\\\\n",
    "\\\n",
    "\\text{\\hatC} \\quad \\hatC x \\\\\n",
    "\\text{\\hatF} \\quad \\hatF x \\\\\n",
    "\\text{\\hatJ} \\quad \\hatJ x \\\\\n",
    "\\text{\\hatK} \\quad \\hatK x \\\\\n",
    "\\text{\\hatP} \\quad \\hatP x \\\\\n",
    "\\text{\\hatS} \\quad \\hatS x \\\\\n",
    "\\text{\\hatT} \\quad \\hatT x \\\\\n",
    "\\text{\\hatY} \\quad \\hatY x \\\\\n",
    "\\text{\\hatV} \\quad \\hatV x \\\\\n",
    "\\text{\\hatU} \\quad \\hatU x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\hateps} \\quad \\hateps x \\\\\n",
    "\\text{\\hatalpha} \\quad \\hatalpha x \\\\\n",
    "\\text{\\hatbeta} \\quad \\hatbeta x \\\\\n",
    "\\text{\\hatpsi} \\quad \\hatpsi x \\\\\n",
    "\\text{\\hatlambda} \\quad \\hatlambda x \\\\\n",
    "\\text{\\hattheta} \\quad \\hattheta x \\\\\n",
    "\\text{\\hatsigma} \\quad \\hatsigma x \\\\\n",
    "\\text{\\hatmu} \\quad \\hatmu x \\\\\n",
    "\\text{\\hatnu} \\quad \\hatnu x \\\\\n",
    "\\text{\\hatSigma} \\quad \\hatSigma x \\\\\n",
    "\\text{\\hatSe} \\quad \\hatSe x \\\\\n",
    "\\text{\\hatExp} \\quad \\hatExp x \\\\\n",
    "\\text{\\hatVar} \\quad \\hatVar x \\\\\n",
    "\\\n",
    "\\text{\\tilx} \\quad \\tilx x \\\\\n",
    "\\text{\\tily} \\quad \\tily x \\\\\n",
    "\\text{\\tilX} \\quad \\tilX x \\\\\n",
    "\\text{\\tilY} \\quad \\tilY x \\\\\n",
    "\\text{\\tilK} \\quad \\tilK x \\\\\n",
    "\\text{\\tilU} \\quad \\tilU x \\\\\n",
    "\\text{\\tilV} \\quad \\tilV x \\\\\n",
    "\\text{\\tilSigma} \\quad \\tilSigma x \\\\\n",
    "\\text{\\tiltau} \\quad \\tiltau x \\\\\n",
    "\\text{\\tiltheta} \\quad \\tiltheta x \\\\\n",
    "\\text{\\tillambda} \\quad \\tillambda x \\\\\n",
    "\\text{\\tilsigma} \\quad \\tilsigma x \\\\\n",
    "\\text{\\tilpsi} \\quad \\tilpsi x \\\\\n",
    "\\text{\\tilmu} \\quad \\tilmu x \\\\\n",
    "\\\n",
    "\\text{\\MLE} \\quad \\MLE x \\\\\n",
    "\\text{\\mlexi} \\quad \\mlexi x \\\\\n",
    "\\text{\\mletheta} \\quad \\mletheta x \\\\\n",
    "\\text{\\mlelambda} \\quad \\mlelambda x \\\\\n",
    "\\text{\\mlesigma} \\quad \\mlesigma x \\\\\n",
    "\\text{\\mlepsi} \\quad \\mlepsi x \\\\\n",
    "\\text{\\mlemu} \\quad \\mlemu x \\\\\n",
    "\\text{\\mlenu} \\quad \\mlenu x \\\\\n",
    "\\\n",
    "\\text{\\mmxi} \\quad \\mmxi x \\\\\n",
    "\\text{\\mmtheta} \\quad \\mmtheta x \\\\\n",
    "\\text{\\mmlambda} \\quad \\mmlambda x \\\\\n",
    "\\text{\\mmsigma} \\quad \\mmsigma x \\\\\n",
    "\\text{\\mmpsi} \\quad \\mmpsi x \\\\\n",
    "\\text{\\mmalpha} \\quad \\mmalpha x \\\\\n",
    "\\text{\\mmbeta} \\quad \\mmbeta x \\\\\n",
    "\\\n",
    "% Классы распределений\n",
    "\\text{\\Poisson} \\quad \\Poisson x \\\\\n",
    "\\text{\\Triangle} \\quad \\Triangle x \\\\\n",
    "\\text{\\Uniform} \\quad \\Uniform x \\\\\n",
    "\\text{\\Binomial} \\quad \\Binomial x \\\\\n",
    "\\text{\\Multinomial} \\quad \\Multinomial x \\\\\n",
    "\\text{\\Bernoulli} \\quad \\Bernoulli x \\\\\n",
    "\\text{\\Gammap} \\quad \\Gammap x \\\\\n",
    "\\text{\\Normal} \\quad \\Normal x \\\\\n",
    "\\text{\\Student} \\quad \\Student x \\\\\n",
    "%\\text{\\Student} \\quad \\Student x \\\\\n",
    "\\text{\\LogN} \\quad \\LogN x \\\\\n",
    "\\text{\\Exponential} \\quad \\Exponential x \\\\\n",
    "\\text{\\Erlang} \\quad \\Erlang x \\\\\n",
    "\\text{\\Cauchy} \\quad \\Cauchy x \\\\\n",
    "\\text{\\Dir} \\quad \\Dir x \\\\\n",
    "\\text{\\Beta} \\quad \\Beta x \\\\\n",
    "\\text{\\Pareto} \\quad \\Pareto x \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "%\n",
    "\\text{\\Family} \\quad \\Family x \\\\\n",
    "\\\n",
    "% Гипотезы\n",
    "\\text{\\RejectRegion} \\quad \\RejectRegion x \\\\\n",
    "\\text{\\pvalue} \\quad \\pvalue x \\\\\n",
    "\\text{\\llr} \\quad \\llr x \\\\\n",
    "\\text{\\Llr} \\quad \\Llr x \\\\\n",
    "\\\n",
    "% Регрессия\n",
    "\\text{\\RRS} \\quad \\RRS x \\\\\n",
    "\\\n",
    "\\text{\\redtext} \\quad \\redtext x \\\\\n",
    "\\text{\\addtask} \\quad \\addtask x \\\\\n",
    "\\text{\\solution} \\quad \\solution x \\\\\n",
    "\\text{\\ignore} \\quad \\ignore x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\NumOfSamples} \\quad \\NumOfSamples x \\\\\n",
    "\\text{\\NumOfDims} \\quad \\NumOfDims x \\\\\n",
    "\\text{\\NumOfHidden} \\quad \\NumOfHidden x \\\\\n",
    "\\text{\\NumOfClasses} \\quad \\NumOfClasses x \\\\\n",
    "\\text{\\NumOfChannels} \\quad \\NumOfChannels x \\\\\n",
    "\\text{\\NumOfFilters} \\quad \\NumOfFilters x \\\\\n",
    "\\text{\\HiddenSize} \\quad \\HiddenSize x \\\\\n",
    "\\\n",
    "\\text{\\boldzero} \\quad \\boldzero x \\\\\n",
    "\\text{\\boldones} \\quad \\boldones x \\\\\n",
    "\\text{\\boldone} \\quad \\boldone x \\\\\n",
    "\\\n",
    "\\text{\\bolda} \\quad \\bolda x \\\\\n",
    "\\text{\\boldb} \\quad \\boldb x \\\\\n",
    "\\text{\\boldc} \\quad \\boldc x \\\\\n",
    "\\text{\\boldd} \\quad \\boldd x \\\\\n",
    "\\text{\\bolde} \\quad \\bolde x \\\\\n",
    "\\text{\\boldf} \\quad \\boldf x \\\\\n",
    "\\text{\\boldg} \\quad \\boldg x \\\\\n",
    "\\text{\\boldh} \\quad \\boldh x \\\\\n",
    "\\text{\\boldi} \\quad \\boldi x \\\\\n",
    "\\text{\\boldj} \\quad \\boldj x \\\\\n",
    "\\text{\\boldk} \\quad \\boldk x \\\\\n",
    "\\text{\\boldl} \\quad \\boldl x \\\\\n",
    "\\text{\\boldm} \\quad \\boldm x \\\\\n",
    "\\text{\\boldn} \\quad \\boldn x \\\\\n",
    "\\text{\\boldo} \\quad \\boldo x \\\\\n",
    "\\text{\\boldp} \\quad \\boldp x \\\\\n",
    "\\text{\\boldq} \\quad \\boldq x \\\\\n",
    "\\text{\\boldr} \\quad \\boldr x \\\\\n",
    "\\text{\\bolds} \\quad \\bolds x \\\\\n",
    "\\text{\\boldt} \\quad \\boldt x \\\\\n",
    "\\text{\\boldu} \\quad \\boldu x \\\\\n",
    "\\text{\\boldv} \\quad \\boldv x \\\\\n",
    "\\text{\\boldw} \\quad \\boldw x \\\\\n",
    "\\text{\\boldx} \\quad \\boldx x \\\\\n",
    "\\text{\\boldy} \\quad \\boldy x \\\\\n",
    "\\text{\\boldz} \\quad \\boldz x \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{\\boldA} \\quad \\boldA x \\\\\n",
    "\\text{\\boldB} \\quad \\boldB x \\\\\n",
    "\\text{\\boldC} \\quad \\boldC x \\\\\n",
    "\\text{\\boldD} \\quad \\boldD x \\\\\n",
    "\\text{\\boldE} \\quad \\boldE x \\\\\n",
    "\\text{\\boldF} \\quad \\boldF x \\\\\n",
    "\\text{\\boldH} \\quad \\boldH x \\\\\n",
    "\\text{\\boldJ} \\quad \\boldJ x \\\\\n",
    "\\text{\\boldK} \\quad \\boldK x \\\\\n",
    "\\text{\\boldL} \\quad \\boldL x \\\\\n",
    "\\text{\\boldM} \\quad \\boldM x \\\\\n",
    "\\text{\\boldN} \\quad \\boldN x \\\\\n",
    "\\text{\\boldI} \\quad \\boldI x \\\\\n",
    "\\text{\\boldP} \\quad \\boldP x \\\\\n",
    "\\text{\\boldQ} \\quad \\boldQ x \\\\\n",
    "\\text{\\boldR} \\quad \\boldR x \\\\\n",
    "\\text{\\boldS} \\quad \\boldS x \\\\\n",
    "\\text{\\boldT} \\quad \\boldT x \\\\\n",
    "\\text{\\boldO} \\quad \\boldO x \\\\\n",
    "\\text{\\boldU} \\quad \\boldU x \\\\\n",
    "\\text{\\boldV} \\quad \\boldV x \\\\\n",
    "\\text{\\boldW} \\quad \\boldW x \\\\\n",
    "\\text{\\boldX} \\quad \\boldX x \\\\\n",
    "\\text{\\boldY} \\quad \\boldY x \\\\\n",
    "\\text{\\boldZ} \\quad \\boldZ x \\\\\n",
    "\\text{\\boldXY} \\quad \\boldXY x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\boldalpha} \\quad \\boldalpha x \\\\\n",
    "\\text{\\boldbeta} \\quad \\boldbeta x \\\\\n",
    "\\text{\\boldtheta} \\quad \\boldtheta x \\\\\n",
    "\\text{\\boldmu} \\quad \\boldmu x \\\\\n",
    "\\text{\\boldxi} \\quad \\boldxi x \\\\\n",
    "\\text{\\boldeta} \\quad \\boldeta x \\\\\n",
    "\\text{\\boldpi} \\quad \\boldpi x \\\\\n",
    "\\text{\\boldsigma} \\quad \\boldsigma x \\\\\n",
    "\\text{\\boldphi} \\quad \\boldphi x \\\\\n",
    "\\text{\\boldpsi} \\quad \\boldpsi x \\\\\n",
    "\\text{\\boldlambda} \\quad \\boldlambda x \\\\\n",
    "\\text{\\boldgamma} \\quad \\boldgamma x \\\\\n",
    "\\text{\\bolddelta} \\quad \\bolddelta x \\\\\n",
    "\\text{\\boldeps} \\quad \\boldeps x \\\\\n",
    "\\text{\\boldPhi} \\quad \\boldPhi x \\\\\n",
    "\\text{\\boldPsi} \\quad \\boldPsi x \\\\\n",
    "\\text{\\boldLambda} \\quad \\boldLambda x \\\\\n",
    "\\text{\\boldSigma} \\quad \\boldSigma x \\\\\n",
    "\\text{\\boldTheta} \\quad \\boldTheta x \\\\\n",
    "\\text{\\boldOmega} \\quad \\boldOmega x \\\\\n",
    "\\\n",
    "\\text{\\hatboldx} \\quad \\hatboldx x \\\\\n",
    "\\text{\\hatboldk} \\quad \\hatboldk x \\\\\n",
    "\\text{\\hatboldw} \\quad \\hatboldw x \\\\\n",
    "\\text{\\hatboldp} \\quad \\hatboldp x \\\\\n",
    "\\text{\\hatboldK} \\quad \\hatboldK x \\\\\n",
    "\\text{\\hatboldC} \\quad \\hatboldC x \\\\\n",
    "\\text{\\hatboldS} \\quad \\hatboldS x \\\\\n",
    "\\text{\\hatboldU} \\quad \\hatboldU x \\\\\n",
    "\\text{\\hatboldV} \\quad \\hatboldV x \\\\\n",
    "\\text{\\hatboldX} \\quad \\hatboldX x \\\\\n",
    "\\text{\\hatboldSigma} \\quad \\hatboldSigma x \\\\\n",
    "\\text{\\hatboldLambda} \\quad \\hatboldLambda x \\\\\n",
    "\\text{\\hatboldy} \\quad \\hatboldy x \\\\\n",
    "\\text{\\hatboldmu} \\quad \\hatboldmu x \\\\\n",
    "\\text{\\hatboldalpha} \\quad \\hatboldalpha x \\\\\n",
    "\\text{\\hatboldbeta} \\quad \\hatboldbeta x \\\\\n",
    "\\text{\\hatboldgamma} \\quad \\hatboldgamma x \\\\\n",
    "\\text{\\hatboldtheta} \\quad \\hatboldtheta x \\\\\n",
    "\\text{\\hatboldeps} \\quad \\hatboldeps x \\\\\n",
    "\\text{\\hatbolddelta} \\quad \\hatbolddelta x \\\\\n",
    "\\\n",
    "\\text{\\tilboldbeta} \\quad \\tilboldbeta x \\\\\n",
    "\\text{\\tilboldw} \\quad \\tilboldw x \\\\\n",
    "\\text{\\tilboldmu} \\quad \\tilboldmu x \\\\\n",
    "\\\n",
    "\\text{\\xs} \\quad \\xs x \\\\\n",
    "\\text{\\ys} \\quad \\ys x \\\\\n",
    "\\text{\\zs} \\quad \\zs x \\\\\n",
    "\\text{\\Xs} \\quad \\Xs x \\\\\n",
    "\\text{\\Ys} \\quad \\Ys x \\\\\n",
    "\\text{\\Zs} \\quad \\Zs x \\\\\n",
    "\\\n",
    "\\text{\\Ndim} \\quad \\Ndim x \\\\\n",
    "\\text{\\Ddim} \\quad \\Ddim x \\\\\n",
    "\\text{\\Mdim} \\quad \\Mdim x \\\\\n",
    "\\text{\\Kdim} \\quad \\Kdim x \\\\\n",
    "\\text{\\Adim} \\quad \\Adim x \\\\\n",
    "\\text{\\Qdim} \\quad \\Qdim x \\\\\n",
    "\\text{\\Rdim} \\quad \\Rdim x \\\\\n",
    "\\\n",
    "\\text{\\mcalA} \\quad \\mcalA x \\\\\n",
    "\\text{\\mcalB} \\quad \\mcalB x \\\\\n",
    "\\text{\\mcalC} \\quad \\mcalC x \\\\\n",
    "\\text{\\mcalD} \\quad \\mcalD x \\\\\n",
    "\\text{\\mcalE} \\quad \\mcalE x \\\\\n",
    "\\text{\\mcalF} \\quad \\mcalF x \\\\\n",
    "\\text{\\mcalI} \\quad \\mcalI x \\\\\n",
    "\\text{\\mcalL} \\quad \\mcalL x \\\\\n",
    "\\text{\\mcalP} \\quad \\mcalP x \\\\\n",
    "\\text{\\mcalQ} \\quad \\mcalQ x \\\\\n",
    "\\text{\\mcalX} \\quad \\mcalX x \\\\\n",
    "\\text{\\hatmcalB} \\quad \\hatmcalB x \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{\\setA} \\quad \\setA x \\\\\n",
    "\\text{\\setB} \\quad \\setB x \\\\\n",
    "\\text{\\setC} \\quad \\setC x \\\\\n",
    "\\text{\\setE} \\quad \\setE x \\\\\n",
    "\\text{\\setD} \\quad \\setD x \\\\\n",
    "\\text{\\setS} \\quad \\setS x \\\\\n",
    "\\text{\\setT} \\quad \\setT x \\\\\n",
    "\\text{\\setV} \\quad \\setV x \\\\\n",
    "\\text{\\setW} \\quad \\setW x \\\\\n",
    "\\\n",
    "\\text{\\matA} \\quad \\matA x \\\\\n",
    "\\text{\\matB} \\quad \\matB x \\\\\n",
    "\\text{\\matC} \\quad \\matC x \\\\\n",
    "\\text{\\matD} \\quad \\matD x \\\\\n",
    "\\text{\\matE} \\quad \\matE x \\\\\n",
    "\\text{\\matI} \\quad \\matI x \\\\\n",
    "\\text{\\matU} \\quad \\matU x \\\\\n",
    "\\text{\\matV} \\quad \\matV x \\\\\n",
    "\\text{\\matW} \\quad \\matW x \\\\\n",
    "\\text{\\matPhi} \\quad \\matPhi x \\\\\n",
    "\\text{\\matPsi} \\quad \\matPsi x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\Factors} \\quad \\Factors x \\\\\n",
    "\\text{\\Variables} \\quad \\Variables x \\\\\n",
    "\\text{\\Eye} \\quad \\Eye x \\\\\n",
    "\\text{\\Zero} \\quad \\Zero x \\\\\n",
    "\\text{\\Energy} \\quad \\Energy x \\\\\n",
    "\\text{\\Entropy} \\quad \\Entropy x \\\\\n",
    "\\text{\\Fenergy} \\quad \\Fenergy x \\\\\n",
    "\\text{\\Edges} \\quad \\Edges x \\\\\n",
    "\\text{\\edge} \\quad \\edge x \\\\\n",
    "\\text{\\Vertices} \\quad \\Vertices x \\\\\n",
    "\\text{\\vertex} \\quad \\vertex x \\\\\n",
    "\\text{\\Graph} \\quad \\Graph x \\\\\n",
    "\\text{\\Tree} \\quad \\Tree x \\\\\n",
    "\\text{\\Children} \\quad \\Children x \\\\\n",
    "\\text{\\Parents} \\quad \\Parents x \\\\\n",
    "\\text{\\Adjacent} \\quad \\Adjacent x \\\\\n",
    "\\text{\\Pa} \\quad \\Pa x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\state} \\quad \\state x \\\\\n",
    "\\text{\\State} \\quad \\State x \\\\\n",
    "\\text{\\StateR} \\quad \\StateR x \\\\\n",
    "\\\n",
    "\\text{\\Covariance} \\quad \\Covariance x \\\\\n",
    "\\text{\\CovX} \\quad \\CovX x \\\\\n",
    "\\text{\\CovY} \\quad \\CovY x \\\\\n",
    "\\text{\\CovZ} \\quad \\CovZ x \\\\\n",
    "\\text{\\CovXY} \\quad \\CovXY x \\\\\n",
    "\\\n",
    "\\text{\\hatCovariance} \\quad \\hatCovariance x \\\\\n",
    "\\text{\\hatCovX} \\quad \\hatCovX x \\\\\n",
    "\\text{\\hatCovY} \\quad \\hatCovY x \\\\\n",
    "\\text{\\hatCovZ} \\quad \\hatCovZ x \\\\\n",
    "\\text{\\hatCovXY} \\quad \\hatCovXY x \\\\\n",
    "\\\n",
    "\\text{\\tildeCovariance} \\quad \\tildeCovariance x \\\\\n",
    "\\text{\\tildeCovX} \\quad \\tildeCovX x \\\\\n",
    "\\text{\\tildeCovY} \\quad \\tildeCovY x \\\\\n",
    "\\text{\\tildeCovZ} \\quad \\tildeCovZ x \\\\\n",
    "\\text{\\tildeCovXY} \\quad \\tildeCovXY x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\hatState} \\quad \\hatState x \\\\\n",
    "\\text{\\StateNum} \\quad \\StateNum x \\\\\n",
    "\\text{\\StateDim} \\quad \\StateDim x \\\\\n",
    "\\text{\\StateSet} \\quad \\StateSet x \\\\\n",
    "\\text{\\StatesSet} \\quad \\StatesSet x \\\\\n",
    "\\text{\\NumStates} \\quad \\NumStates x \\\\\n",
    "\\text{\\StateToState} \\quad \\StateToState x \\\\\n",
    "\\text{\\StateCov} \\quad \\StateCov x \\\\\n",
    "\\text{\\StateJac} \\quad \\StateJac x \\\\\n",
    "\\\n",
    "\\text{\\hatStateCov} \\quad \\hatStateCov x \\\\\n",
    "\\text{\\StateMean} \\quad \\StateMean x \\\\\n",
    "\\text{\\hatStateMean} \\quad \\hatStateMean x \\\\\n",
    "\\text{\\StateToStateHistory} \\quad \\StateToStateHistory x \\\\\n",
    "\\text{\\StateNoise} \\quad \\StateNoise x \\\\\n",
    "\\text{\\StateNoiseCov} \\quad \\StateNoiseCov x \\\\\n",
    "\\text{\\StateHistory} \\quad \\StateHistory x \\\\\n",
    "\\text{\\StatesHistory} \\quad \\StatesHistory x \\\\\n",
    "\\text{\\StateToObserv} \\quad \\StateToObserv x \\\\\n",
    "\\text{\\StateToobserv} \\quad \\StateToobserv x \\\\\n",
    "\\text{\\StateToObservHistory} \\quad \\StateToObservHistory x \\\\\n",
    "\\\n",
    "\\text{\\DState} \\quad \\DState x \\\\\n",
    "\\text{\\hatDState} \\quad \\hatDState x \\\\\n",
    "\\text{\\DStateMean} \\quad \\DStateMean x \\\\\n",
    "\\text{\\hatDStateMean} \\quad \\hatDStateMean x \\\\\n",
    "\\text{\\DStateCov} \\quad \\DStateCov x \\\\\n",
    "\\text{\\hatDStateCov} \\quad \\hatDStateCov x \\\\\n",
    "\\\n",
    "\\text{\\DObserv} \\quad \\DObserv x \\\\\n",
    "\\text{\\hatDObserv} \\quad \\hatDObserv x \\\\\n",
    "\\\n",
    "\\text{\\observ} \\quad \\observ x \\\\\n",
    "\\text{\\Observ} \\quad \\Observ x \\\\\n",
    "\\text{\\ObservCov} \\quad \\ObservCov x \\\\\n",
    "\\text{\\observMean} \\quad \\observMean x \\\\\n",
    "\\text{\\ObservMean} \\quad \\ObservMean x \\\\\n",
    "\\text{\\hatobserv} \\quad \\hatobserv x \\\\\n",
    "\\text{\\hatObserv} \\quad \\hatObserv x \\\\\n",
    "\\text{\\hatObservCov} \\quad \\hatObservCov x \\\\\n",
    "\\text{\\hatobservMean} \\quad \\hatobservMean x \\\\\n",
    "\\text{\\hatObservMean} \\quad \\hatObservMean x \\\\\n",
    "\\\n",
    "\\text{\\ObservSet} \\quad \\ObservSet x \\\\\n",
    "\\text{\\ObservNum} \\quad \\ObservNum x \\\\\n",
    "\\text{\\ObservDim} \\quad \\ObservDim x \\\\\n",
    "\\text{\\ObservSourceNum} \\quad \\ObservSourceNum x \\\\\n",
    "\\text{\\ObservHistory} \\quad \\ObservHistory x \\\\\n",
    "\\text{\\ObservsHistory} \\quad \\ObservsHistory x \\\\\n",
    "\\text{\\Timestamps} \\quad \\Timestamps x \\\\\n",
    "\\text{\\ObservJac} \\quad \\ObservJac x \\\\\n",
    "% Шум наблюдений\n",
    "\\text{\\observNoise} \\quad \\observNoise x \\\\\n",
    "\\text{\\ObservNoise} \\quad \\ObservNoise x \\\\\n",
    "\\text{\\ObservNoiseCov} \\quad \\ObservNoiseCov x \\\\\n",
    "\\text{\\ObservNoiseCovHistory} \\quad \\ObservNoiseCovHistory x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\control} \\quad \\control x \\\\\n",
    "\\text{\\Control} \\quad \\Control x \\\\\n",
    "\\text{\\ControlNum} \\quad \\ControlNum x \\\\\n",
    "\\text{\\ControToState} \\quad \\ControToState x \\\\\n",
    "\\text{\\ControlToStateHistory} \\quad \\ControlToStateHistory x \\\\\n",
    "\\text{\\ControlHistory} \\quad \\ControlHistory x \\\\\n",
    "\\\n",
    "\\text{\\Jacobian} \\quad \\Jacobian x \\\\\n",
    "\\\n",
    "\\text{\\Kalman} \\quad \\Kalman x \\\\\n",
    "\\text{\\kalman} \\quad \\kalman x \\\\\n",
    "\\\n",
    "\\text{\\vel} \\quad \\vel x \\\\\n",
    "$\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4fa596",
   "metadata": {},
   "source": [
    "## Python syntax <span id=Python_syntax_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db05651",
   "metadata": {},
   "source": [
    "### Fstrings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd858197",
   "metadata": {},
   "source": [
    "f\"{expression.format_spec}\"\n",
    "\n",
    "```\n",
    "format_spec     ::=  [[fill]align][sign][z][#][0][width][grouping_option][.precision][type]\n",
    "fill            ::=  <any character>\n",
    "align           ::=  \"<\" | \">\" | \"=\" | \"^\"\n",
    "sign            ::=  \"+\" | \"-\" | \" \"\n",
    "width           ::=  digit+\n",
    "grouping_option ::=  \"_\" | \",\"\n",
    "precision       ::=  digit+\n",
    "type            ::=  \"b\" | \"c\" | \"d\" | \"e\" | \"E\" | \"f\" | \"F\" | \"g\" | \"G\" | \"n\" | \"o\" | \"s\" | \"x\" | \"X\" | \"%\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ad468b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*3=6\n",
      "__repr__(s) = '123'\n",
      "braces {74}\n",
      "2023-03-20 19:04\n",
      "33.3333\n",
      "0.33333\n",
      "3.333333e-01\n",
      "007\n",
      "  7\n",
      "111\n",
      "000003e8\n",
      "   123\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "s = \"123\"\n",
    "width = 2\n",
    "precision = 6\n",
    "\n",
    "print(\n",
    "    f\"{2*3=}\",\n",
    "    f\"__repr__({s=}\".split(\"=\")[0] + f\") = {s!r}\",\n",
    "    f\"braces {{{70 + 4}}}\",\n",
    "    f\"{now:%Y-%m-%d %H:%M}\",\n",
    "    f\"{100/3:{width}.{precision}}\",\n",
    "    f\"{1 / 3:.5f}\",\n",
    "    f\"{1/3:e}\",\n",
    "    f\"{7:03}\",\n",
    "    f\"{7:3}\",\n",
    "    f\"{7:b}\",\n",
    "    f\"{1000:08x}\",\n",
    "    f\"{s:>6}\",\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025a250",
   "metadata": {},
   "source": [
    "### Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51a029a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:00:53.210137Z",
     "start_time": "2023-06-04T09:00:53.187529Z"
    }
   },
   "outputs": [],
   "source": [
    "class Point:\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "\n",
    "def match_point(point):\n",
    "    match point:\n",
    "        case Point(x=0, y=0):\n",
    "            ...\n",
    "        case Point(x=0, y=y):\n",
    "            ...\n",
    "        case Point(x=x, y=0):\n",
    "            ...\n",
    "        case Point(x, y) if x == y:\n",
    "            ...\n",
    "        case Point():\n",
    "            ...\n",
    "        case [Point(0, 0)]:\n",
    "            ...\n",
    "        case [Point(x, y)]:\n",
    "            ...\n",
    "        case [Point(0, y1), Point(0, y2)]:\n",
    "            ...\n",
    "        case (Point(x1, y1), Point(x2, y2) as p2):\n",
    "            ...\n",
    "        case _:\n",
    "            ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c680a",
   "metadata": {},
   "source": [
    "### Context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e5aadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextManager:\n",
    "    def __enter__(self):\n",
    "        ...\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
    "        ...\n",
    "\n",
    "\n",
    "with (\n",
    "    ContextManager() as cm1,\n",
    "    ContextManager() as cm2,\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d73044",
   "metadata": {},
   "source": [
    "### Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96e10385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iterator:\n",
    "    def __next__(self):\n",
    "        raise StopIteration\n",
    "\n",
    "\n",
    "class Iterable:\n",
    "    def __iter__(self):\n",
    "        return Iterator()\n",
    "\n",
    "\n",
    "for _ in Iterable():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b76c0f0",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f01dd07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 3, 5]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generator():\n",
    "    x = yield ...\n",
    "    yield x + 1\n",
    "    yield \"end\"\n",
    "    return 0\n",
    "\n",
    "\n",
    "def delegating_generator():\n",
    "    yield from generator()\n",
    "\n",
    "\n",
    "g = delegating_generator()\n",
    "next(g)\n",
    "g.send(3)\n",
    "for i in g:\n",
    "    print(i)\n",
    "\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def async_generator(delay, to):\n",
    "    \"\"\"Yield numbers from 0 to *to* every *delay* seconds.\"\"\"\n",
    "    for i in range(to):\n",
    "        yield i\n",
    "        await asyncio.sleep(delay)\n",
    "\n",
    "\n",
    "[i async for i in async_generator(0.1, 7) if i % 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c2541",
   "metadata": {},
   "source": [
    "### Except*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83308ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caught <class 'ExceptionGroup'> with nested (TypeError(2),)\n",
      "caught <class 'ExceptionGroup'> with nested (OSError(3), OSError(4))\n",
      "caught <class 'ExceptionGroup'> with nested (ValueError(1),)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    raise ExceptionGroup(\"eg\", [ValueError(1), TypeError(2), OSError(3), OSError(4)])\n",
    "except* TypeError as e:\n",
    "    print(f\"caught {type(e)} with nested {e.exceptions}\")\n",
    "except* OSError as e:\n",
    "    print(f\"caught {type(e)} with nested {e.exceptions}\")\n",
    "except* ValueError as e:\n",
    "    print(f\"caught {type(e)} with nested {e.exceptions}\")\n",
    "else:\n",
    "    print(\"No exception\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d43fe",
   "metadata": {},
   "source": [
    "### Type hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b5ac828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(number: int | float) -> int | float:\n",
    "    return number**2\n",
    "\n",
    "\n",
    "isinstance(1, int | str)\n",
    "\n",
    "import typing\n",
    "\n",
    "\n",
    "class MyLock:\n",
    "    def __enter__(self) -> typing.Self:\n",
    "        self.lock()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2df042",
   "metadata": {},
   "source": [
    "### Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10925dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(15).bit_count()\n",
    "zip([1, 2], [3, 4, 5], strict=True)\n",
    "(walrus := \":=\")\n",
    "breakpoint()\n",
    "\n",
    "\n",
    "def f(a, b, /, c, d, *, e, f):\n",
    "    ...\n",
    "\n",
    "\n",
    "def divmod(a, b, /):\n",
    "    \"Emulate the built in divmod() function -- no keyword arguments.\"\n",
    "    return (a // b, a % b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e085fa59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T10:11:21.916460Z",
     "start_time": "2023-06-01T10:11:21.911154Z"
    }
   },
   "source": [
    "### Styleguide <span id=Styleguide_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6ae4e",
   "metadata": {},
   "source": [
    "https://google.github.io/styleguide/pyguide.html\n",
    "\n",
    "Goes hand in hand with [black](https://black.readthedocs.io/en/stable/), [pylint](https://pylint.readthedocs.io/en/latest/user_guide/usage/index.html), [pyreverse](https://pylint.readthedocs.io/en/latest/pyreverse.html), [pydocstringformatter](https://github.com/DanielNoord/pydocstringformatter), [pytype](https://github.com/google/pytype) and [pydoc](https://docs.python.org/3/library/pydoc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fca71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!black ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f4653",
   "metadata": {},
   "source": [
    "### Jupyter extensions, magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc64cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c21ab",
   "metadata": {},
   "source": [
    "### Enabling extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d583ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jupyter_contrib_nbextensions\n",
    "!python -m jupyter contrib nbextension install --sys-prefix\n",
    "!python -m jupyter nbextension enable execute_time/ExecuteTime --sys-prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a6d6f1",
   "metadata": {},
   "source": [
    "### Configuring extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2f2550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T09:12:28.938465Z",
     "start_time": "2023-06-05T09:12:28.907440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ExecuteTime': {'display_absolute_timestamps': False,\n",
      "                 'highlight': {'use': False},\n",
      "                 'relative_timing_update_period': 5,\n",
      "                 'template': {'executed': '${duration}', 'queued': 'queued'}}}\n"
     ]
    }
   ],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(\n",
    "    ConfigManager().update(\n",
    "        \"notebook\",\n",
    "        {\n",
    "            \"ExecuteTime\": {\n",
    "                \"display_absolute_timestamps\": False,\n",
    "                \"relative_timing_update_period\": 5,\n",
    "                \"highlight\": {\"use\": False},\n",
    "                \"template\": {\"executed\": \"${duration}\", \"queued\": \"queued\"},\n",
    "            }\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec0ddb3",
   "metadata": {},
   "source": [
    "## Utils <span id=Utils_></span>\n",
    "- [Markdown](#Markdown_)\n",
    "- [Requirements](#Requirements_)\n",
    "- [Terminal](#Terminal_)\n",
    "- [Kaggle](#Kaggle_)\n",
    "- [Environment variables](#Environment_variables_)\n",
    "- [Gpu server](#Gpu_server_)\n",
    "- [Web](#Web_)\n",
    "- [Bijection](#Bijection_)\n",
    "- [Yadisk](#Yadisk_)\n",
    "- [Train test split](#Train_test_split_)\n",
    "- [Cache](#Cache_)\n",
    "- [Sparse](#Sparse_)\n",
    "- [Pandas](#Pandas_)\n",
    "- [Midjourney images to yadisk](#Midjourney_images_to_yadisk_)\n",
    "- [Clipboard](#Clipboard_)\n",
    "- [Markdown filtered directory tree](#Markdown_filtered_directory_tree_)\n",
    "- [Camel case to snake case](#Camel_case_to_snake_case_)\n",
    "- [Uml diagrams for modules](#Uml_diagrams_for_modules_)\n",
    "- [Sort arxiv links](#Sort_arxiv_links_)\n",
    "- [Batched iterator](#Batched_iterator_)\n",
    "- [Format .py and .ipynb files](#Format_.py_and_.ipynb_files_)\n",
    "- [Redraw figure in IPython](#Redraw_figure_in_IPython_)\n",
    "- [Torch training and evaluating pipeline template](#Torch_training_and_evaluating_pipeline_template_)\n",
    "- [Time it](#Time_it_)\n",
    "- [Video](#Video_)\n",
    "- [Path representation](#Path_representation_)\n",
    "- [SQLite](#SQLite_)\n",
    "- [Pyarrow](#Pyarrow_)\n",
    "- [Polars](#Polars_)\n",
    "- [Ace stream](#Ace_stream_)\n",
    "- [Exchange rates](#Exchange_rates_)\n",
    "- [Google sheets](#Google_sheets_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36268341",
   "metadata": {},
   "source": [
    "### Markdown <span id=Markdown_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c300ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T10:32:35.280632Z",
     "start_time": "2023-06-05T10:32:35.239862Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_new_markdown_section_with_link(section: str, header_size: int = 2):\n",
    "    header = \"#\" * header_size\n",
    "    section_id = section.replace(\" \", \"_\") + \"_\"\n",
    "    section_link = f\"{header} [{section}](#{section_id})\"\n",
    "    section_header = f\"{header} {section} <span id={section_id}></span>\"\n",
    "    return section_link, section_header\n",
    "\n",
    "\n",
    "import pyperclip\n",
    "\n",
    "\n",
    "def new_section_to_clipboard(section: str, header_size: int = 2):\n",
    "    pyperclip.copy(\"\\n\".join(make_new_markdown_section_with_link(section, header_size)))\n",
    "\n",
    "\n",
    "def make_several_sections(\n",
    "    section_names=(\n",
    "        \"Description\",\n",
    "        \"Research\",\n",
    "        \"Imports\",\n",
    "        \"Globals\",\n",
    "        \"Utils\",\n",
    "        \"Setup\",\n",
    "        \"Data\",\n",
    "        \"Data exploration\",\n",
    "        \"Metrics\",\n",
    "        \"Model\",\n",
    "        \"Training\",\n",
    "        \"Results\",\n",
    "    ),\n",
    "    header_size: int = 2,\n",
    "):\n",
    "    links, headers = zip(\n",
    "        *[make_new_markdown_section_with_link(sn, header_size) for sn in section_names]\n",
    "    )\n",
    "    print(\"\\n\".join(links + (\"\",) + headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e2ff5f",
   "metadata": {},
   "source": [
    "### Requirements <span id=Requirements_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75069401",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T10:32:35.280632Z",
     "start_time": "2023-06-05T10:32:35.239862Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_python_libraries_requirements() -> str:\n",
    "    python_version = sys.version\n",
    "    requirements = !pip freeze\n",
    "    requirements = \"\\n\".join(requirements)\n",
    "    requirements = (\n",
    "        f\"<details>\\n\"\n",
    "        f\"\\t<summary> Python requirements </summary>\\n\\n\"\n",
    "        f\"```\\n\"\n",
    "        f\"{python_version}\\n\\n\"\n",
    "        f\"{requirements}\\n\"\n",
    "        f\"```\\n\"\n",
    "        f\"</details>\"\n",
    "    )\n",
    "    return requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b177ec",
   "metadata": {},
   "source": [
    "### Terminal <span id=Terminal_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(path, error_if_exists=False):\n",
    "    !mkdir {\"-p\" if not error_if_exists else \"\"} {path}\n",
    "\n",
    "\n",
    "def unzip_all(zip_filepath: str) -> list[str]:\n",
    "    zip_file = zipfile.ZipFile(zip_filepath)\n",
    "    zip_file.extractall()\n",
    "    return zip_file.namelist()\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "def delete_zip(zip_path):\n",
    "    for path in glob.glob(zip_path):\n",
    "        if path.endswith(\".zip\"):\n",
    "            !trash {path}\n",
    "\n",
    "\n",
    "def wget_download_to_filepath(url: str, directory: str = \"\", filename: str = \"\") -> str:\n",
    "    filename = filename or os.path.basename(url)\n",
    "    filename = os.path.join(directory, filename)\n",
    "    !wget -O {filename} {url}\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc343e9f",
   "metadata": {},
   "source": [
    "### Kaggle <span id=Kaggle_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7137a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def save_kaggle_api_key(api_token: dict, kaggle_directory: str = \"~/.kaggle\"):\n",
    "    \"\"\"\n",
    "    Given the api token downloaded from https://www.kaggle.com/settings/account,\n",
    "    saves it, allowing to use the kaggle cli. Tokens expire quite often, and without\n",
    "    them kaggle may throw unauthorized access errors.\n",
    "    \"\"\"\n",
    "\n",
    "    kaggle_directory = os.path.expanduser(kaggle_directory)\n",
    "    os.makedirs(kaggle_directory, exist_ok=True)\n",
    "    api_token_json = os.path.join(kaggle_directory, \"kaggle.json\")\n",
    "    with open(api_token_json, \"w\") as file:\n",
    "        json.dump(api_token, file)\n",
    "\n",
    "    os.chmod(api_token_json, 0o600)\n",
    "\n",
    "\n",
    "def kaggle_competitions_search(search_term):\n",
    "    !kaggle competitions list -s {search_term}\n",
    "\n",
    "\n",
    "def kaggle_competitions_files(competition):\n",
    "    !kaggle competitions files {competition}\n",
    "\n",
    "\n",
    "def kaggle_competitions_download(competition, save_path=\"data\", filename=None):\n",
    "    os.mkdir(save_path)\n",
    "    !kaggle competitions download -p {save_path} {\"-f \" + filename if filename else \"\"} {competition}\n",
    "\n",
    "\n",
    "def kaggle_competitions_download_file(competition: str, filename: str, save_path: str):\n",
    "    relative_filename = os.path.join(save_path, filename)\n",
    "    save_path = os.path.join(save_path, os.path.split(filename)[0])\n",
    "    if os.path.exists(relative_filename):\n",
    "        print(f\"File `{relative_filename}` already exists.\")\n",
    "    else:\n",
    "        !kaggle competitions download {competition} -f {filename} -p {save_path}\n",
    "        zip_relative_filename = relative_filename + \".zip\"\n",
    "        if os.path.exists(zip_relative_filename):\n",
    "            unzip(zip_relative_filename, save_path=save_path, delete_zip=True)\n",
    "\n",
    "\n",
    "def kaggle_competitions_submit(competition, filename, message=\"submit\"):\n",
    "    !kaggle competitions submit -f {filename} -m {message} {competition}\n",
    "\n",
    "\n",
    "def kaggle_competitions_submissions(competition):\n",
    "    !kaggle competitions submissions {competition}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850ce15",
   "metadata": {},
   "source": [
    "### Environment variables <span id=Environment_variables_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d63a3e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:15:32.596309Z",
     "start_time": "2023-05-09T06:15:32.366728Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_tokenizers_parallelism(enable: bool):\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\" if enable else \"false\"\n",
    "\n",
    "\n",
    "def set_cuda_device_order_pci_bus():\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "\n",
    "import numba\n",
    "\n",
    "\n",
    "def set_numba_threads(n_threads: int):\n",
    "    numba.config.NUMBA_NUM_THREADS = num_threads\n",
    "    numba.config.THREADING_LAYER = \"threadsafe\"\n",
    "    numba.set_num_threads(num_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345de25f",
   "metadata": {},
   "source": [
    "### Gpu server <span id=Gpu_server_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf793ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:12:07.172733Z",
     "start_time": "2023-05-09T06:12:06.761202Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_shad_server_username_to_telegram_table_path():\n",
    "    home = os.environ[\"HOME\"]\n",
    "    return f\"{home}/shad_server_username_to_telegram.csv\"\n",
    "\n",
    "\n",
    "def read_shad_server_username_to_telegram_series() -> pd.Series:\n",
    "    df = pd.read_csv(get_shad_server_username_to_telegram_table_path())\n",
    "    series = df.set_index(\"server_username\")[\"telegram_username\"]\n",
    "    return series\n",
    "\n",
    "\n",
    "def update_shad_server_username_to_telegram_series():\n",
    "    s = read_shad_server_username_to_telegram_series()\n",
    "\n",
    "    s[\"sapetrov\"] = \"@PetrovSt\"\n",
    "    s[\"okgorbunova\"] = \"@elyaishere\"\n",
    "    s[\"jagiljazev\"] = \"@yulian_g\"\n",
    "    s[\"aaponomarev\"] = \"@Lexolordan\"\n",
    "    s[\"lmmurashov\"] = \"@leoneat\"\n",
    "    s[\"bvshelhonov\"] = \"@Boolean17\"\n",
    "    s[\"vierinova\"] = \"@vladlena_ermak\"\n",
    "    s[\"mdprokudin\"] = \"@mdprokudin\"\n",
    "    s[\"dkkoshman\"] = \"@DimaKoshman\"\n",
    "\n",
    "    s.to_csv(get_shad_server_username_to_telegram_table_path())\n",
    "\n",
    "\n",
    "def get_nvidia_smi_pid_column():\n",
    "    nvidia_smi_pid_column = !nvidia-smi | awk '{print $5}'\n",
    "    return nvidia_smi_pid_column\n",
    "\n",
    "\n",
    "def get_pid_username(pid: int) -> str:\n",
    "    username = !ps -o uname= -p {pid}\n",
    "    return username[0]\n",
    "\n",
    "\n",
    "def get_server_usernames_using_gpu() -> list[str]:\n",
    "    nvidia_smi_pid_column = get_nvidia_smi_pid_column()\n",
    "    pids_using_gpu = []\n",
    "    for row in nvidia_smi_pid_column[::-1]:\n",
    "        if row == \"PID\":\n",
    "            break\n",
    "        try:\n",
    "            pid = int(row)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        pids_using_gpu.append(int(pid))\n",
    "\n",
    "    usernames_using_gpu = [get_pid_username(pid) for pid in pids_using_gpu]\n",
    "    usernames_using_gpu = list(set(usernames_using_gpu))\n",
    "    return usernames_using_gpu\n",
    "\n",
    "\n",
    "def print_telegram_usernames_using_gpu():\n",
    "    server_to_telegram = read_shad_server_username_to_telegram_series()\n",
    "    usernames_using_gpu = get_server_usernames_using_gpu()\n",
    "\n",
    "    telegram_usernames_using_gpu = []\n",
    "    server_usernames_with_unknown_telegram_id = []\n",
    "    for username in usernames_using_gpu:\n",
    "        if username in server_to_telegram.index:\n",
    "            telegram_usernames_using_gpu.append(server_to_telegram[username])\n",
    "        else:\n",
    "            server_usernames_with_unknown_telegram_id.append(username)\n",
    "\n",
    "    print(\"Telegram ids of users using gpu:\")\n",
    "    print(\"\\n\".join(telegram_usernames_using_gpu))\n",
    "\n",
    "    if server_usernames_with_unknown_telegram_id:\n",
    "        print(\"Telegram id is unknown for users:\")\n",
    "        print(\"\\n\".join(server_usernames_with_unknown_telegram_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00de84",
   "metadata": {},
   "source": [
    "### Yadisk <span id=Yadisk_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd680e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:11:35.063356Z",
     "start_time": "2023-05-09T06:11:35.051966Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "\n",
    "\n",
    "def get_yadisk_download_url(\n",
    "    yadisk_url: str,\n",
    "    base_url=\"https://cloud-api.yandex.net/v1/disk/public/resources/download?\",\n",
    ") -> str:\n",
    "    final_url = base_url + urllib.parse.urlencode(dict(public_key=yadisk_url))\n",
    "    response = requests.get(final_url)\n",
    "    download_url = response.json()[\"href\"]\n",
    "    return download_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06a7d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:12:49.581830Z",
     "start_time": "2023-05-09T06:12:49.577720Z"
    }
   },
   "source": [
    "### Web <span id=Web_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_url_response_content_to_file(url: str, filename: str) -> None:\n",
    "    download_response = requests.get(url)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(download_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460ee3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:14:50.054595Z",
     "start_time": "2023-05-09T06:14:50.050652Z"
    }
   },
   "source": [
    "### Bijection <span id=Bijection_></span>\n",
    "\n",
    "Deprecated, check out [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Bijection:\n",
    "    keys: list\n",
    "    values: list\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if len(set(self.keys)) != len(set(self.values)):\n",
    "            raise RuntimeError(\"Bijection is not injective.\")\n",
    "\n",
    "        self._series = pd.Series(index=self.keys, data=self.values)\n",
    "        self._inverse_series = pd.Series(index=self.values, data=self.keys)\n",
    "\n",
    "    def loc(self, index) -> np.ndarray:\n",
    "        return self._series.loc[index].values\n",
    "\n",
    "    def inverse_loc(self, index) -> np.ndarray:\n",
    "        return self._inverse_series.loc[index].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "\n",
    "def build_compact_bijection(values):\n",
    "    values = np.unique(values)\n",
    "    return Bijection(keys=np.arange(len(values)), values=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a4980d",
   "metadata": {},
   "source": [
    "### Train test split <span id=Train_test_split_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_index(size, test_fraction: float, seed=None):\n",
    "    test_size = int(size * test_fraction)\n",
    "    np.random.seed(seed=seed)\n",
    "    index = np.random.permutation(size)\n",
    "    train_index = index[test_size:]\n",
    "    test_index = index[:test_size]\n",
    "    return train_index, test_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ed45b",
   "metadata": {},
   "source": [
    "### Cache <span id=Cache_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db12a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T08:07:51.452897Z",
     "start_time": "2023-06-06T08:07:51.391211Z"
    }
   },
   "outputs": [],
   "source": [
    "import typing\n",
    "from typing import Callable\n",
    "\n",
    "T = typing.TypeVar(\"T\")\n",
    "\n",
    "\n",
    "def load_if_exists_else_build_and_save(\n",
    "    path: str, load: Callable[[str], T], build_and_save: Callable[[str], T]\n",
    ") -> T:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Reusing file {path}\", file=sys.stderr)\n",
    "        return load(path)\n",
    "    return build_and_save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3ee58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:22:01.243719Z",
     "start_time": "2023-05-09T06:22:01.239360Z"
    }
   },
   "source": [
    "### Sparse <span id=Sparse_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a918bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csr_array_like(array):\n",
    "    return scipy.sparse.csr_array(array.shape, dtype=array.dtype)\n",
    "\n",
    "\n",
    "def slice_coo_array_by_entries_index(coo_array, index):\n",
    "    data = coo_array.data[index]\n",
    "    row = coo_array.row[index]\n",
    "    col = coo_array.col[index]\n",
    "    return scipy.sparse.coo_array(\n",
    "        (data, (row, col)), shape=coo_array.shape, dtype=coo_array.dtype\n",
    "    )\n",
    "\n",
    "\n",
    "def take_random_fraction_of_coo_array(coo_array, fraction: float, seed=None):\n",
    "    size = len(coo_array.data)\n",
    "    index = np.random.choice(size, size=int(size * fraction), replace=False)\n",
    "    coo_array = slice_coo_array_by_entries_index(coo_array, index)\n",
    "    return coo_array\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class IndexedCooArray:\n",
    "    coo_array: scipy.sparse.coo_array\n",
    "    row_index: np.ndarray\n",
    "    col_index: np.ndarray\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert self.coo_array.shape == (\n",
    "            len(self.row_index),\n",
    "            len(self.col_index),\n",
    "        ), \"Index shapes don't match.\"\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.coo_array.shape\n",
    "\n",
    "    def get_row_index_series(self):\n",
    "        return pd.Series(index=self.row_index, data=np.arange(self.shape[0]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        coo_array = self.coo_array.tocsr()[index].tocoo()\n",
    "        row_index = self.row_index[index]\n",
    "        col_index = self.col_index\n",
    "        return IndexedCooArray(\n",
    "            coo_array=coo_array, row_index=row_index, col_index=col_index\n",
    "        )\n",
    "\n",
    "\n",
    "def get_user_bool_index_with_at_least_n_interactions(csr_array, n_interactions: int):\n",
    "    index = csr_array.getnnz(axis=1) >= n_interactions\n",
    "    return index\n",
    "\n",
    "\n",
    "def get_item_bool_index_with_at_least_n_interactions(csr_array, n_interactions: int):\n",
    "    index = csr_array.getnnz(axis=0) >= n_interactions\n",
    "    return index\n",
    "\n",
    "\n",
    "def build_filtered_indexed_coo_array(\n",
    "    coo_array,\n",
    "    min_n_user_interactions_for_item: int,\n",
    "    min_n_item_interactions_for_user: int,\n",
    ") -> IndexedCooArray:\n",
    "    csr_array = coo_array.tocsr()\n",
    "    user_index = get_user_bool_index_with_at_least_n_interactions(\n",
    "        csr_array, min_n_item_interactions_for_user\n",
    "    )\n",
    "    item_index = get_item_bool_index_with_at_least_n_interactions(\n",
    "        csr_array, min_n_user_interactions_for_item\n",
    "    )\n",
    "\n",
    "    row_index = np.arange(coo_array.shape[0])[user_index]\n",
    "    col_index = np.arange(coo_array.shape[1])[item_index]\n",
    "\n",
    "    csr_array = csr_array[user_index][:, item_index]\n",
    "    coo_array = csr_array.tocoo()\n",
    "\n",
    "    indexed_coo_array = IndexedCooArray(coo_array, row_index, col_index)\n",
    "    return indexed_coo_array\n",
    "\n",
    "\n",
    "def remove_n_item_interactions_for_each_user(coo_array, n_items, seed=None):\n",
    "    n_interactions = len(coo_array.data)\n",
    "    index = np.arange(n_interactions)\n",
    "    df = pd.DataFrame(dict(row=coo_array.row, col=coo_array.col, index=index))\n",
    "\n",
    "    try:\n",
    "        df = df.groupby(\"row\").sample(n_items, random_state=seed)\n",
    "    except ValueError:\n",
    "        raise RuntimeError(f\"There are users with less than {n_items} interactions.\")\n",
    "\n",
    "    index_to_remove = df[\"index\"].values\n",
    "    index[:] = True\n",
    "    index[index_to_remove] = False\n",
    "    index = index.astype(bool)\n",
    "\n",
    "    coo_array = slice_coo_array_by_entries_index(coo_array, index)\n",
    "    return coo_array\n",
    "\n",
    "\n",
    "def train_test_split(\n",
    "    indexed_coo_array: IndexedCooArray,\n",
    "    n_item_interactions_to_split_as_ground_truth,\n",
    "    seed=None,\n",
    "):\n",
    "    test = copy.deepcopy(indexed_coo_array)\n",
    "\n",
    "    train_coo_array = remove_n_item_interactions_for_each_user(\n",
    "        coo_array=indexed_coo_array.coo_array,\n",
    "        n_items=n_item_interactions_to_split_as_ground_truth,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    train = indexed_coo_array\n",
    "    train.coo_array = train_coo_array\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def torch_tensor_to_scipy_coo(tensor: torch.Tensor) -> scipy.sparse.coo_array:\n",
    "    if tensor.ndim != 2:\n",
    "        raise ValueError(\"Only 2d tensors can be converted to sparse coo arrays.\")\n",
    "\n",
    "    tensor = tensor.detach().cpu().to_sparse_coo().coalesce()\n",
    "    values = tensor.values().numpy()\n",
    "    indices = tensor.indices().numpy()\n",
    "    sparse_coo_array = scipy.sparse.coo_array((values, indices), shape=tensor.shape)\n",
    "    return sparse_coo_array\n",
    "\n",
    "\n",
    "def scipy_coo_to_torch_tensor(coo_array: scipy.sparse.coo_array) -> torch.Tensor:\n",
    "    indices = torch.from_numpy(np.array([coo_array.row, coo_array.col]))\n",
    "    data = torch.from_numpy(coo_array.data)\n",
    "    tensor = torch.sparse_coo_tensor(indices=indices, values=data, size=coo_array.shape)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6e482",
   "metadata": {},
   "source": [
    "### Pandas <span id=Pandas_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b916ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_index(df):\n",
    "    df = df.loc[~df.index.duplicated(keep=\"first\")]\n",
    "    return df\n",
    "\n",
    "\n",
    "def dataframe_heatmap(df, axis=0):\n",
    "    style = df.style.background_gradient(\n",
    "        axis=axis, cmap=plt.colormaps[\"coolwarm\"], low=0.5, high=0.5\n",
    "    )\n",
    "    return style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5810f9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T08:33:06.178819Z",
     "start_time": "2023-05-24T08:33:06.172671Z"
    }
   },
   "source": [
    "### Midjourney images to yadisk <span id=Midjourney_images_to_yadisk_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a2bd0",
   "metadata": {},
   "source": [
    "YaDiskClient library with fixed bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75778e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T07:46:45.343660Z",
     "start_time": "2023-09-10T07:46:45.275079Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from warnings import warn\n",
    "\n",
    "from requests import request\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "class YaDiskException(Exception):\n",
    "    \"\"\"Common exception class for YaDisk. Arg 'code' have code of HTTP Error.\"\"\"\n",
    "\n",
    "    code = None\n",
    "\n",
    "    def __init__(self, code, text):\n",
    "        super(YaDiskException, self).__init__(text)\n",
    "        self.code = code\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{code}. {message}\".format(\n",
    "            code=self.code, message=super(YaDiskException, self).__str__()\n",
    "        )\n",
    "\n",
    "\n",
    "class YaDiskXML(object):\n",
    "    namespaces = {\"d\": \"DAV:\"}\n",
    "\n",
    "    def find(self, node, path):\n",
    "        \"\"\"Wrapper for lxml`s find.\"\"\"\n",
    "\n",
    "        return node.find(path, namespaces=self.namespaces)\n",
    "\n",
    "    def xpath(self, node, path):\n",
    "        \"\"\"Wrapper for lxml`s xpath.\"\"\"\n",
    "\n",
    "        return node.xpath(path, namespaces=self.namespaces)\n",
    "\n",
    "\n",
    "def _check_dst_absolute(dst):\n",
    "    if dst[0] != \"/\":\n",
    "        raise YaDiskException(400, \"Destination path must be absolute\")\n",
    "\n",
    "\n",
    "class YaDisk(object):\n",
    "    \"\"\"Main object for work with Yandex.disk.\"\"\"\n",
    "\n",
    "    token = None\n",
    "    login = None\n",
    "    password = None\n",
    "    url = \"https://webdav.yandex.ru/\"\n",
    "    namespaces = {\"d\": \"DAV:\"}\n",
    "\n",
    "    def set_token(self, token):\n",
    "        self.token = token\n",
    "        self.login = None\n",
    "        self.password = None\n",
    "\n",
    "    def set_auth(self, login, password):\n",
    "        self.token = None\n",
    "        self.login = login\n",
    "        self.password = password\n",
    "\n",
    "    def _sendRequest(self, type, addUrl=\"/\", addHeaders={}, data=None):\n",
    "        if self.token is None and (self.login is None or self.password is None):\n",
    "            raise YaDiskException(\n",
    "                400, \"Specify token or login/password for Yandex.Disk account.\"\n",
    "            )\n",
    "\n",
    "        headers = {\"Accept\": \"*/*\"}\n",
    "        auth = None\n",
    "        if self.token is not None:\n",
    "            headers[\"Authorization\"] = \"OAuth %s\" % self.token\n",
    "        else:\n",
    "            auth = (self.login, self.password)\n",
    "\n",
    "        headers.update(addHeaders)\n",
    "        url = self.url + addUrl\n",
    "        return request(type, url, headers=headers, auth=auth, data=data)\n",
    "\n",
    "    def ls(self, path, offset=None, amount=None):\n",
    "        \"\"\"\n",
    "        Return list of files/directories. Each item is a dict.\n",
    "        Keys: 'path', 'creationdate', 'displayname', 'length', 'lastmodified', 'isDir'.\n",
    "        \"\"\"\n",
    "\n",
    "        def parseContent(content):\n",
    "            result = []\n",
    "            root = ET.fromstring(content)\n",
    "            for response in root.findall(\".//d:response\", namespaces=self.namespaces):\n",
    "                node = {\n",
    "                    \"path\": response.find(\"d:href\", namespaces=self.namespaces).text,\n",
    "                    \"creationdate\": response.find(\n",
    "                        \"d:propstat/d:prop/d:creationdate\", namespaces=self.namespaces\n",
    "                    ).text,\n",
    "                    \"displayname\": response.find(\n",
    "                        \"d:propstat/d:prop/d:displayname\", namespaces=self.namespaces\n",
    "                    ).text,\n",
    "                    \"lastmodified\": response.find(\n",
    "                        \"d:propstat/d:prop/d:getlastmodified\",\n",
    "                        namespaces=self.namespaces,\n",
    "                    ).text,\n",
    "                    \"isDir\": response.find(\n",
    "                        \"d:propstat/d:prop/d:resourcetype/d:collection\",\n",
    "                        namespaces=self.namespaces,\n",
    "                    )\n",
    "                    != None,\n",
    "                }\n",
    "                if not node[\"isDir\"]:\n",
    "                    node[\"length\"] = response.find(\n",
    "                        \"d:propstat/d:prop/d:getcontentlength\",\n",
    "                        namespaces=self.namespaces,\n",
    "                    ).text\n",
    "                    node[\"etag\"] = response.find(\n",
    "                        \"d:propstat/d:prop/d:getetag\", namespaces=self.namespaces\n",
    "                    ).text\n",
    "                    node[\"type\"] = response.find(\n",
    "                        \"d:propstat/d:prop/d:getcontenttype\", namespaces=self.namespaces\n",
    "                    ).text\n",
    "                result.append(node)\n",
    "            return result\n",
    "\n",
    "        url = path\n",
    "        if (offset is not None) and (amount is not None):\n",
    "            url += \"?offset={offset}&amount={amount}\".format(\n",
    "                offset=offset, amount=amount\n",
    "            )\n",
    "        resp = self._sendRequest(\"PROPFIND\", url, {\"Depth\": \"1\"})\n",
    "        if resp.status_code == 207:\n",
    "            return parseContent(resp.content)\n",
    "        else:\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def df(self):\n",
    "        \"\"\"Return dict with size of Ya.Disk. Keys: 'available', 'used'.\"\"\"\n",
    "\n",
    "        def parseContent(content):\n",
    "            root = ET.fromstring(content)\n",
    "            return {\n",
    "                \"available\": root.find(\n",
    "                    \".//d:quota-available-bytes\", namespaces=self.namespaces\n",
    "                ).text,\n",
    "                \"used\": root.find(\n",
    "                    \".//d:quota-used-bytes\", namespaces=self.namespaces\n",
    "                ).text,\n",
    "            }\n",
    "\n",
    "        data = \"\"\"\n",
    "<D:propfind xmlns:D=\"DAV:\">\n",
    "  <D:prop>\n",
    "    <D:quota-available-bytes/>\n",
    "    <D:quota-used-bytes/>\n",
    "  </D:prop>\n",
    "</D:propfind>\n",
    "        \"\"\"\n",
    "        resp = self._sendRequest(\"PROPFIND\", \"/\", {\"Depth\": \"0\"}, data)\n",
    "        if resp.status_code == 207:\n",
    "            return parseContent(resp.content)\n",
    "        else:\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def mkdir(self, path):\n",
    "        \"\"\"Create directory. All part of path must be exists. Raise exception when path already exists.\"\"\"\n",
    "\n",
    "        resp = self._sendRequest(\"MKCOL\", path)\n",
    "        if resp.status_code != 201:\n",
    "            if resp.status_code == 409:\n",
    "                raise YaDiskException(\n",
    "                    409, \"Part of path {} does not exists\".format(path)\n",
    "                )\n",
    "            elif resp.status_code == 405:\n",
    "                raise YaDiskException(405, \"Path {} already exists\".format(path))\n",
    "            else:\n",
    "                raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def rm(self, path):\n",
    "        \"\"\"Delete file or directory.\"\"\"\n",
    "\n",
    "        resp = self._sendRequest(\"DELETE\", path)\n",
    "        # By documentation server must return 200 \"OK\", but I get 204 \"No Content\".\n",
    "        # Anyway file or directory have been removed.\n",
    "        if not (resp.status_code in (200, 204)):\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def cp(self, src, dst):\n",
    "        \"\"\"Copy file or directory.\"\"\"\n",
    "\n",
    "        _check_dst_absolute(dst)\n",
    "        resp = self._sendRequest(\"COPY\", src, {\"Destination\": dst})\n",
    "        if resp.status_code not in (201, 202):\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def mv(self, src, dst):\n",
    "        \"\"\"Move file or directory.\"\"\"\n",
    "\n",
    "        _check_dst_absolute(dst)\n",
    "        resp = self._sendRequest(\"MOVE\", src, {\"Destination\": dst})\n",
    "        if resp.status_code not in (201, 202):\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def upload(self, file, path):\n",
    "        \"\"\"Upload file.\"\"\"\n",
    "\n",
    "        with open(file, \"rb\") as f:\n",
    "            resp = self._sendRequest(\"PUT\", path, data=f)\n",
    "            if resp.status_code not in (201, 202):\n",
    "                raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def download(self, path, file):\n",
    "        \"\"\"Download remote file to disk.\"\"\"\n",
    "\n",
    "        resp = self._sendRequest(\"GET\", path)\n",
    "        if resp.status_code == 200:\n",
    "            with open(file, \"wb\") as f:\n",
    "                f.write(resp.content)\n",
    "        else:\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def publish(self, path):\n",
    "        \"\"\"Publish file or folder and return public url\"\"\"\n",
    "\n",
    "        def parseContent(content):\n",
    "            root = ET.fromstring(content)\n",
    "            prop = root.find(\".//d:prop\", namespaces=self.namespaces)\n",
    "            return prop.find(\"{urn:yandex:disk:meta}public_url\").text.strip()\n",
    "\n",
    "        data = \"\"\"\n",
    "<propertyupdate xmlns=\"DAV:\">\n",
    "  <set>\n",
    "    <prop>\n",
    "      <public_url xmlns=\"urn:yandex:disk:meta\">true</public_url>\n",
    "    </prop>\n",
    "  </set>\n",
    "</propertyupdate>\n",
    "        \"\"\"\n",
    "\n",
    "        _check_dst_absolute(path)\n",
    "        resp = self._sendRequest(\"PROPPATCH\", addUrl=path, data=data)\n",
    "        if resp.status_code == 207:\n",
    "            return parseContent(resp.content)\n",
    "        else:\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def unpublish(self, path):\n",
    "        \"\"\"Make public file or folder private (delete public url)\"\"\"\n",
    "\n",
    "        data = \"\"\"\n",
    "<propertyupdate xmlns=\"DAV:\">\n",
    "  <remove>\n",
    "    <prop>\n",
    "      <public_url xmlns=\"urn:yandex:disk:meta\" />\n",
    "    </prop>\n",
    "  </remove>\n",
    "</propertyupdate>\n",
    "        \"\"\"\n",
    "\n",
    "        _check_dst_absolute(path)\n",
    "        resp = self._sendRequest(\"PROPPATCH\", addUrl=path, data=data)\n",
    "        if resp.status_code == 207:\n",
    "            pass\n",
    "        else:\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def publish_doc(self, path):\n",
    "        warn(\n",
    "            'This method was deprecated in favor method \"publish\"',\n",
    "            DeprecationWarning,\n",
    "            stacklevel=2,\n",
    "        )\n",
    "        return self.publish(path)\n",
    "\n",
    "    def hide_doc(self, path):\n",
    "        warn(\n",
    "            'This method was deprecated in favor method \"unpublish\"',\n",
    "            DeprecationWarning,\n",
    "            stacklevel=2,\n",
    "        )\n",
    "        return self.unpublish(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5abd4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T07:50:18.306064Z",
     "start_time": "2023-09-10T07:50:18.009711Z"
    }
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import tqdm.autonotebook\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "yandex_client_id = \"3d5e193c86ba465f9d737bbdfdb28f33\"\n",
    "yandex_admin_url = f\"https://oauth.yandex.ru/client/{yandex_client_id}\"\n",
    "yandex_get_token_url = f\"https://oauth.yandex.ru/authorize?response_type=token&client_id={yandex_client_id}\"\n",
    "yandex_token = input(prompt=f\"Type in token from {yandex_get_token_url}\\n\")\n",
    "yadisk = YaDisk()\n",
    "yadisk.set_token(yandex_token)\n",
    "yadisk.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b6a29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T07:56:51.400741Z",
     "start_time": "2023-09-10T07:56:51.131374Z"
    }
   },
   "outputs": [],
   "source": [
    "midjourney_showcase = \"https://www.midjourney.com/showcase/recent/\"\n",
    "yadisk_folder = \"/midjourney/\"\n",
    "n_images = 100\n",
    "\n",
    "midjouney_response = requests.get(midjourney_showcase)\n",
    "content = midjouney_response.content.decode(\"utf-8\")\n",
    "image_urls = re.findall(r'\"seedImageURL\":\"(.*?)\"', content)\n",
    "\n",
    "print(\n",
    "    f\"Uploading images from {midjourney_showcase} \"\n",
    "    f\"to yandex disk folder https://disk.yandex.com/client/disk{yadisk_folder}:\"\n",
    ")\n",
    "for image_url in tqdm.autonotebook.tqdm(image_urls[:n_images]):\n",
    "    response = requests.get(image_url, stream=True)\n",
    "    image = PIL.Image.open(response.raw)\n",
    "    tmp_png = \"tmp.png\"\n",
    "    image.save(open(tmp_png, \"wb\"))\n",
    "    image_id = re.match(r\"https://cdn.midjourney.com/(.*?/.*)\", image_url).groups()[0]\n",
    "    image_id = image_id.replace(\"/\", \"_\")\n",
    "    yadisk.upload(tmp_png, yadisk_folder + image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849020f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T10:08:36.175514Z",
     "start_time": "2023-05-24T10:08:36.171120Z"
    }
   },
   "source": [
    "### Clipboard <span id=Clipboard_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a53390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:23:32.816550Z",
     "start_time": "2023-09-01T08:23:32.813222Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def clipboard_io(function: Callable[[str], str]) -> None:\n",
    "    \"\"\"Take input for function from clipboard and replace it with output.\"\"\"\n",
    "    pyperclip.copy(function(pyperclip.paste()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f24aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T17:55:13.228793Z",
     "start_time": "2023-05-31T17:55:13.196542Z"
    }
   },
   "source": [
    "### Markdown filtered directory tree <span id=Markdown_filtered_directory_tree_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67a24153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:23:56.007756Z",
     "start_time": "2023-09-01T08:23:55.991612Z"
    }
   },
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import os\n",
    "import pyperclip\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Tree:\n",
    "    root: str\n",
    "    filenames: list[str] = dataclasses.field(default_factory=list)\n",
    "    dirnames: dict[str, \"Tree\"] = dataclasses.field(default_factory=dict)\n",
    "\n",
    "    def __bool__(self):\n",
    "        return bool(self.filenames or self.dirnames)\n",
    "\n",
    "\n",
    "def build_filtered_tree(directory, filename_filter, dirname_filter) -> Tree:\n",
    "    tree = Tree(directory)\n",
    "\n",
    "    if not dirname_filter(os.path.split(directory)[1]):\n",
    "        return tree\n",
    "\n",
    "    _, dirnames, filenames = next(os.walk(directory))\n",
    "\n",
    "    for filename in filter(filename_filter, sorted(filenames)):\n",
    "        tree.filenames.append(filename)\n",
    "\n",
    "    for dirname in sorted(dirnames):\n",
    "        if subtree := build_filtered_tree(\n",
    "            os.path.join(directory, dirname), filename_filter, dirname_filter\n",
    "        ):\n",
    "            tree.dirnames[dirname] = subtree\n",
    "\n",
    "    return tree\n",
    "\n",
    "\n",
    "def build_markdown_filename_link(filename):\n",
    "    \"\"\"Assuming jupyter was launched from home directory.\"\"\"\n",
    "\n",
    "    jupyter_launch_dir = os.environ[\"HOME\"]\n",
    "    f = filename_relative_to_home = filename.removeprefix(jupyter_launch_dir)\n",
    "    bare_filename = os.path.splitext(os.path.split(f)[1])[0]\n",
    "    link = f\"[{bare_filename}](</tree{f}>)\"\n",
    "    return link\n",
    "\n",
    "\n",
    "def build_markdown_tree(tree: Tree, prefix=\"- \", dir_indent=\"  \"):\n",
    "    markdown_tree = \"\"\n",
    "\n",
    "    for filename in tree.filenames:\n",
    "        filename = os.path.join(tree.root, filename)\n",
    "        markdown_tree += prefix + build_markdown_filename_link(filename) + \"\\n\"\n",
    "\n",
    "    for dirname, subtree in tree.dirnames.items():\n",
    "        markdown_subtree = build_markdown_tree(subtree, dir_indent + prefix)\n",
    "        if markdown_subtree:\n",
    "            markdown_tree += prefix + dirname + \"\\n\"\n",
    "            markdown_tree += markdown_subtree\n",
    "\n",
    "    return markdown_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03ddcd12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:24:19.495547Z",
     "start_time": "2023-09-01T08:24:19.378669Z"
    }
   },
   "outputs": [],
   "source": [
    "notebook_tree = build_markdown_tree(\n",
    "    build_filtered_tree(\n",
    "        directory=os.path.dirname(os.getcwd()),\n",
    "        filename_filter=lambda f: f.endswith(\".ipynb\"),\n",
    "        dirname_filter=lambda d: d not in [\".ipynb_checkpoints\", \"python3.11\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "pyperclip.copy(notebook_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be2fad3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T18:34:39.098968Z",
     "start_time": "2023-05-31T18:34:39.058804Z"
    }
   },
   "outputs": [],
   "source": [
    "cpp_tree = build_markdown_tree(\n",
    "    build_filtered_tree(\n",
    "        directory=os.path.dirname(os.getcwd()),\n",
    "        filename_filter=lambda f: f.endswith(\".cpp\"),\n",
    "        dirname_filter=lambda d: not d.startswith(\"cmake-build\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "pyperclip.copy(cpp_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8b17d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T11:33:33.149072Z",
     "start_time": "2023-06-02T11:33:33.113532Z"
    }
   },
   "source": [
    "### Camel case to snake case <span id=Camel_case_to_snake_case_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26301303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def camel_case_to_snake(string):\n",
    "    string = re.sub(\"\\s+\", \"\", string)\n",
    "    words = re.split(r\"(?<=.)(?=[A-Z])\", string)\n",
    "    snake_case = \"_\".join(w.lower() for w in words)\n",
    "    return snake_case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05e3d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T13:08:17.120293Z",
     "start_time": "2023-06-02T13:08:17.115636Z"
    }
   },
   "source": [
    "### Uml diagrams for modules <span id=Uml_diagrams_for_modules_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c8643",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T13:16:46.131564Z",
     "start_time": "2023-06-02T13:16:46.106627Z"
    }
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import graphviz\n",
    "import os\n",
    "\n",
    "\n",
    "def build_uml_diagram_in_directory(\n",
    "    package_or_module_path: str, output_directory=\"tmp\"\n",
    ") -> str:\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    !pyreverse {package_or_module_path} --output-directory {output_directory}\n",
    "    return output_directory\n",
    "\n",
    "\n",
    "def load_graphviz_graphs(directory: str) -> list[graphviz.Source]:\n",
    "    graphs = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        filename = os.path.join(directory, filename)\n",
    "        graph = graphviz.Source.from_file(filename)\n",
    "        graphs.append(graph)\n",
    "\n",
    "    return graphs\n",
    "\n",
    "\n",
    "def display_uml_diagrams(package_or_module_path, **kwargs):\n",
    "    directory = build_uml_diagram_in_directory(package_or_module_path, **kwargs)\n",
    "    diagrams = load_graphviz_graphs(directory)\n",
    "\n",
    "    for diagram in diagrams:\n",
    "        IPython.display.display(diagram.filename)\n",
    "        IPython.display.display(diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51014a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-03T14:06:11.933963Z",
     "start_time": "2023-06-03T14:06:06.176258Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_uml_diagrams(\"/Users/dimakoshman/YSDA/my_tools/my_tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ea834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:07:29.819713Z",
     "start_time": "2023-06-04T09:07:29.787144Z"
    }
   },
   "source": [
    "### Sort arxiv links <span id=Sort_arxiv_links_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea86aab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:22:46.795346Z",
     "start_time": "2023-09-01T08:22:46.784902Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "import re\n",
    "import sys\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def get_arxiv_id(arxiv_link: str) -> int:\n",
    "    arxiv_link_pattern = r\"https://arxiv\\.org/pdf/(?P<id>.+)\\.pdf\"\n",
    "    match = re.search(arxiv_link_pattern, arxiv_link)\n",
    "\n",
    "    if match is None:\n",
    "        message = f'Arxiv link \"{arxiv_link}\" doesn\\'t match expected pattern.'\n",
    "        print(message, file=sys.stderr)\n",
    "\n",
    "    arxiv_id = match.group(\"id\")\n",
    "    arxiv_id = int(arxiv_id.replace(\".\", \"\"))\n",
    "    return arxiv_id\n",
    "\n",
    "\n",
    "def sort_arxiv_links_by_time(arxiv_links: str or list[str]):\n",
    "    if isinstance(arxiv_links, str):\n",
    "        arxiv_links = arxiv_links.splitlines()\n",
    "\n",
    "    sorted_arxiv_links = sorted(arxiv_links, key=get_arxiv_id)\n",
    "    return \"\\n\".join(sorted_arxiv_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec5832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:21:33.313148Z",
     "start_time": "2023-09-01T08:21:33.261166Z"
    }
   },
   "outputs": [],
   "source": [
    "clipboard_io(sort_arxiv_links_by_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129384cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T10:33:15.951628Z",
     "start_time": "2023-06-05T10:33:15.912638Z"
    }
   },
   "source": [
    "### Batched iterator <span id=Batched_iterator_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ae8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def batched(iterable, n) -> tp.Generator[list, None, None]:\n",
    "    \"\"\"\n",
    "    Batch data into tuples of length n. The last batch may be shorter.\n",
    "\n",
    "    batched('ABCDEFG', 3) --> ABC DEF G\n",
    "    \"\"\"\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be at least one.\")\n",
    "\n",
    "    it = iter(iterable)\n",
    "    while batch := list(itertools.islice(it, n)):\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede644e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T13:34:58.575861Z",
     "start_time": "2023-06-06T13:34:58.573223Z"
    }
   },
   "source": [
    "### Format .py and .ipynb files <span id=Format_.py_and_.ipynb_files_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82eb97b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:20:43.709053Z",
     "start_time": "2023-09-01T08:20:43.700331Z"
    }
   },
   "outputs": [],
   "source": [
    "def black_format(path=\".\"):\n",
    "    !black {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542ee4fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T14:46:30.453458Z",
     "start_time": "2023-06-06T14:46:30.415711Z"
    }
   },
   "source": [
    "### Redraw figure in IPython <span id=Redraw_figure_in_IPython_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def redraw_figure():\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    IPython.display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26315c3",
   "metadata": {},
   "source": [
    "### Torch training and evaluating pipeline template <span id=Torch_training_and_evaluating_pipeline_template_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "@dataclasses.dataclass(kw_only=True)\n",
    "class Config:\n",
    "    is_debugging:bool = True\n",
    "    ...\n",
    "        \n",
    "        \n",
    "def is_debugging() -> bool:\n",
    "    return Config.is_debugging\n",
    "\n",
    "\n",
    "def metric(...):\n",
    "    ...\n",
    "\n",
    "    \n",
    "class LightningModule(pl.LightningModule):\n",
    "    def __init__(self, ...):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        ...\n",
    "\n",
    "    def forward(self, ...):\n",
    "        preds = ...\n",
    "        return preds\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_id):\n",
    "        preds = self(...)\n",
    "        loss = ...\n",
    "        self.log(\"loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_id):\n",
    "        preds = self(...)\n",
    "        ...\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer\n",
    "    \n",
    "\n",
    "def main(**kwargs):\n",
    "    wandb.init(config= ..., project=...)\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=...,\n",
    "        shuffle=True,\n",
    "        batch_size=...,\n",
    "    )\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=...,\n",
    "        batch_size=...,\n",
    "    )\n",
    "    early_stopping_callback = pl.callbacks.EarlyStopping(\n",
    "        monitor=...,\n",
    "        mode=...,\n",
    "        min_delta=...,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=...,\n",
    "        devices=...,\n",
    "        logger=pl.loggers.WandbLogger(),\n",
    "        callbacks=[\n",
    "            early_stopping_callback,\n",
    "            ...,\n",
    "        ],\n",
    "        val_check_interval=...,\n",
    "        accumulate_grad_batches=...,\n",
    "        fast_dev_run=...,\n",
    "    )\n",
    "    model = LightningModule(...)\n",
    "    trainer.fit(\n",
    "        model=...,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040876d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:29:57.193379Z",
     "start_time": "2023-09-01T08:29:57.163903Z"
    }
   },
   "source": [
    "### Time it <span id=Time_it_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbbb249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def time_it(name: str = \"\", file=sys.stderr):\n",
    "    begin = time.perf_counter()\n",
    "    yield\n",
    "    end = time.perf_counter()\n",
    "    name = name + \":\\t\" if name else \"\"\n",
    "    delta_ms = 1000 * (end - begin)\n",
    "    print(f\"{name}{delta_ms:.3f} ms\", file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17189d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:33:31.126955Z",
     "start_time": "2023-09-01T08:33:31.091345Z"
    }
   },
   "source": [
    "### Video <span id=Video_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6182b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:34:08.387589Z",
     "start_time": "2023-09-01T08:34:08.005291Z"
    }
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import imageio\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def build_background_video(\n",
    "    n_frames: int,\n",
    "    width: int = 300,\n",
    "    height: int = 300,\n",
    "    n_channels: int = 3,\n",
    "    color: tuple[int] = (0, 0, 0),\n",
    ") -> np.ndarray:\n",
    "    video = np.full(\n",
    "        shape=[n_frames, width, height, n_channels],\n",
    "        fill_value=color,\n",
    "        dtype=np.uint8,\n",
    "    )\n",
    "    return video\n",
    "\n",
    "\n",
    "def write_gif(uri: str, images: np.ndarray, fps=30) -> None | bytes:\n",
    "    encoded_image = imageio.v3.imwrite(uri, images, loop=0, duration=len(images) / fps)\n",
    "    return encoded_image\n",
    "\n",
    "\n",
    "def display_video(video: np.ndarray) -> None:\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".gif\") as gif:\n",
    "        filename = gif.name\n",
    "        write_gif(filename, video)\n",
    "        IPython.display.display(IPython.display.Image(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3db19",
   "metadata": {},
   "source": [
    "### Path representation <span id=Path_representation_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reprlib\n",
    "import pprint\n",
    "\n",
    "# Or use the `tree` cli if available\n",
    "\n",
    "\n",
    "def path_to_dict(path):\n",
    "    _, dirnames, filenames = next(os.walk(path))\n",
    "    path_contents = filenames + [path_to_dict(os.path.join(path, i)) for i in dirnames]\n",
    "    return {os.path.basename(path): path_contents}\n",
    "\n",
    "\n",
    "def pprint_path_contents(path):\n",
    "    path_dict = path_to_dict(path)\n",
    "    short_path_repr = reprlib.repr(path_dict)\n",
    "    short_path_dict = eval(short_path_repr)\n",
    "    string = pprint.pformat(short_path_dict).replace(\"Ellipsis\", \"...\")\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c41caa",
   "metadata": {},
   "source": [
    "### SQLite <span id=SQLite_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5906e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import tqdm.auto\n",
    "\n",
    "\n",
    "def get_db_connection(database: str) -> contextlib.closing:\n",
    "    return contextlib.closing(sqlite3.connect(database))\n",
    "\n",
    "\n",
    "def get_all_db_tables() -> list[str]:\n",
    "    with get_db_connection() as con:\n",
    "        cur = con.execute(\"select name from sqlite_master where type='table'\")\n",
    "        return [i for i, in cur.fetchall()]\n",
    "\n",
    "\n",
    "def get_db_table_info(table: str) -> pd.DataFrame:\n",
    "    with get_db_connection() as con:\n",
    "        cur = con.execute(f\"PRAGMA table_info('{table}')\")\n",
    "        table_info = cur.fetchall()\n",
    "\n",
    "    table_info = pd.DataFrame(\n",
    "        table_info,\n",
    "        columns=[\"index\", \"name\", \"type\", \"notnull\", \"default\", \"primary_key\"],\n",
    "    )\n",
    "    table_info = table_info.set_index(\"index\")\n",
    "    return table_info\n",
    "\n",
    "\n",
    "def drop_database(database: str) -> None:\n",
    "    os.remove(database)\n",
    "\n",
    "\n",
    "def load_tables_into_db(chunksize: int = 100_000) -> None:\n",
    "    \"\"\"Very slow for sqlite3, as it doesn't support sparse columns.\"\"\"\n",
    "    table_groups = get_table_groups()\n",
    "    with get_db_connection() as con:\n",
    "        for _, row in tqdm.auto.tqdm(table_groups.iterrows(), total=len(table_groups)):\n",
    "            df = pd.read_parquet(os.path.join(row[\"path\"]))\n",
    "            df.to_sql(row[\"name\"], con=con, if_exists=\"append\", chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c3e76",
   "metadata": {},
   "source": [
    "### Pyarrow <span id=Pyarrow_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed15978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "\n",
    "def set_column(table: pa.Table, column_name: str, column: pa.Array) -> pa.Table:\n",
    "    return table.set_column(\n",
    "        i=table.column_names.index(column_name), field_=column_name, column=column\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b3e780-14f6-4dd4-a651-ae05a9f7ac1f",
   "metadata": {},
   "source": [
    "### Polars <span id=Polars_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d8dc9-f199-4bfa-bc34-df6fa0823c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "\n",
    "def filter_all_null_rows(df):\n",
    "    df = df.filter(pl.all_horizontal(pl.all().is_null()).not_())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5acbb-9de4-440d-b340-4496885fd12e",
   "metadata": {},
   "source": [
    "### Ace stream <span id=Ace_stream_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ea298b-345f-4c37-ad34-95cee0eeed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_local_ace_url(\n",
    "    ace_url: str, docker_port: int = 8000, server_ip: str = \"127.0.0.1\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    To watch ace streams:\n",
    "\n",
    "        1. Start docker daemon in terminal or just open desktop docker app.\n",
    "        2. Pull docker image:\n",
    "            docker pull ikatson/aceproxy:latest\n",
    "        3. Run docker image:\n",
    "            docker run -t -p 8000:8000 ikatson/aceproxy\n",
    "        4. Get ace stream url in format acestream://{stream_id}.\n",
    "        5. Parse url using this function.\n",
    "        6. Go to VLC player -> Open Network -> enter url -> watch.\n",
    "\n",
    "    Example url:\n",
    "    http://127.0.0.1:8000/pid/b28db77c5084da7993395d77df96c30bb134f0a9/stream.mp4\n",
    "    \"\"\"\n",
    "    match = re.fullmatch(pattern=r\"acestream://(?P<stream_id>.+)\", string=ace_url)\n",
    "    stream_id = match.group(\"stream_id\")\n",
    "    url = f\"http://{server_ip}:{docker_port}/pid/{stream_id}/stream.mp4\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48b3335-fc5b-4069-bdd3-4e91863d6b13",
   "metadata": {},
   "source": [
    "### Exchange rates <span id=Exchange_rates_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a043e24-524c-4def-bed5-dcbc67b0fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def fetch_exchange_rates(\n",
    "    currencyfreaks_api_key_path:str = \"/Users/dimakoshman/secrets/currencyfreaks_api_key.txt\") -> dict[str, float]:\n",
    "    with open(currencyfreaks_api_key_path) as f:\n",
    "        apikey = f.read()\n",
    "        \n",
    "    response = requests.get(\"https://api.currencyfreaks.com/v2.0/rates/latest\", params=dict(apikey=apikey))\n",
    "    content = json.loads(response.content)\n",
    "    rates = {code: float(rate) for code, rate in content[\"rates\"].items()}\n",
    "    return rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d204ad31-b83f-4c96-9f72-6945df2e9439",
   "metadata": {},
   "source": [
    "### Google sheets <span id=Google_sheets_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12492f04-c117-4125-8f62-bcf2cb919ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Iterable\n",
    "\n",
    "import google\n",
    "import google_auth_oauthlib\n",
    "import googleapiclient\n",
    "import googleapiclient.discovery\n",
    "\n",
    "\n",
    "def fetch_credentials(\n",
    "    credentials_json:str=\"/Users/dimakoshman/secrets/client_secret_914741765622-n2qe9tc9o8rt6uanca88ngjss4spg0pa.apps.googleusercontent.com.json\",\n",
    "    cached_credentials_path: str = \"token.json\",\n",
    "    scopes: Iterable[str] = (\"https://www.googleapis.com/auth/spreadsheets.readonly\",),\n",
    ") -> google.oauth2.credentials.Credentials:\n",
    "    if os.path.exists(cached_credentials_path):\n",
    "        credentials = google.oauth2.credentials.Credentials.from_authorized_user_file(\n",
    "            cached_credentials_path, scopes\n",
    "        )\n",
    "\n",
    "    if not credentials or not credentials.valid:\n",
    "        if credentials and credentials.expired and credentials.refresh_token:\n",
    "            credentials.refresh(google.auth.transport.requests.Request())\n",
    "        else:\n",
    "            flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "                credentials_json, scopes\n",
    "            )\n",
    "            credentials = flow.run_local_server(port=0)\n",
    "\n",
    "        with open(cached_credentials_path, \"w\") as cache:\n",
    "            cache.write(credentials.to_json())\n",
    "\n",
    "    return credentials\n",
    "\n",
    "def fetch_sheet_range(spreadsheet_id:str, sheet_range:str=\"A:Z\") -> list:\n",
    "    sheets_service = googleapiclient.discovery.build(\n",
    "        \"sheets\", \"v4\", credentials=fetch_credentials()\n",
    "    )\n",
    "    fetched_range = (\n",
    "        sheets_service.spreadsheets()\n",
    "        .values()\n",
    "        .get(spreadsheetId=spreadsheet_id, range=sheet_range)\n",
    "        .execute()\n",
    "    )\n",
    "    values = fetched_range[\"values\"]\n",
    "    return values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a60231-72ed-41c5-818d-d1bf0730b3be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
