{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98dd26d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T10:12:50.949914Z",
     "start_time": "2023-10-19T10:12:50.940572Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "\n",
    "\n",
    "def make_new_markdown_section_with_link(section: str, header_size: int = 2) -> tuple[str, str]:\n",
    "    header = \"#\" * header_size\n",
    "    section_id = section.replace(\" \", \"_\") + \"_\"\n",
    "    section_link = f\"{header} [{section}](#{section_id})\"\n",
    "    section_header = f\"{header} {section} <span id={section_id}></span>\"\n",
    "    return section_link, section_header\n",
    "\n",
    "\n",
    "def new_section_to_clipboard(section: str, header_size: int = 2):\n",
    "    pyperclip.copy(\"\\n\".join(make_new_markdown_section_with_link(section, header_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088d688",
   "metadata": {},
   "source": [
    "## [Todo](#Todo_)\n",
    "## [Resources](#Resources_)\n",
    "- ### [Documentation](#Documentation_)\n",
    "- ### [Notebooks](#Notebooks_)\n",
    "- ### [Research papers](#Research_)\n",
    "- ### [Confluence](https://koshmandk.atlassian.net/wiki/spaces/)\n",
    "- ### [Notes](#Notes_)\n",
    "## [Languages](#Languages_)\n",
    "- ### [Markdown syntax](#Markdown_syntax_)\n",
    "- ### [Tex syntax](#Tex_syntax_)\n",
    "- ### [Python syntax](#Python_syntax_)\n",
    "    - ### [Styleguide](#Styleguide_)\n",
    "- ### [Jupyter extensions](#Jupyter-extensions,-magic)\n",
    "- ### [Cli](#Cli_)\n",
    "## [Utils](#Utils_)\n",
    "- [Markdown](#Markdown_)\n",
    "- [Terminal](#Terminal_)\n",
    "- [Kaggle](#Kaggle_)\n",
    "- [Environment variables](#Environment_variables_)\n",
    "- [Gpu server](#Gpu_server_)\n",
    "- [Yadisk](#Yadisk_)\n",
    "- [Web](#Web_)\n",
    "- [Bijection](#Bijection_)\n",
    "- [Train test split](#Train_test_split_)\n",
    "- [Cache](#Cache_)\n",
    "- [Sparse](#Sparse_)\n",
    "- [Pandas](#Pandas_)\n",
    "- [Midjourney images to yadisk](#Midjourney_images_to_yadisk_)\n",
    "- [Clipboard](#Clipboard_)\n",
    "- [Markdown filtered directory tree](#Markdown_filtered_directory_tree_)\n",
    "- [Camel case to snake case](#Camel_case_to_snake_case_)\n",
    "- [Uml diagrams for modules](#Uml_diagrams_for_modules_)\n",
    "- [Sort arxiv links](#Sort_arxiv_links_)\n",
    "- [Batched iterator](#Batched_iterator_)\n",
    "- [Format .py and .ipynb files](#Format_.py_and_.ipynb_files_)\n",
    "- [Redraw figure in IPython](#Redraw_figure_in_IPython_)\n",
    "- [Torch training and evaluating pipeline template](#Torch_training_and_evaluating_pipeline_template_)\n",
    "- [Time it](#Time_it_)\n",
    "- [Video](#Video_)\n",
    "- [Algorithms](#Algorithms_)\n",
    "\n",
    "\n",
    "## [Modules](#Modules_)\n",
    "- [Dataclasses](#Dataclasses-module)\n",
    "- [Parsimonious](#Parsimonious_)\n",
    "- [Gradio](#Gradio_)\n",
    "- [graph-tool](#graph-tool_)\n",
    "- [Ray](#Ray_)\n",
    "- [Seaborn](#Seaborn_)\n",
    "- [Bokeh](#Bokeh_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b44c1",
   "metadata": {},
   "source": [
    "## Todo <span id=Todo_></span> \n",
    "\n",
    "1. Review this cookbook, papers, code.\n",
    "1. Choose a scheduler: yandex calendar, jupyter notebook, jira, paper notebook?\n",
    "1. Create demos for various ml tasks: translation, image segmentation, pose detection, image generation, etc.\n",
    "1. Repeat statistics course\n",
    "1. Do some leetcode exercises\n",
    "\n",
    "\n",
    "### Secondary\n",
    "1. [Stepik Stats](https://stepik.org/course/326/syllabus)\n",
    "1. https://www.coursera.org/specializations/machine-learning-introduction\n",
    "1. Try population based training: https://docs.ray.io/en/latest/tune/examples/pbt_guide.html\n",
    "1. Download Mojo\n",
    "1. Make demos for the various ml skills I have\n",
    "1. https://www.kaggle.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d10719",
   "metadata": {},
   "source": [
    "## Resources <span id=Resources_></span>\n",
    "\n",
    "- Video\n",
    "    - [Лекции Воронцова](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%28%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9%2C_%D0%9A.%D0%92.%D0%92%D0%BE%D1%80%D0%BE%D0%BD%D1%86%D0%BE%D0%B2%29)\n",
    "    - https://www.youtube.com/@TwoMinutePapers/videos\n",
    "    - https://www.youtube.com/@Fireship/videos\n",
    "    - [Курс глубинного обучения](https://www.youtube.com/playlist?list=PLJOzdkh8T5kpL2y8-lhHOlBxzLszSyDa0)\n",
    "- News\n",
    "    - https://medium.com\n",
    "    - https://towardsdatascience.com\n",
    "    - https://www.marktechpost.com\n",
    "    - https://wandb.ai/fully-connected\n",
    "    - https://www.midjourney.com/showcase/recent/\n",
    "    - https://github.com/openai/openai-cookbook/tree/main\n",
    "- Research\n",
    "    - https://huggingface.co/papers\n",
    "    - https://paperswithcode.com\n",
    "    - https://nn.labml.ai - annotated paper implementations\n",
    "    - https://koshmandk.atlassian.net/wiki/spaces/YSDA/overview\n",
    "    - https://academy.yandex.ru/handbook/ml\n",
    "    - https://distill.pub\n",
    "    - https://madewithml.com\n",
    "    - https://www.deeplearningbook.org\n",
    "    - [ML systems design](https://stanford-cs329s.github.io)\n",
    "- Practice and courses\n",
    "    - https://www.kaggle.com/\n",
    "           - [Kaggle winning solution writeups](https://www.kaggle.com/code/sudalairajkumar/winning-solutions-of-kaggle-competitions)\n",
    "        - [Kaggle ai report 2023](https://www.kaggle.com/competitions/2023-kaggle-ai-report/discussion/429989)\n",
    "    - https://www.eolymp.com/ru/\n",
    "    - https://stepik.org/\n",
    "    - https://www.coursera.org/\n",
    "    - https://lena-voita.github.io/nlp_course.html\n",
    "    - https://huggingface.co/learn/nlp-course\n",
    "    - https://huggingface.co/learn/deep-rl-course\n",
    "    - https://learn.deeplearning.ai/diffusion-models\n",
    "    - https://learn.deeplearning.ai/chatgpt-prompt-eng/\n",
    "    - https://www.deeplearning.ai/courses/\n",
    "    - https://www.wandb.courses/pages/w-b-courses\n",
    "    https://leetcode.com\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7e6a64",
   "metadata": {},
   "source": [
    "### Documentation <span id=Documentation_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b8dc1",
   "metadata": {},
   "source": [
    "- [sklearn](https://scikit-learn.org/stable/)\n",
    "- [scipy](https://docs.scipy.org/doc/scipy/tutorial/index.html#user-guide)\n",
    "- [torch](https://pytorch.org)\n",
    "    - [masked tensor](https://pytorch.org/docs/stable/masked.html)\n",
    "    - [named tensor](https://pytorch.org/docs/stable/named_tensor.html)\n",
    "- [transformers](https://huggingface.co/course/chapter0/1?fw=pt)\n",
    "    - [agents](https://huggingface.co/docs/transformers/transformers_agents)\n",
    "- [numpy](https://numpy.org/doc/stable/user/index.html#user)\n",
    "- [numba](https://numba.readthedocs.io/en/stable/user/index.html)\n",
    "    - [tutorial](https://github.com/ContinuumIO/gtc2018-numba/blob/master/1%20-%20Numba%20Basics.ipynb)\n",
    "- [pytest](https://docs.pytest.org/en/7.3.x/how-to/index.html#how-to)\n",
    "- [sqlalchemy](https://docs.sqlalchemy.org/en/20/index.html)\n",
    "- [databutton: build multipage web apps with ai assistant](https://docs.databutton.com)\n",
    "- [langchain: utilize llms in apps](https://python.langchain.com/docs/get_started/introduction.html)\n",
    "    - [tutorial](https://learn.deeplearning.ai/langchain/)\n",
    "    - [chatgpt tutorial](https://learn.deeplearning.ai/chatgpt-building-system/)\n",
    "- [mediapipe](https://developers.google.com/mediapipe/framework/getting_started/python_framework)\n",
    "\n",
    "### Other\n",
    "- [Mojo language](https://docs.modular.com/mojo/changelog.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2f1b1",
   "metadata": {},
   "source": [
    "### Notebooks <span id=Notebooks_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b661f",
   "metadata": {},
   "source": [
    "- algorithms\n",
    "  - [algorithms_2_theory_2](</tree/YSDA/algorithms/algorithms_2_theory_2.ipynb>)\n",
    "- books\n",
    "  - Probability and statistics\n",
    "    - [случайность](</tree/YSDA/books/Probability and statistics/случайность.ipynb>)\n",
    "- coderun_2023\n",
    "  - [coderun_ds_1](</tree/YSDA/coderun_2023/coderun_ds_1.ipynb>)\n",
    "  - [coderun_ml_1](</tree/YSDA/coderun_2023/coderun_ml_1.ipynb>)\n",
    "  - [coderun_ml_2](</tree/YSDA/coderun_2023/coderun_ml_2.ipynb>)\n",
    "- dependency_recovery\n",
    "  - [HW4](</tree/YSDA/dependency_recovery/HW4.ipynb>)\n",
    "- machine_learning\n",
    "  - [lab_backpropagation](</tree/YSDA/machine_learning/lab_backpropagation.ipynb>)\n",
    "  - [lab_cnn](</tree/YSDA/machine_learning/lab_cnn.ipynb>)\n",
    "  - [lab_cnn_2](</tree/YSDA/machine_learning/lab_cnn_2.ipynb>)\n",
    "  - [lab_em_algorithm](</tree/YSDA/machine_learning/lab_em_algorithm.ipynb>)\n",
    "  - [lab_forecasting](</tree/YSDA/machine_learning/lab_forecasting.ipynb>)\n",
    "  - [lab_forecasting_2](</tree/YSDA/machine_learning/lab_forecasting_2.ipynb>)\n",
    "  - [lab_image_captioning](</tree/YSDA/machine_learning/lab_image_captioning.ipynb>)\n",
    "  - [lab_ranking](</tree/YSDA/machine_learning/lab_ranking.ipynb>)\n",
    "  - [lab_recommending](</tree/YSDA/machine_learning/lab_recommending.ipynb>)\n",
    "  - [lab_recommending_2](</tree/YSDA/machine_learning/lab_recommending_2.ipynb>)\n",
    "  - [lab_recommending_music](</tree/YSDA/machine_learning/lab_recommending_music.ipynb>)\n",
    "  - [lab_recommending_zen](</tree/YSDA/machine_learning/lab_recommending_zen.ipynb>)\n",
    "  - [lab_research_papers](</tree/YSDA/machine_learning/lab_research_papers.ipynb>)\n",
    "  - [seminar_clustering](</tree/YSDA/machine_learning/seminar_clustering.ipynb>)\n",
    "  - [seminar_deep_learning_tricks](</tree/YSDA/machine_learning/seminar_deep_learning_tricks.ipynb>)\n",
    "  - [seminar_em_algorithm](</tree/YSDA/machine_learning/seminar_em_algorithm.ipynb>)\n",
    "  - [seminar_nlp](</tree/YSDA/machine_learning/seminar_nlp.ipynb>)\n",
    "  - [seminar_recommending](</tree/YSDA/machine_learning/seminar_recommending.ipynb>)\n",
    "  - [seminar_recommending_music](</tree/YSDA/machine_learning/seminar_recommending_music.ipynb>)\n",
    "  - [seminar_rl_1](</tree/YSDA/machine_learning/seminar_rl_1.ipynb>)\n",
    "  - asl-fingerspelling\n",
    "    - [asl-fingerspelling](</tree/YSDA/machine_learning/asl-fingerspelling/asl-fingerspelling.ipynb>)\n",
    "  - kaggle\n",
    "    - titanic\n",
    "      - [titanic](</tree/YSDA/machine_learning/kaggle/titanic/titanic.ipynb>)\n",
    "  - sandbox\n",
    "    - [clustering](</tree/YSDA/machine_learning/sandbox/clustering.ipynb>)\n",
    "    - [cython](</tree/YSDA/machine_learning/sandbox/cython.ipynb>)\n",
    "    - [decision_tree_lab](</tree/YSDA/machine_learning/sandbox/decision_tree_lab.ipynb>)\n",
    "    - [decision_trees](</tree/YSDA/machine_learning/sandbox/decision_trees.ipynb>)\n",
    "    - [decision_trees_pad](</tree/YSDA/machine_learning/sandbox/decision_trees_pad.ipynb>)\n",
    "    - [einops](</tree/YSDA/machine_learning/sandbox/einops.ipynb>)\n",
    "    - [k_means](</tree/YSDA/machine_learning/sandbox/k_means.ipynb>)\n",
    "    - [logistic_regression](</tree/YSDA/machine_learning/sandbox/logistic_regression.ipynb>)\n",
    "    - [mobile_net](</tree/YSDA/machine_learning/sandbox/mobile_net.ipynb>)\n",
    "    - [pytorch](</tree/YSDA/machine_learning/sandbox/pytorch.ipynb>)\n",
    "    - [rnns](</tree/YSDA/machine_learning/sandbox/rnns.ipynb>)\n",
    "    - [scraps](</tree/YSDA/machine_learning/sandbox/scraps.ipynb>)\n",
    "  - transformer_apps\n",
    "    - [sem_transformers](</tree/YSDA/machine_learning/transformer_apps/sem_transformers.ipynb>)\n",
    "    - annotated_transformer\n",
    "      - [the_annotated_transformer](</tree/YSDA/machine_learning/transformer_apps/annotated_transformer/the_annotated_transformer.ipynb>)\n",
    "    - making_graphs_accessible\n",
    "      - [making_graphs_accessible](</tree/YSDA/machine_learning/transformer_apps/making_graphs_accessible/making_graphs_accessible.ipynb>)\n",
    "- notebooks\n",
    "  - [cookbook](</tree/YSDA/notebooks/cookbook.ipynb>)\n",
    "  - [data_visualization](</tree/YSDA/notebooks/data_visualization.ipynb>)\n",
    "  - [machine_learning_template](</tree/YSDA/notebooks/machine_learning_template.ipynb>)\n",
    "  - [portfolio](</tree/YSDA/notebooks/portfolio.ipynb>)\n",
    "- statistics\n",
    "  - [statistics_hw1](</tree/YSDA/statistics/statistics_hw1.ipynb>)\n",
    "  - [statistics_hw2](</tree/YSDA/statistics/statistics_hw2.ipynb>)\n",
    "  - [statistics_hw3](</tree/YSDA/statistics/statistics_hw3.ipynb>)\n",
    "  - [statistics_hw4](</tree/YSDA/statistics/statistics_hw4.ipynb>)\n",
    "  - [statistics_hw5](</tree/YSDA/statistics/statistics_hw5.ipynb>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cac508",
   "metadata": {},
   "source": [
    "### Research papers <span id=Research_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e3d7b9",
   "metadata": {},
   "source": [
    "#### Machine learning\n",
    "\n",
    "- [Deconvolutional Networks](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwi419Xz9rL-AhXBRvEDHXaZC9EQFnoECAoQAQ&url=https%3A%2F%2Fwww.matthewzeiler.com%2Fmattzeiler%2Fdeconvolutionalnetworks.pdf&usg=AOvVaw0e46OK618TQ9Oxkmu6HbHK)\n",
    "- [Layer-Wise Pretraining](https://proceedings.neurips.cc/paper_files/paper/2006/file/5da713a690c067105aeb2fae32403405-Paper.pdf)\n",
    "- [Optimal Brain Surgeon](https://authors.library.caltech.edu/54983/3/647-second-order-derivatives-for-network-pruning-optimal-brain-surgeon(1).pdf)\n",
    "- [DfNet](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zeng_DF2Net_A_Dense-Fine-Finer_Network_for_Detailed_3D_Face_Reconstruction_ICCV_2019_paper.pdf)\n",
    "- [Xavier - Understanding the difficulty of training deep feedforward neural networks](https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "\n",
    "- [Global Average Pooling](https://arxiv.org/pdf/1312.4400v3.pdf)\n",
    "- [Variational Autoencoder: a probabilistic autoencoder able to generate new datapoints by sampling in the latent space](https://arxiv.org/pdf/1312.6114.pdf)\n",
    "- [VCG](https://arxiv.org/pdf/1409.1556.pdf)\n",
    "- [GAN: a training process simultaneously learning to generate data and discriminate real from fake data](https://arxiv.org/pdf/1406.2661.pdf)\n",
    "- [ADAM](https://arxiv.org/pdf/1412.6980.pdf)\n",
    "- [Delving Deep into Rectifiers](https://arxiv.org/pdf/1502.01852v1.pdf)\n",
    "- [Highway Networks](https://arxiv.org/pdf/1505.00387.pdf)\n",
    "- [U-Net: convolutional net with progressively shrinking residual connections](https://arxiv.org/pdf/1505.04597.pdf)\n",
    "- [YOLO: object detection via cnn](https://arxiv.org/pdf/1506.02640.pdf)\n",
    "- [DCGAN: generate data directly from noise via stacked convolutions](https://arxiv.org/pdf/1511.06434.pdf)\n",
    "- [Resnet: net with residual, or skip, or identity connections](https://arxiv.org/pdf/1512.03385.pdf)\n",
    "- [Convolutions guide](https://arxiv.org/pdf/1603.07285.pdf)\n",
    "- [Perceptual loss: loss network for style transfer, super resolution](https://arxiv.org/pdf/1603.08155.pdf)\n",
    "- [MGAN texture synthesis](https://arxiv.org/pdf/1604.04382.pdf)\n",
    "- [GELU](https://arxiv.org/pdf/1606.08415.pdf)\n",
    "- [GLU (gated linear units): attention-like transformation with just a filter instead of the key-value mechanism](https://arxiv.org/pdf/1612.08083v3.pdf)\n",
    "- [Wasserstein GAN: adversarial training method with supposedly better convergence properties](https://arxiv.org/pdf/1701.07875.pdf)\n",
    "- [Cycle GAN: learn to transfer style without elementwise target mapping via a trainable discriminator between styles, aiming for a bijective transformation as a regularization](https://arxiv.org/pdf/1703.10593.pdf)\n",
    "- [Wasserstein GAN with Gradient Penalty: a GAN with supposedly further improved convergence](https://arxiv.org/pdf/1704.00028.pdf)\n",
    "- [Mobile Nets](https://arxiv.org/pdf/1704.04861.pdf)\n",
    "- [Deep RL from Human Preferences](https://arxiv.org/pdf/1706.03741.pdf)\n",
    "- [Proximal Policy Optimization: make several gradient steps on one batch, with constraint that policy doesn't change too much](https://arxiv.org/pdf/1707.06347.pdf)\n",
    "- [Vector Quantization: learning a codebook in the latent space, can be thought of as a discrete finite transformation layer](https://arxiv.org/pdf/1711.00937v2.pdf)\n",
    "- [Population Based Training](https://arxiv.org/pdf/1711.09846.pdf)\n",
    "- [Spherical CNN](https://arxiv.org/pdf/1801.10130.pdf)\n",
    "- [Everybody dance now](https://arxiv.org/pdf/1808.07371.pdf)\n",
    "- [CatBoost](https://arxiv.org/pdf/1810.11363.pdf)\n",
    "- [OpenPose](https://arxiv.org/pdf/1812.08008.pdf)\n",
    "- [SHAP Values](https://arxiv.org/pdf/1905.04610.pdf)\n",
    "- [EfficientNet: compound scaling, ](https://arxiv.org/pdf/1905.11946.pdf)\n",
    "- [Fine-Tuning by Increasing Model Capacity](https://arxiv.org/pdf/1907.07844.pdf)\n",
    "- [Deep Double Descent](https://arxiv.org/pdf/1912.02292.pdf)\n",
    "- [StyleGAN2: a specific](https://arxiv.org/pdf/1912.04958.pdf)\n",
    "- [Face Detector](https://arxiv.org/pdf/2003.11228.pdf)\n",
    "- [Denoising Diffusion Probabilistic Models (DDPM): learn to remove noise from data and generate new data from white noise](https://arxiv.org/pdf/2006.11239.pdf)\n",
    "- [Dalle](https://arxiv.org/pdf/2102.12092.pdf)\n",
    "- [CLIP: use pretrained image and text embeddings, generate captioned image dataset and train via contrastive loss](https://arxiv.org/pdf/2103.00020.pdf)\n",
    "- [Latent Diffusion Model: models reverse diffusion in the latent space via neural net capable to condition on different modalities](https://arxiv.org/pdf/2112.10752.pdf)\n",
    "- [ConvMixer: simple patches-based convolution net](https://arxiv.org/pdf/2201.09792.pdf)\n",
    "- [Dalle 2](https://arxiv.org/pdf/2204.06125.pdf)\n",
    "\n",
    "\n",
    "#### Transformers\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)\n",
    "- [BERT: encoder only, masked language model and next sentence prediction pretraining](https://arxiv.org/pdf/1810.04805.pdf)\n",
    "- [GPT-2: decoder only, unsupervised pretraining, prepending description task in input sequence](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)\n",
    "- [Transformer-XL: recurrence between batches, faster inference](https://arxiv.org/pdf/1901.02860.pdf)\n",
    "- [Nucleus Sampling: an overview of sequence generation algorithms](https://arxiv.org/pdf/1904.09751.pdf)\n",
    "- [BART: encoder-decoder, noisy pretraining](https://arxiv.org/pdf/1910.13461.pdf)\n",
    "- [kNN-LM: Generalization through Memorization, similar to Retro, lookup extra context with embedding similar to query](https://arxiv.org/pdf/1911.00172.pdf)\n",
    "- [Compressive Transformer: transformer with memory that gets gradually compressed with time](https://arxiv.org/pdf/1911.05507.pdf)\n",
    "- [Feedback Transformer: attempt to enhance transformer with memory from previous sequence chunks by aggregating previous layer outputs as extra context](https://arxiv.org/pdf/2002.09402.pdf)\n",
    "- [Vision Transformer (ViT): 2d patches as tokens](https://arxiv.org/pdf/2010.11929.pdf)\n",
    "- [VQGAN: take a VQVAE and train it with GAN method, then apply transformer in the latent space to be able to generate data conditioned on a wide range of context modalities](https://arxiv.org/pdf/2012.09841.pdf)\n",
    "- [LambdaNetworks](https://arxiv.org/pdf/2102.08602.pdf)\n",
    "- [Fast Weights Transformer: adjust the attention mechanism to model memory with write and remove operations](https://arxiv.org/pdf/2102.11174.pdf)\n",
    "- [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/pdf/2103.14030.pdf)\n",
    "- [RoFormer: multiplication by rotation matrix as relative positional encoding](https://arxiv.org/pdf/2104.09864.pdf)\n",
    "- [MLP-Mixer: a net for vision without convolution or attention, performing channel-wise operations and mixing spatial information via transpositions](https://arxiv.org/pdf/2105.01601.pdf)\n",
    "- [FNet: replace matrix multiplication and elementwise product in attention layer with Fourier transforms to speed up calculations](https://arxiv.org/pdf/2105.03824.pdf)\n",
    "- [Pay Attention to MLPs (gMLP): transformer with gated linear units instead of attention](https://arxiv.org/pdf/2105.08050.pdf)\n",
    "- [Attention Free Transformer: refactoring the attention operation to reduce computational and memory complexity](https://arxiv.org/pdf/2105.14103.pdf)\n",
    "- [Decision Transformer: Reinforcement Learning via Sequence Modeling](https://arxiv.org/pdf/2106.01345.pdf)\n",
    "- [ALiBi: encoding position with simple linear bias allegedly improves extrapolation on sequences longer than during training](https://arxiv.org/pdf/2108.12409.pdf)\n",
    "- [Primer: an evolutionary search for optimal transformer modifications led to suggestion of using squared ReLU and 3x1 depthwise convolution after attention](https://arxiv.org/pdf/2109.08668.pdf)\n",
    "- [Hourglass: a UNet inspired transformer with down/up sampling and skip connections](https://arxiv.org/pdf/2110.13711.pdf)\n",
    "- [Retro (retrieval-enhanced transformer): simulate external memory by looking up neighbors to current data embeddings in a large database and use it as extra context](https://arxiv.org/pdf/2112.04426.pdf)\n",
    "- [VQGAN-CLIP: VQGAN trained to generate images with CLIP embeddings similar to textual context, cool but slow](https://arxiv.org/pdf/2204.08583.pdf)\n",
    "- [DETR: transformer object detector](https://arxiv.org/pdf/2304.08069v2.pdf)\n",
    "\n",
    "#### Ranking\n",
    "- [Ranking Review](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf)\n",
    "- [Deep Structured Semantic Models](https://posenhuang.github.io/papers/cikm2013_DSSM_fullversion.pdf)\n",
    "- [LambdaLoss](https://dl.acm.org/doi/pdf/10.1145/3269206.3271784)\n",
    "- [RankNet](https://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf)\n",
    "\n",
    "#### Recommending\n",
    "- [Factorization Meets the Neighborhood](https://people.engr.tamu.edu/huangrh/Spring16/papers_course/matrix_factorization.pdf)\n",
    "- [Implicit Feedback Model](http://yifanhu.net/PUB/cf.pdf)\n",
    "- [SLIM](https://www.researchgate.net/publication/220765374_SLIM_Sparse_Linear_Methods_for_Top-N_Recommender_Systems)\n",
    "\n",
    "- [Bayesian Personalized Ranking](https://arxiv.org/pdf/1205.2618.pdf)\n",
    "- [LightFM](https://arxiv.org/pdf/1507.08439.pdf)\n",
    "- [Variational Autoencoders](https://arxiv.org/pdf/1802.05814.pdf)\n",
    "- [BERT4Rec](https://arxiv.org/pdf/1904.06690.pdf)\n",
    "- [CARCA](https://arxiv.org/pdf/2204.06519.pdf)\n",
    "\n",
    "\n",
    "#### Algorithms\n",
    "- [Approximate nearest neighbor algorithm](https://publications.hse.ru/pubs/share/folder/x5p6h7thif/128296059.pdf)\n",
    "- [Navigable Small World](https://arxiv.org/pdf/1603.09320.pdf)\n",
    "- [100 prisoners and a lightbulb](https://arxiv.org/pdf/2208.00771.pdf)\n",
    "\n",
    "\n",
    "#### Other\n",
    "- [Lookahead Optimizer: look ahead k fast grad steps and make one final slow step](https://arxiv.org/pdf/1907.08610.pdf)\n",
    "- [RoPE: Rotary Position Encoding](https://arxiv.org/pdf/2104.09864.pdf)\n",
    "- [Understanding data augmentation for classification: benefits and pitfalls of data augmentation](https://arxiv.org/pdf/1609.08764.pdf)\n",
    "- [Data2vec: a modality-invariant self-supervised masked learning of data encodings](https://arxiv.org/pdf/2202.03555.pdf)\n",
    "- [Data2vec 2.0: a more efficient learning algorithm](https://arxiv.org/pdf/2212.07525.pdf)\n",
    "- [Squeeze-and-excite: an attention-like layer for cnns](https://arxiv.org/pdf/1709.01507.pdf)\n",
    "- [ContextNet (2020): squeeze-and-excite cnn](https://arxiv.org/pdf/2005.03191.pdf)\n",
    "- [Noisy student: iteratively train larger model on unlabeled data using previous model's predictions as target](https://arxiv.org/pdf/1911.04252v4.pdf)\n",
    "- [Stochastic depth regularization](https://arxiv.org/pdf/1603.09382.pdf)\n",
    "- [Token Learner: simple spacial attention based feature extractor](https://openreview.net/pdf?id=z-l1kpDXs88)\n",
    "- [Population based training: a explore-exploit algorithm for hyperparameter search](https://arxiv.org/pdf/1711.09846.pdf)\n",
    "- [QLoRA](https://www.semanticscholar.org/reader/32ac52069e562d4f900afee70bdca63f53461481): Efficient Finetuning of Quantized LLMs\n",
    "- [GNN introduction (2021)](https://distill.pub/2021/gnn-intro/)\n",
    "- [RetNet](https://arxiv.org/pdf/2307.08621.pdf): an attention with both parallel and recurrent formulations\n",
    "- [RetNet implementation](https://github.com/Jamie-Stirling/RetNet/blob/main/src/retention.py)\n",
    "\n",
    "#### NLP\n",
    "- [Word2Vec (2013)](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "- [GloVe (2014)](https://aclanthology.org/D14-1162.pdf)\n",
    "- [T5: flexible text-to-text model with task-specific prefix](https://arxiv.org/pdf/1910.10683v3.pdf)\n",
    "- [LLaMa: an open-source family of large language models](https://arxiv.org/pdf/2302.13971v1.pdf)\n",
    "- [Training Compute-Optimal LLMs: analysis of relationship between model size, training and dataset size](https://arxiv.org/pdf/2203.15556.pdf)\n",
    "\n",
    "\n",
    "#### Speech, video sequences\n",
    "- [CTC loss: a way to measure distance between two different modality sequences](https://distill.pub/2017/ctc/)\n",
    "- [I3D (2018): overview of video classification methods, such as conv2d + optical flow + LSTM, conv3d](https://arxiv.org/pdf/1705.07750.pdf)\n",
    "- [Semi-supervised learning for speech recognition (2022): mix labeled and unlabeled data, iteratively train student models with conformer architecture](https://arxiv.org/pdf/2010.10504v2.pdf)\n",
    "- [wav2vec 2.0 (2020): learning audio encodings via masked pretraining, conv + VQ + transformer](https://arxiv.org/pdf/2006.11477.pdf)\n",
    "- [Whisper (2022): robust speech recognition via large-scale weak supervision with transformer](https://arxiv.org/pdf/2212.04356.pdf)\n",
    "- [SpecAugment: speech recognition augmentation via time warping, block masking](https://arxiv.org/pdf/1904.08779v3.pdf)\n",
    "- [Conformer (2020): cnn and transformer fusion](https://arxiv.org/pdf/2005.08100.pdf)\n",
    "- [SqueezeFormer: a simplified Conformer](https://arxiv.org/pdf/2206.00888.pdf)\n",
    "- [Jasper: a family of models for asr based on cnns](https://arxiv.org/pdf/1904.03288.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddab117",
   "metadata": {},
   "source": [
    "## Notes <span id=Notes_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055e358a",
   "metadata": {},
   "source": [
    "- Attention mechanism can be thought of as a form of factorization. For example, a fully connected layer can produce the same outputs as a layer with attention, but its parameters will have to both determine the absolute and relative importance of the features, whereas in attention layer, the attention head determines the relative importance of given item in the sequence and the key-value parameters determine the absolute importance of the given item's features. This factorization reduces the model complexity, but still leaves room for flexibility to learn elaborate dependencies.\n",
    "- Another idea is weight sharing between different layers, which can be beneficial for logicaly connected layers, such as encoder and decoder, or query and key projections in attention.\n",
    "- Save previous model outputs as memory for sequence-based tasks.\n",
    "- Preprocess extra big data for online quering to simulate knowledge framework.\n",
    "- Vector quantization, or continuous values binning as a discrete transformation with fewer parameters, may be used to simulate hierarchical system or decision making process.\n",
    "- [Model quantization](https://pytorch.org/docs/stable/quantization.html) is different from vector quantization, used to speed up inference and reduce model size.\n",
    "- Implement conditional model flow, or switches based on input data, to speed up inference, while expanding output space and keeping model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75633e",
   "metadata": {},
   "source": [
    "### Model training workflow:\n",
    "\n",
    "- Separate tiny fraction of data for debugging purposes. That way it is possible to save time during the exploration, coding and experimenting stages.\n",
    "- Write code in such a way that a model can be fully trained and evaluated via a function that takes simple arguments, such as strings, ints and floats. That way incapsulation is achieved, bugs are easier to catch, different configs can be compared and hyperparameter sweeps performed.\n",
    "- Try to separate code into these sections:\n",
    "    - Setup: data loading and preprocessing\n",
    "    - Data exploration: get to know your data: visualize it, compute statistics, take samples\n",
    "    - Metrics: understand how to measure model quality\n",
    "    - Data processing: tokenization, filtering, splitting, transforming, etc. End result of this stage should be a function that loads a processed dataset and returns a convenient object, such as a torch.utils.data.Dataset\n",
    "    - Model: write core model structure, for example as a torch.nn.Module subclass\n",
    "    - Training, logging and inference: write a model wrapper that builds and trains a model, computes and logs test metrics and can be used in inference on new data, for example a pytorch_lightning.LightningModule subclass\n",
    "    - Main: a function that wraps everything together, allowing to launch separate processes to evaluate or tune different configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd593f",
   "metadata": {},
   "source": [
    "- When hyperparameter searching, it may be efficient to construct a base model and try scaling all its hyperparameters together, following the method from https://arxiv.org/pdf/1905.11946.pdf.\n",
    "- When training large models, it may be efficient to gradualy increase batch size during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ebf195",
   "metadata": {},
   "source": [
    "### Tabular data file format options:\n",
    "- csv for compatibility\n",
    "- parquet for efficient long term storage\n",
    "- arrow for fast retrieval from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df4737c",
   "metadata": {},
   "source": [
    "### App ideas\n",
    "\n",
    "1. Implement online feedback interface to incrementally train models.\n",
    "1. Git commit: adversarial models - one makes commit, other tries to match commit message to commit.\n",
    "1. Something with reinforcement learning with online feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac717db0",
   "metadata": {},
   "source": [
    "### Miscellaneous:\n",
    "\n",
    "- If Notebook hangs, it may be because of large amount of cell outputs, so `Cell -> All Output -> Clear` may help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d23ed6",
   "metadata": {},
   "source": [
    "## Languages <span id=Languages_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fcb445",
   "metadata": {},
   "source": [
    "## Markdown syntax <span id=Markdown_syntax_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1263131",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Collapsible</summary>\n",
    "\n",
    "**bold text**\n",
    "    \n",
    "*italicized text*\n",
    "\n",
    "### section id\n",
    "    \n",
    "> blockquote\n",
    "\n",
    "1. First item\n",
    "2. Second item\n",
    "3. Third item\n",
    "\n",
    "- First item\n",
    "- Second item\n",
    "- Third item\n",
    "\n",
    "`code`\n",
    "\n",
    "\n",
    "\n",
    "```c++ \n",
    "// formatted code according to specified language\n",
    "public static String monthNames[] = {\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"};\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "[Section link](#section-id)\n",
    "\n",
    "[Markdown Guide](https://www.markdownguide.org)\n",
    "\n",
    "![alt text](https://www.markdownguide.org/assets/images/tux.png \"Image Title\")\n",
    "<figcaption> Caption </figcaption>\n",
    "\n",
    "[Example of a relative link](/tree/YSDA/notebooks/Portfolio.ipynb)\n",
    "    \n",
    "    \n",
    "| Default | Left align | Center align |\n",
    "| - | :- | :-: |\n",
    "| Header | Title | - |\n",
    "| Paragraph | Text | NA|\n",
    "\n",
    "```\n",
    "{\n",
    "  \"firstName\": \"John\",\n",
    "  \"lastName\": \"Smith\",\n",
    "  \"age\": 25\n",
    "}\n",
    "```\n",
    "\n",
    "Monospaced\n",
    "\n",
    "<samp>The quick brown fox jumps over the lazy dog.</samp>\n",
    "\n",
    "Underlined\n",
    "\n",
    "<ins>The quick brown fox jumps over the lazy dog.</ins>\n",
    "\n",
    "Strike-through\n",
    "\n",
    "~~The quick brown fox jumps over the lazy dog.~~\n",
    "\n",
    "\n",
    "Boxed\n",
    "\n",
    "<table><tr><td>The quick brown fox jumps over the lazy dog.</td></tr></table>\n",
    "\n",
    "Subscript <sub>The quick brown fox jumps over the lazy dog.</sub>\n",
    "\n",
    "Superscript <sup>The quick brown fox jumps over the lazy dog.</sup>\n",
    "\n",
    "- [x] Fix Bug 223\n",
    "- [ ] Add Feature 33\n",
    "- [ ] Add unit tests\n",
    "\n",
    "\n",
    "  \n",
    "  ### Heading\n",
    "  1. Foo\n",
    "  2. Bar\n",
    "     * Baz\n",
    "     * Qux\n",
    "\n",
    "  ### Some Code\n",
    "  ```js\n",
    "  function logSomething(something) {\n",
    "    console.log('Something', something);\n",
    "  }\n",
    "  ```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e12e83",
   "metadata": {},
   "source": [
    "## Tex syntax <span id=Tex_syntax_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48bbcb",
   "metadata": {},
   "source": [
    "$\\displaystyle{\n",
    "}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11d762",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Tex probability commands shortlist</summary>\n",
    "  \n",
    "```\n",
    "$\\newcommand{\\Sum}{\\sum\\limits}\n",
    "\\newcommand{\\Int}{\\int\\limits}\n",
    "\\newcommand{\\Intf}{\\int\\limits_{-\\infty}^{+\\infty}}\n",
    "\\newcommand{\\Prod}{\\prod\\limits}\n",
    "\\newcommand{\\Max}{\\max\\limits}\n",
    "\\newcommand{\\Min}{\\min\\limits}\n",
    "\\newcommand{\\Lim}{\\lim\\limits}\n",
    "\\newcommand{\\Var}{\\mathbb{V}}\n",
    "\\newcommand{\\Exp}{\\mathbb{E}}\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\argmax}{\\arg\\max}\n",
    "\\newcommand{\\Cov}{\\text{Cov}}\n",
    "\\newcommand{\\makebold}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\newcommand{\\mean}[1]{\\overline{#1}}\n",
    "\\newcommand{\\avg}[1]{\\langle #1 \\rangle}\n",
    "\\newcommand{\\angmean}[1]{\\langle #1 \\rangle}\n",
    "\\newcommand{\\Prob}{\\mathcal{P}}\n",
    "\\newcommand{\\se}{\\text{se}}\n",
    "\\newcommand{\\lp}{\\left}\n",
    "\\newcommand{\\rp}{\\right}\n",
    "\\newcommand{\\boldx}{\\boldsymbol{x}}\n",
    "\\newcommand{\\boldy}{\\boldsymbol{y}}\n",
    "\\newcommand{\\boldz}{\\boldsymbol{z}}\n",
    "\\newcommand{\\boldX}{\\boldsymbol{X}}\n",
    "\\newcommand{\\boldY}{\\boldsymbol{Y}}\n",
    "\\newcommand{\\boldZ}{\\boldsymbol{Z}}\n",
    "\\newcommand{\\Poisson}{\\mathrm{Poisson}}\n",
    "\\newcommand{\\Triangle}{\\mathrm{Triangle}}\n",
    "\\newcommand{\\Uniform}{\\mathrm{Uniform}}\n",
    "\\newcommand{\\Binomial}{\\mathrm{Binomial}}\n",
    "\\newcommand{\\Bernoulli}{\\mathrm{Bernoulli}}\n",
    "\\newcommand{\\Gammap}{\\mathrm{Gamma}}\n",
    "\\newcommand{\\Normal}{\\mathcal{N}}\n",
    "\\newcommand{\\LogN}{\\mathrm{LogN}}\n",
    "\\newcommand{\\Exponential}{\\mathrm{Exp}}\n",
    "\\newcommand{\\Erlang}{\\mathrm{Erlang}}\n",
    "\\newcommand{\\Cauchy}{C}\n",
    "\\newcommand{\\Dir}{\\mathrm{Dir}}\n",
    "\\newcommand{\\Beta}{\\mathrm{Beta}}\n",
    "\\newcommand{\\Pareto}{\\mathrm{Pareto}}\n",
    "\\newcommand{\\lf}{\\left\\{}\n",
    "\\newcommand{\\rf}{\\right\\}}\n",
    "\\newcommand{\\lp}{\\left(}\n",
    "\\newcommand{\\rp}{\\right)}\n",
    "\\newcommand{\\Ecdf}[1]{\\hat{F}_n(#1)}\n",
    "\\newcommand{\\OPT}{\\text{OPT}}\n",
    "\\newcommand{\\opt}{\\text{opt}}\n",
    "\\newcommand{\\boot}{\\text{boot}}\n",
    "\\newcommand{\\bias}{\\text{bias}}\n",
    "\\newcommand{\\se}{\\text{se}}\n",
    "\\newcommand{\\MSE}{\\text{MSE}}\n",
    "\\newcommand{\\qm}{\\text{qm}}\n",
    "\\newcommand{\\as}{\\text{as}}\n",
    "\\newcommand{\\trace}{\\text{trace}}\n",
    "\\newcommand{\\esttheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\estlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\estmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\estsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\estalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\estbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\estxi}{\\hat{\\xi}}\n",
    "\\newcommand{\\esttau}{\\hat{\\tau}}\n",
    "\\newcommand{\\estpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\esta}{\\hat{a}}\n",
    "\\newcommand{\\estb}{\\hat{b}}\n",
    "\\newcommand{\\estc}{\\hat{c}}\n",
    "\\newcommand{\\estd}{\\hat{d}}\n",
    "\\newcommand{\\estp}{\\hat{p}}\n",
    "\\newcommand{\\estT}{\\hat{T}}\n",
    "\\newcommand{\\estR}{\\hat{R}}\n",
    "\\newcommand{\\estF}{\\hat{F}}\n",
    "\\newcommand{\\estf}{\\hat{f}}\n",
    "\\newcommand{\\estC}{\\hat{C}}\n",
    "\\newcommand{\\estS}{\\hat{S}}\n",
    "\\newcommand{\\estY}{\\hat{Y}}\n",
    "\\newcommand{\\esty}{\\hat{y}}\n",
    "\\newcommand{\\estVar}{\\hat{\\Var}}\n",
    "\\newcommand{\\estExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\estSe}{\\hat{\\se}}\n",
    "\\newcommand{\\hatp}{\\hat{p}}\n",
    "\\newcommand{\\hatF}{\\hat{F}}\n",
    "\\newcommand{\\hatT}{\\hat{T}}\n",
    "\\newcommand{\\hattheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\hatse}{\\hat{\\se}}$\n",
    "```\n",
    "    \n",
    "<\\details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da4191",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Tex commands extended list</summary>\n",
    "  \n",
    "```\n",
    "$\n",
    "% The list of general commands\n",
    "\\newcommand{\\PI}{3.141592654}\n",
    "\\newcommand{\\Sum}{\\sum\\limits}\n",
    "\\newcommand{\\Int}{\\int\\limits}\n",
    "\\newcommand{\\Lim}{\\lim\\limits}\n",
    "\\newcommand{\\Prod}{\\prod\\limits}\n",
    "\\newcommand{\\Intf}{\\int\\limits_{-\\infty}^{+\\infty}}\n",
    "\\newcommand{\\Sumclap}[1]{\\Sum_{\\mathclap{#1}}}\n",
    "\\newcommand{\\Intclap}[1]{\\Int_{\\mathclap{#1}}}\n",
    "\\newcommand{\\Prodclap}[1]{\\Prod_{\\mathclap{#1}}}\n",
    "\\newcommand{\\Aprod}{\\bigodot}\n",
    "\\newcommand{\\aprod}{\\odot}\n",
    "\\newcommand{\\Max}{\\max\\limits}\n",
    "\\newcommand{\\Min}{\\min\\limits}\n",
    "\\newcommand{\\argmax}{\\arg\\max}\n",
    "\\newcommand{\\argmin}{\\arg\\min}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\lp}{\\left(}\n",
    "\\newcommand{\\rp}{\\right)}\n",
    "\\newcommand{\\lf}{\\left\\{}\n",
    "\\newcommand{\\rf}{\\right\\}}\n",
    "\\newcommand{\\ls}{\\left[}\n",
    "\\newcommand{\\rs}{\\right]}\n",
    "\\newcommand{\\lv}{\\left|}\n",
    "\\newcommand{\\rv}{\\right|}\n",
    "\\newcommand{\\la}{\\left\\langle}\n",
    "\\newcommand{\\ra}{\\right\\rangle}\n",
    "\\\n",
    "% Обозначения из предметной области: теории вероятностей и статистики\n",
    "\\newcommand{\\Distr}{\\mathsf{D}}\n",
    "\\newcommand{\\Var}{\\mathbb{V}}\n",
    "\\newcommand{\\Exp}{\\mathbb{E}}\n",
    "\\newcommand{\\Cov}{\\mathbb{C}\\mathrm{ov}}\n",
    "\\newcommand{\\Loss}{\\mathcal{L}}\n",
    "\\newcommand{\\loss}{\\ell}\n",
    "\\newcommand{\\LogLike}{\\mathcal{L}}\n",
    "\\newcommand{\\Like}{\\ell}\n",
    "\\newcommand{\\Risk}{\\mathcal{R}}\n",
    "\\newcommand{\\makebold}[1]{\\boldsymbol{#1}}\n",
    "\\\n",
    "\\newcommand{\\mean}[1]{\\overline{#1}}\n",
    "\\newcommand{\\avg}[1]{\\overline{#1}}\n",
    "\\newcommand{\\angmean}[1]{\\left\\langle #1 \\right\\rangle}\n",
    "\\newcommand{\\barmean}[1]{\\overline{#1}}\n",
    "\\\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\renewcommand{\\epsilon}{\\varepsilon}\n",
    "\\newcommand{\\Ind}{I}\n",
    "\\newcommand{\\Fisher}{I}\n",
    "\\\n",
    "\\newcommand{\\HOT}{\\text{\\textbf{H.O.T.}}}\n",
    "\\\n",
    "\\newcommand{\\partfrac}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\ttt}[1]{\\texttt{#1}}\n",
    "\\newcommand{\\term}[1]{\\textbf{#1}}\n",
    "$\n",
    "$\n",
    "\\\n",
    "\\renewcommand{\\phi}{\\varphi}\n",
    "\\\n",
    "\\newcommand{\\CC}{\\mathbb{C}}\n",
    "\\newcommand{\\NN}{\\mathbb{N}}\n",
    "\\newcommand{\\PP}{\\mathbb{P}}\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\XX}{\\mathbb{X}}\n",
    "\\newcommand{\\ZZ}{\\mathbb{Z}}\n",
    "\\renewcommand{\\AA}{\\mathbb{A}}\n",
    "\\\n",
    "\\newcommand{\\Xbb}{\\mathbb{X}}\n",
    "\\newcommand{\\Ybb}{\\mathbb{Y}}\n",
    "\\newcommand{\\Zbb}{\\mathbb{Z}}\n",
    "\\\n",
    "% Empirical values\n",
    "\\newcommand{\\Ecdf}[1]{\\hat{F}_n(#1)}\n",
    "\\newcommand{\\OPT}{\\ensuremath{\\mathrm{OPT}\\xspace}}\n",
    "\\newcommand{\\opt}{\\ensuremath{\\mathrm{opt}\\xspace}}\n",
    "\\newcommand{\\boot}{\\ensuremath{\\mathrm{boot}\\xspace}}\n",
    "\\newcommand{\\bias}{\\ensuremath{\\mathrm{bias}\\xspace}}\n",
    "\\newcommand{\\se}{\\ensuremath{\\mathrm{se}\\xspace}}\n",
    "\\newcommand{\\MSE}{\\ensuremath{\\mathrm{MSE}\\xspace}}\n",
    "\\newcommand{\\RSS}{\\ensuremath{\\mathrm{RSS}\\xspace}}\n",
    "\\newcommand{\\qm}{\\ensuremath{\\mathrm{qm}\\xspace}}\n",
    "\\newcommand{\\as}{\\ensuremath{\\mathrm{as}\\xspace}}\n",
    "\\newcommand{\\trace}{\\ensuremath{\\mathrm{tr}\\xspace}}\n",
    "\\newcommand{\\const}{\\ensuremath{\\mathrm{const}\\xspace}}\n",
    "\\newcommand{\\sign}{\\ensuremath{\\mathrm{sign}\\xspace}}\n",
    "\\newcommand{\\tr}{\\mathrm{tr}}\n",
    "\\newcommand{\\new}{\\mathrm{new}}\n",
    "\\newcommand{\\lasso}{\\mathrm{lasso}}\n",
    "\\newcommand{\\old}{\\mathrm{old}}\n",
    "\\newcommand{\\diag}{\\mathrm{diag}}\n",
    "\\newcommand{\\rank}{\\mathrm{rg}}\n",
    "\\newcommand{\\ML}{\\mathrm{ML}}\n",
    "\\newcommand{\\MP}{\\mathrm{MP}}\n",
    "\\newcommand{\\KL}{\\mathrm{KL}}\n",
    "\\newcommand{\\NV}{\\mathrm{NV}}\n",
    "\\newcommand{\\MV}{\\mathrm{MV}}\n",
    "\\newcommand{\\NP}{\\mathrm{MP}}   % Нейман-Пирсон\n",
    "\\newcommand{\\vs}{\\mathrm{vs}}   % versus\n",
    "\\newcommand{\\LOO}{\\mathrm{LOO}}\n",
    "\\newcommand{\\IGMV}{\\mathrm{IGMV}}\n",
    "\\newcommand{\\MM}{\\mathrm{MM}}\n",
    "\\newcommand{\\nat}{\\mathrm{nat}\\xspace}\n",
    "\\newcommand{\\grad}{\\mathrm{grad}\\xspace}\n",
    "% Оценки\n",
    "\\newcommand{\\esttheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\estlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\estmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\estsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\estalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\estbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\estxi}{\\hat{\\xi}}\n",
    "\\newcommand{\\esttau}{\\hat{\\tau}}\n",
    "\\newcommand{\\estpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\esta}{\\hat{a}}\n",
    "\\newcommand{\\estb}{\\hat{b}}\n",
    "\\newcommand{\\estc}{\\hat{c}}\n",
    "\\newcommand{\\estd}{\\hat{d}}\n",
    "\\newcommand{\\estf}{\\hat{f}}\n",
    "\\newcommand{\\estp}{\\hat{p}}\n",
    "\\newcommand{\\esty}{\\hat{y}}\n",
    "\\newcommand{\\estT}{\\hat{T}}\n",
    "\\newcommand{\\estR}{\\hat{R}}\n",
    "\\newcommand{\\estF}{\\hat{F}}\n",
    "\\newcommand{\\estC}{\\hat{C}}\n",
    "\\newcommand{\\estS}{\\hat{S}}\n",
    "\\newcommand{\\estY}{\\hat{Y}}\n",
    "\\newcommand{\\estVar}{\\hat{\\Var}}\n",
    "\\newcommand{\\estExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\estSe}{\\hat{\\se}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\ecdf}{\\hat{F}}\n",
    "\\\n",
    "\\newcommand{\\hata}{\\hat{a}}\n",
    "\\newcommand{\\hatb}{\\hat{b}}\n",
    "\\newcommand{\\hatc}{\\hat{c}}\n",
    "\\newcommand{\\hatd}{\\hat{d}}\n",
    "\\newcommand{\\hatf}{\\hat{f}}\n",
    "\\newcommand{\\hatg}{\\hat{g}}\n",
    "\\newcommand{\\hatk}{\\hat{k}}\n",
    "\\newcommand{\\hatp}{\\hat{p}}\n",
    "\\newcommand{\\hatr}{\\hat{r}}\n",
    "\\newcommand{\\hatt}{\\hat{t}}\n",
    "\\newcommand{\\haty}{\\hat{y}}\n",
    "\\newcommand{\\hatw}{\\hat{w}}\n",
    "\\\n",
    "\\newcommand{\\hatC}{\\hat{C}}\n",
    "\\newcommand{\\hatF}{\\hat{F}}\n",
    "\\newcommand{\\hatJ}{\\hat{J}}\n",
    "\\newcommand{\\hatK}{\\hat{K}}\n",
    "\\newcommand{\\hatP}{\\hat{P}}\n",
    "\\newcommand{\\hatS}{\\hat{S}}\n",
    "\\newcommand{\\hatT}{\\hat{T}}\n",
    "\\newcommand{\\hatY}{\\hat{Y}}\n",
    "\\newcommand{\\hatV}{\\hat{V}}\n",
    "\\newcommand{\\hatU}{\\hat{U}}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\hateps}{\\hat{\\eps}}\n",
    "\\newcommand{\\hatalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\hatbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\hatpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\hatlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\hattheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\hatsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\hatmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\hatnu}{\\hat{\\nu}}\n",
    "\\newcommand{\\hatSigma}{\\hat{\\Sigma}}\n",
    "\\newcommand{\\hatSe}{\\hat{\\se}}\n",
    "\\newcommand{\\hatExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\hatVar}{\\hat{\\Var}}\n",
    "\\\n",
    "\\newcommand{\\tilx}{\\tilde{x}}\n",
    "\\newcommand{\\tily}{\\tilde{y}}\n",
    "\\newcommand{\\tilX}{\\tilde{X}}\n",
    "\\newcommand{\\tilY}{\\tilde{Y}}\n",
    "\\newcommand{\\tilK}{\\tilde{K}}\n",
    "\\newcommand{\\tilU}{\\tilde{U}}\n",
    "\\newcommand{\\tilV}{\\tilde{V}}\n",
    "\\newcommand{\\tilSigma}{\\tilde{\\Sigma}}\n",
    "\\newcommand{\\tiltau}{\\tilde{\\tau}}\n",
    "\\newcommand{\\tiltheta}{\\tilde{\\theta}}\n",
    "\\newcommand{\\tillambda}{\\tilde{\\lambda}}\n",
    "\\newcommand{\\tilsigma}{\\tilde{\\sigma}}\n",
    "\\newcommand{\\tilpsi}{\\tilde{\\psi}}\n",
    "\\newcommand{\\tilmu}{\\tilde{\\mu}}\n",
    "\\\n",
    "\\newcommand{\\MLE}{\\text{MLE}}\n",
    "\\newcommand{\\mlexi}{\\xi_{MLE}}\n",
    "\\newcommand{\\mletheta}{\\theta_{MLE}}\n",
    "\\newcommand{\\mlelambda}{\\lambda_{MLE}}\n",
    "\\newcommand{\\mlesigma}{\\sigma_{MLE}}\n",
    "\\newcommand{\\mlepsi}{\\psi_{MLE}}\n",
    "\\newcommand{\\mlemu}{\\mu_{MLE}}\n",
    "\\newcommand{\\mlenu}{\\nu_{MLE}}\n",
    "\\\n",
    "\\newcommand{\\mmxi}{\\xi_{MM}}\n",
    "\\newcommand{\\mmtheta}{\\theta_{MM}}\n",
    "\\newcommand{\\mmlambda}{\\lambda_{MM}}\n",
    "\\newcommand{\\mmsigma}{\\sigma_{MM}}\n",
    "\\newcommand{\\mmpsi}{\\psi_{MM}}\n",
    "\\newcommand{\\mmalpha}{\\alpha_{MM}}\n",
    "\\newcommand{\\mmbeta}{\\beta_{MM}}\n",
    "\\\n",
    "% Классы распределений\n",
    "\\newcommand{\\Poisson}{\\mathrm{Poisson}\\xspace}\n",
    "\\newcommand{\\Triangle}{\\mathrm{Triangle}\\xspace}\n",
    "\\newcommand{\\Uniform}{\\mathrm{Uniform}\\xspace}\n",
    "\\newcommand{\\Binomial}{\\mathrm{Binomial}\\xspace}\n",
    "\\newcommand{\\Multinomial}{\\mathrm{Multinomial}\\xspace}\n",
    "\\newcommand{\\Bernoulli}{\\mathrm{Bernoulli}\\xspace}\n",
    "\\newcommand{\\Gammap}{\\mathrm{Gamma}\\xspace}\n",
    "\\newcommand{\\Normal}{\\mathcal{N}\\xspace}\n",
    "\\newcommand{\\Student}{\\mathcal{T}\\xspace}\n",
    "%\\newcommand{\\Student}{\\mathrm{Student}\\xspace}\n",
    "\\newcommand{\\LogN}{\\mathrm{LogN}\\xspace}\n",
    "\\newcommand{\\Exponential}{\\mathrm{Exp}\\xspace}\n",
    "\\newcommand{\\Erlang}{\\mathrm{Erlang}\\xspace}\n",
    "\\newcommand{\\Cauchy}{C\\xspace}\n",
    "\\newcommand{\\Dir}{\\mathrm{Dir}\\xspace}\n",
    "\\newcommand{\\Beta}{\\mathrm{Beta}\\xspace}\n",
    "\\newcommand{\\Pareto}{\\mathrm{Pareto}\\xspace}\n",
    "$\n",
    "$\n",
    "%\n",
    "\\newcommand{\\Family}{\\mathfrak{F}}\n",
    "\\\n",
    "% Гипотезы\n",
    "\\newcommand{\\RejectRegion}{R}\n",
    "\\newcommand{\\pvalue}{\\text{p-value}\\xspace}\n",
    "\\newcommand{\\llr}{\\ell}\n",
    "\\newcommand{\\Llr}{\\mathcal{L}}\n",
    "\\\n",
    "% Регрессия\n",
    "\\newcommand{\\RRS}{\\mathrm{RSS}\\xspace}\n",
    "\\\n",
    "\\newcommand{\\redtext}[1]{\\textcolor{red}{#1}}\n",
    "\\newcommand{\\addtask}[1]{\\hyperref[#1]{\\redtext{Задача~\\ref*{#1}}}}\n",
    "\\newcommand{\\solution}{\\redtext{\\textbf{Решение.}}}\n",
    "\\newcommand{\\ignore}[1]{\\xspace}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\NumOfSamples}{\\mathcal{N}}\n",
    "\\newcommand{\\NumOfDims}{\\mathcal{D}}\n",
    "\\newcommand{\\NumOfHidden}{\\mathcal{H}}\n",
    "\\newcommand{\\NumOfClasses}{\\mathcal{K}}\n",
    "\\newcommand{\\NumOfChannels}{\\mathcal{C}}\n",
    "\\newcommand{\\NumOfFilters}{\\mathcal{F}}\n",
    "\\newcommand{\\HiddenSize}{\\mathcal{H}}\n",
    "\\\n",
    "\\newcommand{\\boldzero}{\\boldsymbol{0}}\n",
    "\\newcommand{\\boldones}{\\boldsymbol{1}}\n",
    "\\newcommand{\\boldone}{\\boldsymbol{1}}\n",
    "\\\n",
    "\\newcommand{\\bolda}{\\boldsymbol{a}}\n",
    "\\newcommand{\\boldb}{\\boldsymbol{b}}\n",
    "\\newcommand{\\boldc}{\\boldsymbol{c}}\n",
    "\\newcommand{\\boldd}{\\boldsymbol{d}}\n",
    "\\newcommand{\\bolde}{\\boldsymbol{e}}\n",
    "\\newcommand{\\boldf}{\\boldsymbol{f}}\n",
    "\\newcommand{\\boldg}{\\boldsymbol{g}}\n",
    "\\newcommand{\\boldh}{\\boldsymbol{h}}\n",
    "\\newcommand{\\boldi}{\\boldsymbol{i}}\n",
    "\\newcommand{\\boldj}{\\boldsymbol{j}}\n",
    "\\newcommand{\\boldk}{\\boldsymbol{k}}\n",
    "\\newcommand{\\boldl}{\\boldsymbol{l}}\n",
    "\\newcommand{\\boldm}{\\boldsymbol{m}}\n",
    "\\newcommand{\\boldn}{\\boldsymbol{n}}\n",
    "\\newcommand{\\boldo}{\\boldsymbol{o}}\n",
    "\\newcommand{\\boldp}{\\boldsymbol{p}}\n",
    "\\newcommand{\\boldq}{\\boldsymbol{q}}\n",
    "\\newcommand{\\boldr}{\\boldsymbol{r}}\n",
    "\\newcommand{\\bolds}{\\boldsymbol{s}}\n",
    "\\newcommand{\\boldt}{\\boldsymbol{t}}\n",
    "\\newcommand{\\boldu}{\\boldsymbol{u}}\n",
    "\\newcommand{\\boldv}{\\boldsymbol{v}}\n",
    "\\newcommand{\\boldw}{\\boldsymbol{w}}\n",
    "\\newcommand{\\boldx}{\\boldsymbol{x}}\n",
    "\\newcommand{\\boldy}{\\boldsymbol{y}}\n",
    "\\newcommand{\\boldz}{\\boldsymbol{z}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\boldA}{\\boldsymbol{A}}\n",
    "\\newcommand{\\boldB}{\\boldsymbol{B}}\n",
    "\\newcommand{\\boldC}{\\boldsymbol{C}}\n",
    "\\newcommand{\\boldD}{\\boldsymbol{D}}\n",
    "\\newcommand{\\boldE}{\\boldsymbol{E}}\n",
    "\\newcommand{\\boldF}{\\boldsymbol{F}}\n",
    "\\newcommand{\\boldH}{\\boldsymbol{H}}\n",
    "\\newcommand{\\boldJ}{\\boldsymbol{J}}\n",
    "\\newcommand{\\boldK}{\\boldsymbol{K}}\n",
    "\\newcommand{\\boldL}{\\boldsymbol{L}}\n",
    "\\newcommand{\\boldM}{\\boldsymbol{M}}\n",
    "\\newcommand{\\boldN}{\\boldsymbol{N}}\n",
    "\\newcommand{\\boldI}{\\boldsymbol{I}}\n",
    "\\newcommand{\\boldP}{\\boldsymbol{P}}\n",
    "\\newcommand{\\boldQ}{\\boldsymbol{Q}}\n",
    "\\newcommand{\\boldR}{\\boldsymbol{R}}\n",
    "\\newcommand{\\boldS}{\\boldsymbol{S}}\n",
    "\\newcommand{\\boldT}{\\boldsymbol{T}}\n",
    "\\newcommand{\\boldO}{\\boldsymbol{O}}\n",
    "\\newcommand{\\boldU}{\\boldsymbol{U}}\n",
    "\\newcommand{\\boldV}{\\boldsymbol{V}}\n",
    "\\newcommand{\\boldW}{\\boldsymbol{W}}\n",
    "\\newcommand{\\boldX}{\\boldsymbol{X}}\n",
    "\\newcommand{\\boldY}{\\boldsymbol{Y}}\n",
    "\\newcommand{\\boldZ}{\\boldsymbol{Z}}\n",
    "\\newcommand{\\boldXY}{\\boldsymbol{XY}}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\boldalpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\boldbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\boldtheta}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\boldmu}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\boldxi}{\\boldsymbol{\\xi}}\n",
    "\\newcommand{\\boldeta}{\\boldsymbol{\\eta}}\n",
    "\\newcommand{\\boldpi}{\\boldsymbol{\\pi}}\n",
    "\\newcommand{\\boldsigma}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\boldphi}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\boldpsi}{\\boldsymbol{\\psi}}\n",
    "\\newcommand{\\boldlambda}{\\boldsymbol{\\lambda}}\n",
    "\\newcommand{\\boldgamma}{\\boldsymbol{\\gamma}}\n",
    "\\newcommand{\\bolddelta}{\\boldsymbol{\\delta}}\n",
    "\\newcommand{\\boldeps}{\\boldsymbol{\\eps}}\n",
    "\\newcommand{\\boldPhi}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\boldPsi}{\\boldsymbol{\\Psi}}\n",
    "\\newcommand{\\boldLambda}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\boldSigma}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\boldTheta}{\\boldsymbol{\\Theta}}\n",
    "\\newcommand{\\boldOmega}{\\boldsymbol{\\Omega}}\n",
    "\\\n",
    "\\newcommand{\\hatboldx}{\\hat{\\boldx}}\n",
    "\\newcommand{\\hatboldk}{\\hat{\\boldk}}\n",
    "\\newcommand{\\hatboldw}{\\hat{\\boldw}}\n",
    "\\newcommand{\\hatboldp}{\\hat{\\boldp}}\n",
    "\\newcommand{\\hatboldK}{\\hat{\\boldK}}\n",
    "\\newcommand{\\hatboldC}{\\hat{\\boldC}}\n",
    "\\newcommand{\\hatboldS}{\\hat{\\boldS}}\n",
    "\\newcommand{\\hatboldU}{\\hat{\\boldU}}\n",
    "\\newcommand{\\hatboldV}{\\hat{\\boldV}}\n",
    "\\newcommand{\\hatboldX}{\\hat{\\boldX}}\n",
    "\\newcommand{\\hatboldSigma}{\\hat{\\boldSigma}}\n",
    "\\newcommand{\\hatboldLambda}{\\hat{\\boldLambda}}\n",
    "\\newcommand{\\hatboldy}{\\hat{\\boldy}}\n",
    "\\newcommand{\\hatboldmu}{\\hat{\\boldmu}}\n",
    "\\newcommand{\\hatboldalpha}{\\hat{\\boldalpha}}\n",
    "\\newcommand{\\hatboldbeta}{\\hat{\\boldbeta}}\n",
    "\\newcommand{\\hatboldgamma}{\\hat{\\boldgamma}}\n",
    "\\newcommand{\\hatboldtheta}{\\hat{\\bold\\theta}}\n",
    "\\newcommand{\\hatboldeps}{\\hat{\\boldeps}}\n",
    "\\newcommand{\\hatbolddelta}{\\hat{\\bolddelta}}\n",
    "\\\n",
    "\\newcommand{\\tilboldbeta}{\\tilde{\\boldbeta}}\n",
    "\\newcommand{\\tilboldw}{\\tilde{\\boldw}}\n",
    "\\newcommand{\\tilboldmu}{\\tilde{\\boldmu}}\n",
    "\\\n",
    "\\newcommand{\\xs}[1]{\\boldx^{#1}}\n",
    "\\newcommand{\\ys}[1]{\\boldy^{#1}}\n",
    "\\newcommand{\\zs}[1]{\\boldz^{#1}}\n",
    "\\newcommand{\\Xs}[1]{\\boldX^{#1}}\n",
    "\\newcommand{\\Ys}[1]{\\boldY^{#1}}\n",
    "\\newcommand{\\Zs}[1]{\\boldZ^{#1}}\n",
    "\\\n",
    "\\newcommand{\\Ndim}{N}\n",
    "\\newcommand{\\Ddim}{D}\n",
    "\\newcommand{\\Mdim}{M}\n",
    "\\newcommand{\\Kdim}{K}\n",
    "\\newcommand{\\Adim}{A}\n",
    "\\newcommand{\\Qdim}{Q}\n",
    "\\newcommand{\\Rdim}{R}\n",
    "\\\n",
    "\\newcommand{\\mcalA}{\\mathcal{A}}\n",
    "\\newcommand{\\mcalB}{\\mathcal{B}}\n",
    "\\newcommand{\\mcalC}{\\mathcal{C}}\n",
    "\\newcommand{\\mcalD}{\\mathcal{D}}\n",
    "\\newcommand{\\mcalE}{\\mathcal{E}}\n",
    "\\newcommand{\\mcalF}{\\mathcal{F}}\n",
    "\\newcommand{\\mcalI}{\\mathcal{I}}\n",
    "\\newcommand{\\mcalL}{\\mathcal{L}}\n",
    "\\newcommand{\\mcalP}{\\mathcal{P}}\n",
    "\\newcommand{\\mcalQ}{\\mathcal{Q}}\n",
    "\\newcommand{\\mcalX}{\\mathcal{X}}\n",
    "\\newcommand{\\hatmcalB}{\\hat{\\mcalB}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\setA}{\\mathcal{A}}\n",
    "\\newcommand{\\setB}{\\mathcal{B}}\n",
    "\\newcommand{\\setC}{\\mathcal{C}}\n",
    "\\newcommand{\\setE}{\\mathcal{E}}\n",
    "\\newcommand{\\setD}{\\mathcal{D}}\n",
    "\\newcommand{\\setS}{\\mathcal{S}}\n",
    "\\newcommand{\\setT}{\\mathcal{T}}\n",
    "\\newcommand{\\setV}{\\mathcal{V}}\n",
    "\\newcommand{\\setW}{\\mathcal{W}}\n",
    "\\\n",
    "\\newcommand{\\matA}{A}\n",
    "\\newcommand{\\matB}{B}\n",
    "\\newcommand{\\matC}{C}\n",
    "\\newcommand{\\matD}{D}\n",
    "\\newcommand{\\matE}{E}\n",
    "\\newcommand{\\matI}{I}\n",
    "\\newcommand{\\matU}{U}\n",
    "\\newcommand{\\matV}{V}\n",
    "\\newcommand{\\matW}{W}\n",
    "\\newcommand{\\matPhi}{\\Phi}\n",
    "\\newcommand{\\matPsi}{\\Psi}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\Factors}{F}\n",
    "\\newcommand{\\Variables}{X}\n",
    "\\newcommand{\\Eye}{I}\n",
    "\\newcommand{\\Zero}{O}\n",
    "\\newcommand{\\Energy}{\\mathcal{E}}\n",
    "\\newcommand{\\Entropy}{\\mathcal{H}}\n",
    "\\newcommand{\\Fenergy}{F}\n",
    "\\newcommand{\\Edges}{E}\n",
    "\\newcommand{\\edge}{e}\n",
    "\\newcommand{\\Vertices}{V}\n",
    "\\newcommand{\\vertex}{v}\n",
    "\\newcommand{\\Graph}{\\mathcal{G}}\n",
    "\\newcommand{\\Tree}{\\mathcal{T}}\n",
    "\\newcommand{\\Children}{\\mathcal{C}}\n",
    "\\newcommand{\\Parents}{\\mathcal{P}}\n",
    "\\newcommand{\\Adjacent}{\\mathcal{A}}\n",
    "\\newcommand{\\Pa}{\\mathrm{Pa}}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\state}{z}\n",
    "\\newcommand{\\State}{\\boldz}\n",
    "\\newcommand{\\StateR}{\\boldZ}\n",
    "\\\n",
    "\\newcommand{\\Covariance}{\\Sigma}\n",
    "\\newcommand{\\CovX}{\\Covariance_{\\boldX}}\n",
    "\\newcommand{\\CovY}{\\Covariance_{\\boldY}}\n",
    "\\newcommand{\\CovZ}{\\Covariance_{\\boldZ}}\n",
    "\\newcommand{\\CovXY}{\\Covariance_{\\boldX\\boldY}}\n",
    "\\\n",
    "\\newcommand{\\hatCovariance}{\\hat{\\Covariance}}\n",
    "\\newcommand{\\hatCovX}{\\hatCovariance_{\\boldX}}\n",
    "\\newcommand{\\hatCovY}{\\hatCovariance_{\\boldY}}\n",
    "\\newcommand{\\hatCovZ}{\\hatCovariance_{\\boldZ}}\n",
    "\\newcommand{\\hatCovXY}{\\hatCovariance_{\\boldX\\boldY}}\n",
    "\\\n",
    "\\newcommand{\\tildeCovariance}{\\tilde{\\Covariance}}\n",
    "\\newcommand{\\tildeCovX}{\\tildeCovariance_{\\boldX}}\n",
    "\\newcommand{\\tildeCovY}{\\tildeCovariance_{\\boldY}}\n",
    "\\newcommand{\\tildeCovZ}{\\tildeCovariance_{\\boldZ}}\n",
    "\\newcommand{\\tildeCovXY}{\\tildeCovariance_{\\boldX\\boldY}}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\hatState}{\\hat{\\State}}\n",
    "\\newcommand{\\StateNum}{N}\n",
    "\\newcommand{\\StateDim}{K}\n",
    "\\newcommand{\\StateSet}{\\ZZ}\n",
    "\\newcommand{\\StatesSet}{\\StateSet}\n",
    "\\newcommand{\\NumStates}{N}\n",
    "\\newcommand{\\StateToState}{A}\n",
    "\\newcommand{\\StateCov}{\\Sigma}\n",
    "\\newcommand{\\StateJac}{A}\n",
    "\\\n",
    "\\newcommand{\\hatStateCov}{\\hat{\\StateCov}}\n",
    "\\newcommand{\\StateMean}{\\boldmu}\n",
    "\\newcommand{\\hatStateMean}{\\hat{\\StateMean}}\n",
    "\\newcommand{\\StateToStateHistory}{\\boldA}\n",
    "\\newcommand{\\StateNoise}{\\boldr}\n",
    "\\newcommand{\\StateNoiseCov}{R}\n",
    "\\newcommand{\\StateHistory}{\\boldZ}\n",
    "\\newcommand{\\StatesHistory}{\\StateHistory}\n",
    "\\newcommand{\\StateToObserv}{C}\n",
    "\\newcommand{\\StateToobserv}{\\boldc}\n",
    "\\newcommand{\\StateToObservHistory}{\\boldC}\n",
    "\\\n",
    "\\newcommand{\\DState}{\\bolddelta}\n",
    "\\newcommand{\\hatDState}{\\hat{\\DState}}\n",
    "\\newcommand{\\DStateMean}{\\boldlambda}\n",
    "\\newcommand{\\hatDStateMean}{\\hat{\\DStateMean}}\n",
    "\\newcommand{\\DStateCov}{\\Lambda}\n",
    "\\newcommand{\\hatDStateCov}{\\hat{\\DStateCov}}\n",
    "\\\n",
    "\\newcommand{\\DObserv}{\\boldgamma}\n",
    "\\newcommand{\\hatDObserv}{\\hat{\\DObserv}}\n",
    "\\\n",
    "\\newcommand{\\observ}{x}\n",
    "\\newcommand{\\Observ}{\\boldsymbol{\\observ}}\n",
    "\\newcommand{\\ObservCov}{\\Lambda}\n",
    "\\newcommand{\\observMean}{\\lambda}\n",
    "\\newcommand{\\ObservMean}{\\boldlambda}\n",
    "\\newcommand{\\hatobserv}{\\hat{\\observ}}\n",
    "\\newcommand{\\hatObserv}{\\hat{\\Observ}}\n",
    "\\newcommand{\\hatObservCov}{\\hat{\\ObservCov}}\n",
    "\\newcommand{\\hatobservMean}{\\hat{\\observMean}}\n",
    "\\newcommand{\\hatObservMean}{\\hat{\\ObservMean}}\n",
    "\\\n",
    "\\newcommand{\\ObservSet}{\\XX}\n",
    "\\newcommand{\\ObservNum}{N}\n",
    "\\newcommand{\\ObservDim}{D}\n",
    "\\newcommand{\\ObservSourceNum}{M}\n",
    "\\newcommand{\\ObservHistory}{\\boldX}\n",
    "\\newcommand{\\ObservsHistory}{\\ObservHistory}\n",
    "\\newcommand{\\Timestamps}{\\boldT}\n",
    "\\newcommand{\\ObservJac}{H}\n",
    "% Шум наблюдений\n",
    "\\newcommand{\\observNoise}{q}\n",
    "\\newcommand{\\ObservNoise}{\\boldq}\n",
    "\\newcommand{\\ObservNoiseCov}{Q}\n",
    "\\newcommand{\\ObservNoiseCovHistory}{\\boldQ}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\control}{u}\n",
    "\\newcommand{\\Control}{\\boldu}\n",
    "\\newcommand{\\ControlNum}{N}\n",
    "\\newcommand{\\ControToState}{B}\n",
    "\\newcommand{\\ControlToStateHistory}{\\boldB}\n",
    "\\newcommand{\\ControlHistory}{\\boldU}\n",
    "\\\n",
    "\\newcommand{\\Jacobian}{\\boldJ}\n",
    "\\\n",
    "\\newcommand{\\Kalman}{K}\n",
    "\\newcommand{\\kalman}{\\boldk}\n",
    "\\\n",
    "\\newcommand{\\vel}{v}\n",
    "$\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e1dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T08:30:19.382520Z",
     "start_time": "2023-05-24T08:30:19.373869Z"
    }
   },
   "source": [
    "### Tex commands examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0edc3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def add_example(string):\n",
    "    return re.sub(\n",
    "        r\"\\\\newcommand{(\\\\.+?)}(.+?)\\n\", r\"\\\\text{\\1} \\\\quad \\1 x \\\\\\\\\\n\", string\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5733b9f8",
   "metadata": {},
   "source": [
    "$\n",
    "% The list of general commands\n",
    "\\newcommand{\\PI}{3.141592654}\n",
    "\\newcommand{\\Sum}{\\sum\\limits}\n",
    "\\newcommand{\\Int}{\\int\\limits}\n",
    "\\newcommand{\\Lim}{\\lim\\limits}\n",
    "\\newcommand{\\Prod}{\\prod\\limits}\n",
    "\\newcommand{\\Intf}{\\int\\limits_{-\\infty}^{+\\infty}}\n",
    "\\newcommand{\\Sumclap}[1]{\\Sum_{\\mathclap{#1}}}\n",
    "\\newcommand{\\Intclap}[1]{\\Int_{\\mathclap{#1}}}\n",
    "\\newcommand{\\Prodclap}[1]{\\Prod_{\\mathclap{#1}}}\n",
    "\\newcommand{\\Aprod}{\\bigodot}\n",
    "\\newcommand{\\aprod}{\\odot}\n",
    "\\newcommand{\\Max}{\\max\\limits}\n",
    "\\newcommand{\\Min}{\\min\\limits}\n",
    "\\newcommand{\\argmax}{\\arg\\max}\n",
    "\\newcommand{\\argmin}{\\arg\\min}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\lp}{\\left(}\n",
    "\\newcommand{\\rp}{\\right)}\n",
    "\\newcommand{\\lf}{\\left\\{}\n",
    "\\newcommand{\\rf}{\\right\\}}\n",
    "\\newcommand{\\ls}{\\left[}\n",
    "\\newcommand{\\rs}{\\right]}\n",
    "\\newcommand{\\lv}{\\left|}\n",
    "\\newcommand{\\rv}{\\right|}\n",
    "\\newcommand{\\la}{\\left\\langle}\n",
    "\\newcommand{\\ra}{\\right\\rangle}\n",
    "\\\n",
    "% Обозначения из предметной области: теории вероятностей и статистики\n",
    "\\newcommand{\\Distr}{\\mathsf{D}}\n",
    "\\newcommand{\\Var}{\\mathbb{V}}\n",
    "\\newcommand{\\Exp}{\\mathbb{E}}\n",
    "\\newcommand{\\Cov}{\\mathbb{C}\\mathrm{ov}}\n",
    "\\newcommand{\\Loss}{\\mathcal{L}}\n",
    "\\newcommand{\\loss}{\\ell}\n",
    "\\newcommand{\\LogLike}{\\mathcal{L}}\n",
    "\\newcommand{\\Like}{\\ell}\n",
    "\\newcommand{\\Risk}{\\mathcal{R}}\n",
    "\\newcommand{\\makebold}[1]{\\boldsymbol{#1}}\n",
    "\\\n",
    "\\newcommand{\\mean}[1]{\\overline{#1}}\n",
    "\\newcommand{\\avg}[1]{\\overline{#1}}\n",
    "\\newcommand{\\angmean}[1]{\\left\\langle #1 \\right\\rangle}\n",
    "\\newcommand{\\barmean}[1]{\\overline{#1}}\n",
    "\\\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\renewcommand{\\epsilon}{\\varepsilon}\n",
    "\\newcommand{\\Ind}{I}\n",
    "\\newcommand{\\Fisher}{I}\n",
    "\\\n",
    "\\newcommand{\\HOT}{\\text{\\textbf{H.O.T.}}}\n",
    "\\\n",
    "\\newcommand{\\partfrac}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\ttt}[1]{\\texttt{#1}}\n",
    "\\newcommand{\\term}[1]{\\textbf{#1}}\n",
    "$\n",
    "$\n",
    "\\\n",
    "\\renewcommand{\\phi}{\\varphi}\n",
    "\\\n",
    "\\newcommand{\\CC}{\\mathbb{C}}\n",
    "\\newcommand{\\NN}{\\mathbb{N}}\n",
    "\\newcommand{\\PP}{\\mathbb{P}}\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\XX}{\\mathbb{X}}\n",
    "\\newcommand{\\ZZ}{\\mathbb{Z}}\n",
    "\\renewcommand{\\AA}{\\mathbb{A}}\n",
    "\\\n",
    "\\newcommand{\\Xbb}{\\mathbb{X}}\n",
    "\\newcommand{\\Ybb}{\\mathbb{Y}}\n",
    "\\newcommand{\\Zbb}{\\mathbb{Z}}\n",
    "\\\n",
    "% Empirical values\n",
    "\\newcommand{\\Ecdf}[1]{\\hat{F}_n(#1)}\n",
    "\\newcommand{\\OPT}{\\ensuremath{\\mathrm{OPT}\\xspace}}\n",
    "\\newcommand{\\opt}{\\ensuremath{\\mathrm{opt}\\xspace}}\n",
    "\\newcommand{\\boot}{\\ensuremath{\\mathrm{boot}\\xspace}}\n",
    "\\newcommand{\\bias}{\\ensuremath{\\mathrm{bias}\\xspace}}\n",
    "\\newcommand{\\se}{\\ensuremath{\\mathrm{se}\\xspace}}\n",
    "\\newcommand{\\MSE}{\\ensuremath{\\mathrm{MSE}\\xspace}}\n",
    "\\newcommand{\\RSS}{\\ensuremath{\\mathrm{RSS}\\xspace}}\n",
    "\\newcommand{\\qm}{\\ensuremath{\\mathrm{qm}\\xspace}}\n",
    "\\newcommand{\\as}{\\ensuremath{\\mathrm{as}\\xspace}}\n",
    "\\newcommand{\\trace}{\\ensuremath{\\mathrm{tr}\\xspace}}\n",
    "\\newcommand{\\const}{\\ensuremath{\\mathrm{const}\\xspace}}\n",
    "\\newcommand{\\sign}{\\ensuremath{\\mathrm{sign}\\xspace}}\n",
    "\\newcommand{\\tr}{\\mathrm{tr}}\n",
    "\\newcommand{\\new}{\\mathrm{new}}\n",
    "\\newcommand{\\lasso}{\\mathrm{lasso}}\n",
    "\\newcommand{\\old}{\\mathrm{old}}\n",
    "\\newcommand{\\diag}{\\mathrm{diag}}\n",
    "\\newcommand{\\rank}{\\mathrm{rg}}\n",
    "\\newcommand{\\ML}{\\mathrm{ML}}\n",
    "\\newcommand{\\MP}{\\mathrm{MP}}\n",
    "\\newcommand{\\KL}{\\mathrm{KL}}\n",
    "\\newcommand{\\NV}{\\mathrm{NV}}\n",
    "\\newcommand{\\MV}{\\mathrm{MV}}\n",
    "\\newcommand{\\NP}{\\mathrm{MP}}   % Нейман-Пирсон\n",
    "\\newcommand{\\vs}{\\mathrm{vs}}   % versus\n",
    "\\newcommand{\\LOO}{\\mathrm{LOO}}\n",
    "\\newcommand{\\IGMV}{\\mathrm{IGMV}}\n",
    "\\newcommand{\\MM}{\\mathrm{MM}}\n",
    "\\newcommand{\\nat}{\\mathrm{nat}\\xspace}\n",
    "\\newcommand{\\grad}{\\mathrm{grad}\\xspace}\n",
    "% Оценки\n",
    "\\newcommand{\\esttheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\estlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\estmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\estsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\estalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\estbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\estxi}{\\hat{\\xi}}\n",
    "\\newcommand{\\esttau}{\\hat{\\tau}}\n",
    "\\newcommand{\\estpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\esta}{\\hat{a}}\n",
    "\\newcommand{\\estb}{\\hat{b}}\n",
    "\\newcommand{\\estc}{\\hat{c}}\n",
    "\\newcommand{\\estd}{\\hat{d}}\n",
    "\\newcommand{\\estf}{\\hat{f}}\n",
    "\\newcommand{\\estp}{\\hat{p}}\n",
    "\\newcommand{\\esty}{\\hat{y}}\n",
    "\\newcommand{\\estT}{\\hat{T}}\n",
    "\\newcommand{\\estR}{\\hat{R}}\n",
    "\\newcommand{\\estF}{\\hat{F}}\n",
    "\\newcommand{\\estC}{\\hat{C}}\n",
    "\\newcommand{\\estS}{\\hat{S}}\n",
    "\\newcommand{\\estY}{\\hat{Y}}\n",
    "\\newcommand{\\estVar}{\\hat{\\Var}}\n",
    "\\newcommand{\\estExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\estSe}{\\hat{\\se}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\ecdf}{\\hat{F}}\n",
    "\\\n",
    "\\newcommand{\\hata}{\\hat{a}}\n",
    "\\newcommand{\\hatb}{\\hat{b}}\n",
    "\\newcommand{\\hatc}{\\hat{c}}\n",
    "\\newcommand{\\hatd}{\\hat{d}}\n",
    "\\newcommand{\\hatf}{\\hat{f}}\n",
    "\\newcommand{\\hatg}{\\hat{g}}\n",
    "\\newcommand{\\hatk}{\\hat{k}}\n",
    "\\newcommand{\\hatp}{\\hat{p}}\n",
    "\\newcommand{\\hatr}{\\hat{r}}\n",
    "\\newcommand{\\hatt}{\\hat{t}}\n",
    "\\newcommand{\\haty}{\\hat{y}}\n",
    "\\newcommand{\\hatw}{\\hat{w}}\n",
    "\\\n",
    "\\newcommand{\\hatC}{\\hat{C}}\n",
    "\\newcommand{\\hatF}{\\hat{F}}\n",
    "\\newcommand{\\hatJ}{\\hat{J}}\n",
    "\\newcommand{\\hatK}{\\hat{K}}\n",
    "\\newcommand{\\hatP}{\\hat{P}}\n",
    "\\newcommand{\\hatS}{\\hat{S}}\n",
    "\\newcommand{\\hatT}{\\hat{T}}\n",
    "\\newcommand{\\hatY}{\\hat{Y}}\n",
    "\\newcommand{\\hatV}{\\hat{V}}\n",
    "\\newcommand{\\hatU}{\\hat{U}}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\hateps}{\\hat{\\eps}}\n",
    "\\newcommand{\\hatalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\hatbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\hatpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\hatlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\hattheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\hatsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\hatmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\hatnu}{\\hat{\\nu}}\n",
    "\\newcommand{\\hatSigma}{\\hat{\\Sigma}}\n",
    "\\newcommand{\\hatSe}{\\hat{\\se}}\n",
    "\\newcommand{\\hatExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\hatVar}{\\hat{\\Var}}\n",
    "\\\n",
    "\\newcommand{\\tilx}{\\tilde{x}}\n",
    "\\newcommand{\\tily}{\\tilde{y}}\n",
    "\\newcommand{\\tilX}{\\tilde{X}}\n",
    "\\newcommand{\\tilY}{\\tilde{Y}}\n",
    "\\newcommand{\\tilK}{\\tilde{K}}\n",
    "\\newcommand{\\tilU}{\\tilde{U}}\n",
    "\\newcommand{\\tilV}{\\tilde{V}}\n",
    "\\newcommand{\\tilSigma}{\\tilde{\\Sigma}}\n",
    "\\newcommand{\\tiltau}{\\tilde{\\tau}}\n",
    "\\newcommand{\\tiltheta}{\\tilde{\\theta}}\n",
    "\\newcommand{\\tillambda}{\\tilde{\\lambda}}\n",
    "\\newcommand{\\tilsigma}{\\tilde{\\sigma}}\n",
    "\\newcommand{\\tilpsi}{\\tilde{\\psi}}\n",
    "\\newcommand{\\tilmu}{\\tilde{\\mu}}\n",
    "\\\n",
    "\\newcommand{\\MLE}{\\text{MLE}}\n",
    "\\newcommand{\\mlexi}{\\xi_{MLE}}\n",
    "\\newcommand{\\mletheta}{\\theta_{MLE}}\n",
    "\\newcommand{\\mlelambda}{\\lambda_{MLE}}\n",
    "\\newcommand{\\mlesigma}{\\sigma_{MLE}}\n",
    "\\newcommand{\\mlepsi}{\\psi_{MLE}}\n",
    "\\newcommand{\\mlemu}{\\mu_{MLE}}\n",
    "\\newcommand{\\mlenu}{\\nu_{MLE}}\n",
    "\\\n",
    "\\newcommand{\\mmxi}{\\xi_{MM}}\n",
    "\\newcommand{\\mmtheta}{\\theta_{MM}}\n",
    "\\newcommand{\\mmlambda}{\\lambda_{MM}}\n",
    "\\newcommand{\\mmsigma}{\\sigma_{MM}}\n",
    "\\newcommand{\\mmpsi}{\\psi_{MM}}\n",
    "\\newcommand{\\mmalpha}{\\alpha_{MM}}\n",
    "\\newcommand{\\mmbeta}{\\beta_{MM}}\n",
    "\\\n",
    "% Классы распределений\n",
    "\\newcommand{\\Poisson}{\\mathrm{Poisson}\\xspace}\n",
    "\\newcommand{\\Triangle}{\\mathrm{Triangle}\\xspace}\n",
    "\\newcommand{\\Uniform}{\\mathrm{Uniform}\\xspace}\n",
    "\\newcommand{\\Binomial}{\\mathrm{Binomial}\\xspace}\n",
    "\\newcommand{\\Multinomial}{\\mathrm{Multinomial}\\xspace}\n",
    "\\newcommand{\\Bernoulli}{\\mathrm{Bernoulli}\\xspace}\n",
    "\\newcommand{\\Gammap}{\\mathrm{Gamma}\\xspace}\n",
    "\\newcommand{\\Normal}{\\mathcal{N}\\xspace}\n",
    "\\newcommand{\\Student}{\\mathcal{T}\\xspace}\n",
    "%\\newcommand{\\Student}{\\mathrm{Student}\\xspace}\n",
    "\\newcommand{\\LogN}{\\mathrm{LogN}\\xspace}\n",
    "\\newcommand{\\Exponential}{\\mathrm{Exp}\\xspace}\n",
    "\\newcommand{\\Erlang}{\\mathrm{Erlang}\\xspace}\n",
    "\\newcommand{\\Cauchy}{C\\xspace}\n",
    "\\newcommand{\\Dir}{\\mathrm{Dir}\\xspace}\n",
    "\\newcommand{\\Beta}{\\mathrm{Beta}\\xspace}\n",
    "\\newcommand{\\Pareto}{\\mathrm{Pareto}\\xspace}\n",
    "$\n",
    "$\n",
    "%\n",
    "\\newcommand{\\Family}{\\mathfrak{F}}\n",
    "\\\n",
    "% Гипотезы\n",
    "\\newcommand{\\RejectRegion}{R}\n",
    "\\newcommand{\\pvalue}{\\text{p-value}\\xspace}\n",
    "\\newcommand{\\llr}{\\ell}\n",
    "\\newcommand{\\Llr}{\\mathcal{L}}\n",
    "\\\n",
    "% Регрессия\n",
    "\\newcommand{\\RRS}{\\mathrm{RSS}\\xspace}\n",
    "\\\n",
    "\\newcommand{\\redtext}[1]{\\textcolor{red}{#1}}\n",
    "\\newcommand{\\addtask}[1]{\\hyperref[#1]{\\redtext{Задача~\\ref*{#1}}}}\n",
    "\\newcommand{\\solution}{\\redtext{\\textbf{Решение.}}}\n",
    "\\newcommand{\\ignore}[1]{\\xspace}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\NumOfSamples}{\\mathcal{N}}\n",
    "\\newcommand{\\NumOfDims}{\\mathcal{D}}\n",
    "\\newcommand{\\NumOfHidden}{\\mathcal{H}}\n",
    "\\newcommand{\\NumOfClasses}{\\mathcal{K}}\n",
    "\\newcommand{\\NumOfChannels}{\\mathcal{C}}\n",
    "\\newcommand{\\NumOfFilters}{\\mathcal{F}}\n",
    "\\newcommand{\\HiddenSize}{\\mathcal{H}}\n",
    "\\\n",
    "\\newcommand{\\boldzero}{\\boldsymbol{0}}\n",
    "\\newcommand{\\boldones}{\\boldsymbol{1}}\n",
    "\\newcommand{\\boldone}{\\boldsymbol{1}}\n",
    "\\\n",
    "\\newcommand{\\bolda}{\\boldsymbol{a}}\n",
    "\\newcommand{\\boldb}{\\boldsymbol{b}}\n",
    "\\newcommand{\\boldc}{\\boldsymbol{c}}\n",
    "\\newcommand{\\boldd}{\\boldsymbol{d}}\n",
    "\\newcommand{\\bolde}{\\boldsymbol{e}}\n",
    "\\newcommand{\\boldf}{\\boldsymbol{f}}\n",
    "\\newcommand{\\boldg}{\\boldsymbol{g}}\n",
    "\\newcommand{\\boldh}{\\boldsymbol{h}}\n",
    "\\newcommand{\\boldi}{\\boldsymbol{i}}\n",
    "\\newcommand{\\boldj}{\\boldsymbol{j}}\n",
    "\\newcommand{\\boldk}{\\boldsymbol{k}}\n",
    "\\newcommand{\\boldl}{\\boldsymbol{l}}\n",
    "\\newcommand{\\boldm}{\\boldsymbol{m}}\n",
    "\\newcommand{\\boldn}{\\boldsymbol{n}}\n",
    "\\newcommand{\\boldo}{\\boldsymbol{o}}\n",
    "\\newcommand{\\boldp}{\\boldsymbol{p}}\n",
    "\\newcommand{\\boldq}{\\boldsymbol{q}}\n",
    "\\newcommand{\\boldr}{\\boldsymbol{r}}\n",
    "\\newcommand{\\bolds}{\\boldsymbol{s}}\n",
    "\\newcommand{\\boldt}{\\boldsymbol{t}}\n",
    "\\newcommand{\\boldu}{\\boldsymbol{u}}\n",
    "\\newcommand{\\boldv}{\\boldsymbol{v}}\n",
    "\\newcommand{\\boldw}{\\boldsymbol{w}}\n",
    "\\newcommand{\\boldx}{\\boldsymbol{x}}\n",
    "\\newcommand{\\boldy}{\\boldsymbol{y}}\n",
    "\\newcommand{\\boldz}{\\boldsymbol{z}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\boldA}{\\boldsymbol{A}}\n",
    "\\newcommand{\\boldB}{\\boldsymbol{B}}\n",
    "\\newcommand{\\boldC}{\\boldsymbol{C}}\n",
    "\\newcommand{\\boldD}{\\boldsymbol{D}}\n",
    "\\newcommand{\\boldE}{\\boldsymbol{E}}\n",
    "\\newcommand{\\boldF}{\\boldsymbol{F}}\n",
    "\\newcommand{\\boldH}{\\boldsymbol{H}}\n",
    "\\newcommand{\\boldJ}{\\boldsymbol{J}}\n",
    "\\newcommand{\\boldK}{\\boldsymbol{K}}\n",
    "\\newcommand{\\boldL}{\\boldsymbol{L}}\n",
    "\\newcommand{\\boldM}{\\boldsymbol{M}}\n",
    "\\newcommand{\\boldN}{\\boldsymbol{N}}\n",
    "\\newcommand{\\boldI}{\\boldsymbol{I}}\n",
    "\\newcommand{\\boldP}{\\boldsymbol{P}}\n",
    "\\newcommand{\\boldQ}{\\boldsymbol{Q}}\n",
    "\\newcommand{\\boldR}{\\boldsymbol{R}}\n",
    "\\newcommand{\\boldS}{\\boldsymbol{S}}\n",
    "\\newcommand{\\boldT}{\\boldsymbol{T}}\n",
    "\\newcommand{\\boldO}{\\boldsymbol{O}}\n",
    "\\newcommand{\\boldU}{\\boldsymbol{U}}\n",
    "\\newcommand{\\boldV}{\\boldsymbol{V}}\n",
    "\\newcommand{\\boldW}{\\boldsymbol{W}}\n",
    "\\newcommand{\\boldX}{\\boldsymbol{X}}\n",
    "\\newcommand{\\boldY}{\\boldsymbol{Y}}\n",
    "\\newcommand{\\boldZ}{\\boldsymbol{Z}}\n",
    "\\newcommand{\\boldXY}{\\boldsymbol{XY}}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\boldalpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\boldbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\boldtheta}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\boldmu}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\boldxi}{\\boldsymbol{\\xi}}\n",
    "\\newcommand{\\boldeta}{\\boldsymbol{\\eta}}\n",
    "\\newcommand{\\boldpi}{\\boldsymbol{\\pi}}\n",
    "\\newcommand{\\boldsigma}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\boldphi}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\boldpsi}{\\boldsymbol{\\psi}}\n",
    "\\newcommand{\\boldlambda}{\\boldsymbol{\\lambda}}\n",
    "\\newcommand{\\boldgamma}{\\boldsymbol{\\gamma}}\n",
    "\\newcommand{\\bolddelta}{\\boldsymbol{\\delta}}\n",
    "\\newcommand{\\boldeps}{\\boldsymbol{\\eps}}\n",
    "\\newcommand{\\boldPhi}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\boldPsi}{\\boldsymbol{\\Psi}}\n",
    "\\newcommand{\\boldLambda}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\boldSigma}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\boldTheta}{\\boldsymbol{\\Theta}}\n",
    "\\newcommand{\\boldOmega}{\\boldsymbol{\\Omega}}\n",
    "\\\n",
    "\\newcommand{\\hatboldx}{\\hat{\\boldx}}\n",
    "\\newcommand{\\hatboldk}{\\hat{\\boldk}}\n",
    "\\newcommand{\\hatboldw}{\\hat{\\boldw}}\n",
    "\\newcommand{\\hatboldp}{\\hat{\\boldp}}\n",
    "\\newcommand{\\hatboldK}{\\hat{\\boldK}}\n",
    "\\newcommand{\\hatboldC}{\\hat{\\boldC}}\n",
    "\\newcommand{\\hatboldS}{\\hat{\\boldS}}\n",
    "\\newcommand{\\hatboldU}{\\hat{\\boldU}}\n",
    "\\newcommand{\\hatboldV}{\\hat{\\boldV}}\n",
    "\\newcommand{\\hatboldX}{\\hat{\\boldX}}\n",
    "\\newcommand{\\hatboldSigma}{\\hat{\\boldSigma}}\n",
    "\\newcommand{\\hatboldLambda}{\\hat{\\boldLambda}}\n",
    "\\newcommand{\\hatboldy}{\\hat{\\boldy}}\n",
    "\\newcommand{\\hatboldmu}{\\hat{\\boldmu}}\n",
    "\\newcommand{\\hatboldalpha}{\\hat{\\boldalpha}}\n",
    "\\newcommand{\\hatboldbeta}{\\hat{\\boldbeta}}\n",
    "\\newcommand{\\hatboldgamma}{\\hat{\\boldgamma}}\n",
    "\\newcommand{\\hatboldtheta}{\\hat{\\bold\\theta}}\n",
    "\\newcommand{\\hatboldeps}{\\hat{\\boldeps}}\n",
    "\\newcommand{\\hatbolddelta}{\\hat{\\bolddelta}}\n",
    "\\\n",
    "\\newcommand{\\tilboldbeta}{\\tilde{\\boldbeta}}\n",
    "\\newcommand{\\tilboldw}{\\tilde{\\boldw}}\n",
    "\\newcommand{\\tilboldmu}{\\tilde{\\boldmu}}\n",
    "\\\n",
    "\\newcommand{\\xs}[1]{\\boldx^{#1}}\n",
    "\\newcommand{\\ys}[1]{\\boldy^{#1}}\n",
    "\\newcommand{\\zs}[1]{\\boldz^{#1}}\n",
    "\\newcommand{\\Xs}[1]{\\boldX^{#1}}\n",
    "\\newcommand{\\Ys}[1]{\\boldY^{#1}}\n",
    "\\newcommand{\\Zs}[1]{\\boldZ^{#1}}\n",
    "\\\n",
    "\\newcommand{\\Ndim}{N}\n",
    "\\newcommand{\\Ddim}{D}\n",
    "\\newcommand{\\Mdim}{M}\n",
    "\\newcommand{\\Kdim}{K}\n",
    "\\newcommand{\\Adim}{A}\n",
    "\\newcommand{\\Qdim}{Q}\n",
    "\\newcommand{\\Rdim}{R}\n",
    "\\\n",
    "\\newcommand{\\mcalA}{\\mathcal{A}}\n",
    "\\newcommand{\\mcalB}{\\mathcal{B}}\n",
    "\\newcommand{\\mcalC}{\\mathcal{C}}\n",
    "\\newcommand{\\mcalD}{\\mathcal{D}}\n",
    "\\newcommand{\\mcalE}{\\mathcal{E}}\n",
    "\\newcommand{\\mcalF}{\\mathcal{F}}\n",
    "\\newcommand{\\mcalI}{\\mathcal{I}}\n",
    "\\newcommand{\\mcalL}{\\mathcal{L}}\n",
    "\\newcommand{\\mcalP}{\\mathcal{P}}\n",
    "\\newcommand{\\mcalQ}{\\mathcal{Q}}\n",
    "\\newcommand{\\mcalX}{\\mathcal{X}}\n",
    "\\newcommand{\\hatmcalB}{\\hat{\\mcalB}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\setA}{\\mathcal{A}}\n",
    "\\newcommand{\\setB}{\\mathcal{B}}\n",
    "\\newcommand{\\setC}{\\mathcal{C}}\n",
    "\\newcommand{\\setE}{\\mathcal{E}}\n",
    "\\newcommand{\\setD}{\\mathcal{D}}\n",
    "\\newcommand{\\setS}{\\mathcal{S}}\n",
    "\\newcommand{\\setT}{\\mathcal{T}}\n",
    "\\newcommand{\\setV}{\\mathcal{V}}\n",
    "\\newcommand{\\setW}{\\mathcal{W}}\n",
    "\\\n",
    "\\newcommand{\\matA}{A}\n",
    "\\newcommand{\\matB}{B}\n",
    "\\newcommand{\\matC}{C}\n",
    "\\newcommand{\\matD}{D}\n",
    "\\newcommand{\\matE}{E}\n",
    "\\newcommand{\\matI}{I}\n",
    "\\newcommand{\\matU}{U}\n",
    "\\newcommand{\\matV}{V}\n",
    "\\newcommand{\\matW}{W}\n",
    "\\newcommand{\\matPhi}{\\Phi}\n",
    "\\newcommand{\\matPsi}{\\Psi}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\Factors}{F}\n",
    "\\newcommand{\\Variables}{X}\n",
    "\\newcommand{\\Eye}{I}\n",
    "\\newcommand{\\Zero}{O}\n",
    "\\newcommand{\\Energy}{\\mathcal{E}}\n",
    "\\newcommand{\\Entropy}{\\mathcal{H}}\n",
    "\\newcommand{\\Fenergy}{F}\n",
    "\\newcommand{\\Edges}{E}\n",
    "\\newcommand{\\edge}{e}\n",
    "\\newcommand{\\Vertices}{V}\n",
    "\\newcommand{\\vertex}{v}\n",
    "\\newcommand{\\Graph}{\\mathcal{G}}\n",
    "\\newcommand{\\Tree}{\\mathcal{T}}\n",
    "\\newcommand{\\Children}{\\mathcal{C}}\n",
    "\\newcommand{\\Parents}{\\mathcal{P}}\n",
    "\\newcommand{\\Adjacent}{\\mathcal{A}}\n",
    "\\newcommand{\\Pa}{\\mathrm{Pa}}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\state}{z}\n",
    "\\newcommand{\\State}{\\boldz}\n",
    "\\newcommand{\\StateR}{\\boldZ}\n",
    "\\\n",
    "\\newcommand{\\Covariance}{\\Sigma}\n",
    "\\newcommand{\\CovX}{\\Covariance_{\\boldX}}\n",
    "\\newcommand{\\CovY}{\\Covariance_{\\boldY}}\n",
    "\\newcommand{\\CovZ}{\\Covariance_{\\boldZ}}\n",
    "\\newcommand{\\CovXY}{\\Covariance_{\\boldX\\boldY}}\n",
    "\\\n",
    "\\newcommand{\\hatCovariance}{\\hat{\\Covariance}}\n",
    "\\newcommand{\\hatCovX}{\\hatCovariance_{\\boldX}}\n",
    "\\newcommand{\\hatCovY}{\\hatCovariance_{\\boldY}}\n",
    "\\newcommand{\\hatCovZ}{\\hatCovariance_{\\boldZ}}\n",
    "\\newcommand{\\hatCovXY}{\\hatCovariance_{\\boldX\\boldY}}\n",
    "\\\n",
    "\\newcommand{\\tildeCovariance}{\\tilde{\\Covariance}}\n",
    "\\newcommand{\\tildeCovX}{\\tildeCovariance_{\\boldX}}\n",
    "\\newcommand{\\tildeCovY}{\\tildeCovariance_{\\boldY}}\n",
    "\\newcommand{\\tildeCovZ}{\\tildeCovariance_{\\boldZ}}\n",
    "\\newcommand{\\tildeCovXY}{\\tildeCovariance_{\\boldX\\boldY}}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\hatState}{\\hat{\\State}}\n",
    "\\newcommand{\\StateNum}{N}\n",
    "\\newcommand{\\StateDim}{K}\n",
    "\\newcommand{\\StateSet}{\\ZZ}\n",
    "\\newcommand{\\StatesSet}{\\StateSet}\n",
    "\\newcommand{\\NumStates}{N}\n",
    "\\newcommand{\\StateToState}{A}\n",
    "\\newcommand{\\StateCov}{\\Sigma}\n",
    "\\newcommand{\\StateJac}{A}\n",
    "\\\n",
    "\\newcommand{\\hatStateCov}{\\hat{\\StateCov}}\n",
    "\\newcommand{\\StateMean}{\\boldmu}\n",
    "\\newcommand{\\hatStateMean}{\\hat{\\StateMean}}\n",
    "\\newcommand{\\StateToStateHistory}{\\boldA}\n",
    "\\newcommand{\\StateNoise}{\\boldr}\n",
    "\\newcommand{\\StateNoiseCov}{R}\n",
    "\\newcommand{\\StateHistory}{\\boldZ}\n",
    "\\newcommand{\\StatesHistory}{\\StateHistory}\n",
    "\\newcommand{\\StateToObserv}{C}\n",
    "\\newcommand{\\StateToobserv}{\\boldc}\n",
    "\\newcommand{\\StateToObservHistory}{\\boldC}\n",
    "\\\n",
    "\\newcommand{\\DState}{\\bolddelta}\n",
    "\\newcommand{\\hatDState}{\\hat{\\DState}}\n",
    "\\newcommand{\\DStateMean}{\\boldlambda}\n",
    "\\newcommand{\\hatDStateMean}{\\hat{\\DStateMean}}\n",
    "\\newcommand{\\DStateCov}{\\Lambda}\n",
    "\\newcommand{\\hatDStateCov}{\\hat{\\DStateCov}}\n",
    "\\\n",
    "\\newcommand{\\DObserv}{\\boldgamma}\n",
    "\\newcommand{\\hatDObserv}{\\hat{\\DObserv}}\n",
    "\\\n",
    "\\newcommand{\\observ}{x}\n",
    "\\newcommand{\\Observ}{\\boldsymbol{\\observ}}\n",
    "\\newcommand{\\ObservCov}{\\Lambda}\n",
    "\\newcommand{\\observMean}{\\lambda}\n",
    "\\newcommand{\\ObservMean}{\\boldlambda}\n",
    "\\newcommand{\\hatobserv}{\\hat{\\observ}}\n",
    "\\newcommand{\\hatObserv}{\\hat{\\Observ}}\n",
    "\\newcommand{\\hatObservCov}{\\hat{\\ObservCov}}\n",
    "\\newcommand{\\hatobservMean}{\\hat{\\observMean}}\n",
    "\\newcommand{\\hatObservMean}{\\hat{\\ObservMean}}\n",
    "\\\n",
    "\\newcommand{\\ObservSet}{\\XX}\n",
    "\\newcommand{\\ObservNum}{N}\n",
    "\\newcommand{\\ObservDim}{D}\n",
    "\\newcommand{\\ObservSourceNum}{M}\n",
    "\\newcommand{\\ObservHistory}{\\boldX}\n",
    "\\newcommand{\\ObservsHistory}{\\ObservHistory}\n",
    "\\newcommand{\\Timestamps}{\\boldT}\n",
    "\\newcommand{\\ObservJac}{H}\n",
    "% Шум наблюдений\n",
    "\\newcommand{\\observNoise}{q}\n",
    "\\newcommand{\\ObservNoise}{\\boldq}\n",
    "\\newcommand{\\ObservNoiseCov}{Q}\n",
    "\\newcommand{\\ObservNoiseCovHistory}{\\boldQ}\n",
    "\\\n",
    "\\\n",
    "\\newcommand{\\control}{u}\n",
    "\\newcommand{\\Control}{\\boldu}\n",
    "\\newcommand{\\ControlNum}{N}\n",
    "\\newcommand{\\ControToState}{B}\n",
    "\\newcommand{\\ControlToStateHistory}{\\boldB}\n",
    "\\newcommand{\\ControlHistory}{\\boldU}\n",
    "\\\n",
    "\\newcommand{\\Jacobian}{\\boldJ}\n",
    "\\\n",
    "\\newcommand{\\Kalman}{K}\n",
    "\\newcommand{\\kalman}{\\boldk}\n",
    "\\\n",
    "\\newcommand{\\vel}{v}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0331a8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Tex commands examples</summary>\n",
    "\n",
    "$\n",
    "% The list of general commands\n",
    "\\text{\\PI} \\quad \\PI x \\\\\n",
    "\\text{\\Sum} \\quad \\Sum x \\\\\n",
    "\\text{\\Int} \\quad \\Int x \\\\\n",
    "\\text{\\Lim} \\quad \\Lim x \\\\\n",
    "\\text{\\Prod} \\quad \\Prod x \\\\\n",
    "\\text{\\Intf} \\quad \\Intf x \\\\\n",
    "\\text{\\Sumclap} \\quad \\Sumclap x \\\\\n",
    "\\text{\\Intclap} \\quad \\Intclap x \\\\\n",
    "\\text{\\Prodclap} \\quad \\Prodclap x \\\\\n",
    "\\text{\\Aprod} \\quad \\Aprod x \\\\\n",
    "\\text{\\aprod} \\quad \\aprod x \\\\\n",
    "\\text{\\Max} \\quad \\Max x \\\\\n",
    "\\text{\\Min} \\quad \\Min x \\\\\n",
    "\\text{\\argmax} \\quad \\argmax x \\\\\n",
    "\\text{\\argmin} \\quad \\argmin x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\lp} \\quad \\lp x \\\\\n",
    "\\text{\\rp} \\quad \\rp x \\\\\n",
    "\\text{\\lf} \\quad \\lf x \\\\\n",
    "\\text{\\rf} \\quad \\rf x \\\\\n",
    "\\text{\\ls} \\quad \\ls x \\\\\n",
    "\\text{\\rs} \\quad \\rs x \\\\\n",
    "\\text{\\lv} \\quad \\lv x \\\\\n",
    "\\text{\\rv} \\quad \\rv x \\\\\n",
    "\\text{\\la} \\quad \\la x \\\\\n",
    "\\text{\\ra} \\quad \\ra x \\\\\n",
    "\\\n",
    "% Обозначения из предметной области: теории вероятностей и статистики\n",
    "\\text{\\Distr} \\quad \\Distr x \\\\\n",
    "\\text{\\Var} \\quad \\Var x \\\\\n",
    "\\text{\\Exp} \\quad \\Exp x \\\\\n",
    "\\text{\\Cov} \\quad \\Cov x \\\\\n",
    "\\text{\\Loss} \\quad \\Loss x \\\\\n",
    "\\text{\\loss} \\quad \\loss x \\\\\n",
    "\\text{\\LogLike} \\quad \\LogLike x \\\\\n",
    "\\text{\\Like} \\quad \\Like x \\\\\n",
    "\\text{\\Risk} \\quad \\Risk x \\\\\n",
    "\\text{\\makebold} \\quad \\makebold x \\\\\n",
    "\\\n",
    "\\text{\\mean} \\quad \\mean x \\\\\n",
    "\\text{\\avg} \\quad \\avg x \\\\\n",
    "\\text{\\angmean} \\quad \\angmean x \\\\\n",
    "\\text{\\barmean} \\quad \\barmean x \\\\\n",
    "\\\n",
    "\\text{\\eps} \\quad \\eps x \\\\\n",
    "\\renewcommand{\\epsilon}{\\varepsilon}\n",
    "\\text{\\Ind} \\quad \\Ind x \\\\\n",
    "\\text{\\Fisher} \\quad \\Fisher x \\\\\n",
    "\\\n",
    "\\text{\\HOT} \\quad \\HOT x \\\\\n",
    "\\\n",
    "\\text{\\partfrac} \\quad \\partfrac x \\\\\n",
    "\\text{\\ttt} \\quad \\ttt x \\\\\n",
    "\\text{\\term} \\quad \\term x \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\\n",
    "\\renewcommand{\\phi}{\\varphi}\n",
    "\\\n",
    "\\text{\\CC} \\quad \\CC x \\\\\n",
    "\\text{\\NN} \\quad \\NN x \\\\\n",
    "\\text{\\PP} \\quad \\PP x \\\\\n",
    "\\text{\\RR} \\quad \\RR x \\\\\n",
    "\\text{\\XX} \\quad \\XX x \\\\\n",
    "\\text{\\ZZ} \\quad \\ZZ x \\\\\n",
    "\\renewcommand{\\AA}{\\mathbb{A}}\n",
    "\\\n",
    "\\text{\\Xbb} \\quad \\Xbb x \\\\\n",
    "\\text{\\Ybb} \\quad \\Ybb x \\\\\n",
    "\\text{\\Zbb} \\quad \\Zbb x \\\\\n",
    "\\\n",
    "% Empirical values\n",
    "\\text{\\Ecdf} \\quad \\Ecdf x \\\\\n",
    "\\text{\\OPT} \\quad \\OPT x \\\\\n",
    "\\text{\\opt} \\quad \\opt x \\\\\n",
    "\\text{\\boot} \\quad \\boot x \\\\\n",
    "\\text{\\bias} \\quad \\bias x \\\\\n",
    "\\text{\\se} \\quad \\se x \\\\\n",
    "\\text{\\MSE} \\quad \\MSE x \\\\\n",
    "\\text{\\RSS} \\quad \\RSS x \\\\\n",
    "\\text{\\qm} \\quad \\qm x \\\\\n",
    "\\text{\\as} \\quad \\as x \\\\\n",
    "\\text{\\trace} \\quad \\trace x \\\\\n",
    "\\text{\\const} \\quad \\const x \\\\\n",
    "\\text{\\sign} \\quad \\sign x \\\\\n",
    "\\text{\\tr} \\quad \\tr x \\\\\n",
    "\\text{\\new} \\quad \\new x \\\\\n",
    "\\text{\\lasso} \\quad \\lasso x \\\\\n",
    "\\text{\\old} \\quad \\old x \\\\\n",
    "\\text{\\diag} \\quad \\diag x \\\\\n",
    "\\text{\\rank} \\quad \\rank x \\\\\n",
    "\\text{\\ML} \\quad \\ML x \\\\\n",
    "\\text{\\MP} \\quad \\MP x \\\\\n",
    "\\text{\\KL} \\quad \\KL x \\\\\n",
    "\\text{\\NV} \\quad \\NV x \\\\\n",
    "\\text{\\MV} \\quad \\MV x \\\\\n",
    "\\text{\\NP} \\quad \\NP x \\\\\n",
    "\\text{\\vs} \\quad \\vs x \\\\\n",
    "\\text{\\LOO} \\quad \\LOO x \\\\\n",
    "\\text{\\IGMV} \\quad \\IGMV x \\\\\n",
    "\\text{\\MM} \\quad \\MM x \\\\\n",
    "\\text{\\nat} \\quad \\nat x \\\\\n",
    "\\text{\\grad} \\quad \\grad x \\\\\n",
    "% Оценки\n",
    "\\text{\\esttheta} \\quad \\esttheta x \\\\\n",
    "\\text{\\estlambda} \\quad \\estlambda x \\\\\n",
    "\\text{\\estmu} \\quad \\estmu x \\\\\n",
    "\\text{\\estsigma} \\quad \\estsigma x \\\\\n",
    "\\text{\\estalpha} \\quad \\estalpha x \\\\\n",
    "\\text{\\estbeta} \\quad \\estbeta x \\\\\n",
    "\\text{\\estxi} \\quad \\estxi x \\\\\n",
    "\\text{\\esttau} \\quad \\esttau x \\\\\n",
    "\\text{\\estpsi} \\quad \\estpsi x \\\\\n",
    "\\text{\\esta} \\quad \\esta x \\\\\n",
    "\\text{\\estb} \\quad \\estb x \\\\\n",
    "\\text{\\estc} \\quad \\estc x \\\\\n",
    "\\text{\\estd} \\quad \\estd x \\\\\n",
    "\\text{\\estf} \\quad \\estf x \\\\\n",
    "\\text{\\estp} \\quad \\estp x \\\\\n",
    "\\text{\\esty} \\quad \\esty x \\\\\n",
    "\\text{\\estT} \\quad \\estT x \\\\\n",
    "\\text{\\estR} \\quad \\estR x \\\\\n",
    "\\text{\\estF} \\quad \\estF x \\\\\n",
    "\\text{\\estC} \\quad \\estC x \\\\\n",
    "\\text{\\estS} \\quad \\estS x \\\\\n",
    "\\text{\\estY} \\quad \\estY x \\\\\n",
    "\\text{\\estVar} \\quad \\estVar x \\\\\n",
    "\\text{\\estExp} \\quad \\estExp x \\\\\n",
    "\\text{\\estSe} \\quad \\estSe x \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{\\ecdf} \\quad \\ecdf x \\\\\n",
    "\\\n",
    "\\text{\\hata} \\quad \\hata x \\\\\n",
    "\\text{\\hatb} \\quad \\hatb x \\\\\n",
    "\\text{\\hatc} \\quad \\hatc x \\\\\n",
    "\\text{\\hatd} \\quad \\hatd x \\\\\n",
    "\\text{\\hatf} \\quad \\hatf x \\\\\n",
    "\\text{\\hatg} \\quad \\hatg x \\\\\n",
    "\\text{\\hatk} \\quad \\hatk x \\\\\n",
    "\\text{\\hatp} \\quad \\hatp x \\\\\n",
    "\\text{\\hatr} \\quad \\hatr x \\\\\n",
    "\\text{\\hatt} \\quad \\hatt x \\\\\n",
    "\\text{\\haty} \\quad \\haty x \\\\\n",
    "\\text{\\hatw} \\quad \\hatw x \\\\\n",
    "\\\n",
    "\\text{\\hatC} \\quad \\hatC x \\\\\n",
    "\\text{\\hatF} \\quad \\hatF x \\\\\n",
    "\\text{\\hatJ} \\quad \\hatJ x \\\\\n",
    "\\text{\\hatK} \\quad \\hatK x \\\\\n",
    "\\text{\\hatP} \\quad \\hatP x \\\\\n",
    "\\text{\\hatS} \\quad \\hatS x \\\\\n",
    "\\text{\\hatT} \\quad \\hatT x \\\\\n",
    "\\text{\\hatY} \\quad \\hatY x \\\\\n",
    "\\text{\\hatV} \\quad \\hatV x \\\\\n",
    "\\text{\\hatU} \\quad \\hatU x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\hateps} \\quad \\hateps x \\\\\n",
    "\\text{\\hatalpha} \\quad \\hatalpha x \\\\\n",
    "\\text{\\hatbeta} \\quad \\hatbeta x \\\\\n",
    "\\text{\\hatpsi} \\quad \\hatpsi x \\\\\n",
    "\\text{\\hatlambda} \\quad \\hatlambda x \\\\\n",
    "\\text{\\hattheta} \\quad \\hattheta x \\\\\n",
    "\\text{\\hatsigma} \\quad \\hatsigma x \\\\\n",
    "\\text{\\hatmu} \\quad \\hatmu x \\\\\n",
    "\\text{\\hatnu} \\quad \\hatnu x \\\\\n",
    "\\text{\\hatSigma} \\quad \\hatSigma x \\\\\n",
    "\\text{\\hatSe} \\quad \\hatSe x \\\\\n",
    "\\text{\\hatExp} \\quad \\hatExp x \\\\\n",
    "\\text{\\hatVar} \\quad \\hatVar x \\\\\n",
    "\\\n",
    "\\text{\\tilx} \\quad \\tilx x \\\\\n",
    "\\text{\\tily} \\quad \\tily x \\\\\n",
    "\\text{\\tilX} \\quad \\tilX x \\\\\n",
    "\\text{\\tilY} \\quad \\tilY x \\\\\n",
    "\\text{\\tilK} \\quad \\tilK x \\\\\n",
    "\\text{\\tilU} \\quad \\tilU x \\\\\n",
    "\\text{\\tilV} \\quad \\tilV x \\\\\n",
    "\\text{\\tilSigma} \\quad \\tilSigma x \\\\\n",
    "\\text{\\tiltau} \\quad \\tiltau x \\\\\n",
    "\\text{\\tiltheta} \\quad \\tiltheta x \\\\\n",
    "\\text{\\tillambda} \\quad \\tillambda x \\\\\n",
    "\\text{\\tilsigma} \\quad \\tilsigma x \\\\\n",
    "\\text{\\tilpsi} \\quad \\tilpsi x \\\\\n",
    "\\text{\\tilmu} \\quad \\tilmu x \\\\\n",
    "\\\n",
    "\\text{\\MLE} \\quad \\MLE x \\\\\n",
    "\\text{\\mlexi} \\quad \\mlexi x \\\\\n",
    "\\text{\\mletheta} \\quad \\mletheta x \\\\\n",
    "\\text{\\mlelambda} \\quad \\mlelambda x \\\\\n",
    "\\text{\\mlesigma} \\quad \\mlesigma x \\\\\n",
    "\\text{\\mlepsi} \\quad \\mlepsi x \\\\\n",
    "\\text{\\mlemu} \\quad \\mlemu x \\\\\n",
    "\\text{\\mlenu} \\quad \\mlenu x \\\\\n",
    "\\\n",
    "\\text{\\mmxi} \\quad \\mmxi x \\\\\n",
    "\\text{\\mmtheta} \\quad \\mmtheta x \\\\\n",
    "\\text{\\mmlambda} \\quad \\mmlambda x \\\\\n",
    "\\text{\\mmsigma} \\quad \\mmsigma x \\\\\n",
    "\\text{\\mmpsi} \\quad \\mmpsi x \\\\\n",
    "\\text{\\mmalpha} \\quad \\mmalpha x \\\\\n",
    "\\text{\\mmbeta} \\quad \\mmbeta x \\\\\n",
    "\\\n",
    "% Классы распределений\n",
    "\\text{\\Poisson} \\quad \\Poisson x \\\\\n",
    "\\text{\\Triangle} \\quad \\Triangle x \\\\\n",
    "\\text{\\Uniform} \\quad \\Uniform x \\\\\n",
    "\\text{\\Binomial} \\quad \\Binomial x \\\\\n",
    "\\text{\\Multinomial} \\quad \\Multinomial x \\\\\n",
    "\\text{\\Bernoulli} \\quad \\Bernoulli x \\\\\n",
    "\\text{\\Gammap} \\quad \\Gammap x \\\\\n",
    "\\text{\\Normal} \\quad \\Normal x \\\\\n",
    "\\text{\\Student} \\quad \\Student x \\\\\n",
    "%\\text{\\Student} \\quad \\Student x \\\\\n",
    "\\text{\\LogN} \\quad \\LogN x \\\\\n",
    "\\text{\\Exponential} \\quad \\Exponential x \\\\\n",
    "\\text{\\Erlang} \\quad \\Erlang x \\\\\n",
    "\\text{\\Cauchy} \\quad \\Cauchy x \\\\\n",
    "\\text{\\Dir} \\quad \\Dir x \\\\\n",
    "\\text{\\Beta} \\quad \\Beta x \\\\\n",
    "\\text{\\Pareto} \\quad \\Pareto x \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "%\n",
    "\\text{\\Family} \\quad \\Family x \\\\\n",
    "\\\n",
    "% Гипотезы\n",
    "\\text{\\RejectRegion} \\quad \\RejectRegion x \\\\\n",
    "\\text{\\pvalue} \\quad \\pvalue x \\\\\n",
    "\\text{\\llr} \\quad \\llr x \\\\\n",
    "\\text{\\Llr} \\quad \\Llr x \\\\\n",
    "\\\n",
    "% Регрессия\n",
    "\\text{\\RRS} \\quad \\RRS x \\\\\n",
    "\\\n",
    "\\text{\\redtext} \\quad \\redtext x \\\\\n",
    "\\text{\\addtask} \\quad \\addtask x \\\\\n",
    "\\text{\\solution} \\quad \\solution x \\\\\n",
    "\\text{\\ignore} \\quad \\ignore x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\NumOfSamples} \\quad \\NumOfSamples x \\\\\n",
    "\\text{\\NumOfDims} \\quad \\NumOfDims x \\\\\n",
    "\\text{\\NumOfHidden} \\quad \\NumOfHidden x \\\\\n",
    "\\text{\\NumOfClasses} \\quad \\NumOfClasses x \\\\\n",
    "\\text{\\NumOfChannels} \\quad \\NumOfChannels x \\\\\n",
    "\\text{\\NumOfFilters} \\quad \\NumOfFilters x \\\\\n",
    "\\text{\\HiddenSize} \\quad \\HiddenSize x \\\\\n",
    "\\\n",
    "\\text{\\boldzero} \\quad \\boldzero x \\\\\n",
    "\\text{\\boldones} \\quad \\boldones x \\\\\n",
    "\\text{\\boldone} \\quad \\boldone x \\\\\n",
    "\\\n",
    "\\text{\\bolda} \\quad \\bolda x \\\\\n",
    "\\text{\\boldb} \\quad \\boldb x \\\\\n",
    "\\text{\\boldc} \\quad \\boldc x \\\\\n",
    "\\text{\\boldd} \\quad \\boldd x \\\\\n",
    "\\text{\\bolde} \\quad \\bolde x \\\\\n",
    "\\text{\\boldf} \\quad \\boldf x \\\\\n",
    "\\text{\\boldg} \\quad \\boldg x \\\\\n",
    "\\text{\\boldh} \\quad \\boldh x \\\\\n",
    "\\text{\\boldi} \\quad \\boldi x \\\\\n",
    "\\text{\\boldj} \\quad \\boldj x \\\\\n",
    "\\text{\\boldk} \\quad \\boldk x \\\\\n",
    "\\text{\\boldl} \\quad \\boldl x \\\\\n",
    "\\text{\\boldm} \\quad \\boldm x \\\\\n",
    "\\text{\\boldn} \\quad \\boldn x \\\\\n",
    "\\text{\\boldo} \\quad \\boldo x \\\\\n",
    "\\text{\\boldp} \\quad \\boldp x \\\\\n",
    "\\text{\\boldq} \\quad \\boldq x \\\\\n",
    "\\text{\\boldr} \\quad \\boldr x \\\\\n",
    "\\text{\\bolds} \\quad \\bolds x \\\\\n",
    "\\text{\\boldt} \\quad \\boldt x \\\\\n",
    "\\text{\\boldu} \\quad \\boldu x \\\\\n",
    "\\text{\\boldv} \\quad \\boldv x \\\\\n",
    "\\text{\\boldw} \\quad \\boldw x \\\\\n",
    "\\text{\\boldx} \\quad \\boldx x \\\\\n",
    "\\text{\\boldy} \\quad \\boldy x \\\\\n",
    "\\text{\\boldz} \\quad \\boldz x \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{\\boldA} \\quad \\boldA x \\\\\n",
    "\\text{\\boldB} \\quad \\boldB x \\\\\n",
    "\\text{\\boldC} \\quad \\boldC x \\\\\n",
    "\\text{\\boldD} \\quad \\boldD x \\\\\n",
    "\\text{\\boldE} \\quad \\boldE x \\\\\n",
    "\\text{\\boldF} \\quad \\boldF x \\\\\n",
    "\\text{\\boldH} \\quad \\boldH x \\\\\n",
    "\\text{\\boldJ} \\quad \\boldJ x \\\\\n",
    "\\text{\\boldK} \\quad \\boldK x \\\\\n",
    "\\text{\\boldL} \\quad \\boldL x \\\\\n",
    "\\text{\\boldM} \\quad \\boldM x \\\\\n",
    "\\text{\\boldN} \\quad \\boldN x \\\\\n",
    "\\text{\\boldI} \\quad \\boldI x \\\\\n",
    "\\text{\\boldP} \\quad \\boldP x \\\\\n",
    "\\text{\\boldQ} \\quad \\boldQ x \\\\\n",
    "\\text{\\boldR} \\quad \\boldR x \\\\\n",
    "\\text{\\boldS} \\quad \\boldS x \\\\\n",
    "\\text{\\boldT} \\quad \\boldT x \\\\\n",
    "\\text{\\boldO} \\quad \\boldO x \\\\\n",
    "\\text{\\boldU} \\quad \\boldU x \\\\\n",
    "\\text{\\boldV} \\quad \\boldV x \\\\\n",
    "\\text{\\boldW} \\quad \\boldW x \\\\\n",
    "\\text{\\boldX} \\quad \\boldX x \\\\\n",
    "\\text{\\boldY} \\quad \\boldY x \\\\\n",
    "\\text{\\boldZ} \\quad \\boldZ x \\\\\n",
    "\\text{\\boldXY} \\quad \\boldXY x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\boldalpha} \\quad \\boldalpha x \\\\\n",
    "\\text{\\boldbeta} \\quad \\boldbeta x \\\\\n",
    "\\text{\\boldtheta} \\quad \\boldtheta x \\\\\n",
    "\\text{\\boldmu} \\quad \\boldmu x \\\\\n",
    "\\text{\\boldxi} \\quad \\boldxi x \\\\\n",
    "\\text{\\boldeta} \\quad \\boldeta x \\\\\n",
    "\\text{\\boldpi} \\quad \\boldpi x \\\\\n",
    "\\text{\\boldsigma} \\quad \\boldsigma x \\\\\n",
    "\\text{\\boldphi} \\quad \\boldphi x \\\\\n",
    "\\text{\\boldpsi} \\quad \\boldpsi x \\\\\n",
    "\\text{\\boldlambda} \\quad \\boldlambda x \\\\\n",
    "\\text{\\boldgamma} \\quad \\boldgamma x \\\\\n",
    "\\text{\\bolddelta} \\quad \\bolddelta x \\\\\n",
    "\\text{\\boldeps} \\quad \\boldeps x \\\\\n",
    "\\text{\\boldPhi} \\quad \\boldPhi x \\\\\n",
    "\\text{\\boldPsi} \\quad \\boldPsi x \\\\\n",
    "\\text{\\boldLambda} \\quad \\boldLambda x \\\\\n",
    "\\text{\\boldSigma} \\quad \\boldSigma x \\\\\n",
    "\\text{\\boldTheta} \\quad \\boldTheta x \\\\\n",
    "\\text{\\boldOmega} \\quad \\boldOmega x \\\\\n",
    "\\\n",
    "\\text{\\hatboldx} \\quad \\hatboldx x \\\\\n",
    "\\text{\\hatboldk} \\quad \\hatboldk x \\\\\n",
    "\\text{\\hatboldw} \\quad \\hatboldw x \\\\\n",
    "\\text{\\hatboldp} \\quad \\hatboldp x \\\\\n",
    "\\text{\\hatboldK} \\quad \\hatboldK x \\\\\n",
    "\\text{\\hatboldC} \\quad \\hatboldC x \\\\\n",
    "\\text{\\hatboldS} \\quad \\hatboldS x \\\\\n",
    "\\text{\\hatboldU} \\quad \\hatboldU x \\\\\n",
    "\\text{\\hatboldV} \\quad \\hatboldV x \\\\\n",
    "\\text{\\hatboldX} \\quad \\hatboldX x \\\\\n",
    "\\text{\\hatboldSigma} \\quad \\hatboldSigma x \\\\\n",
    "\\text{\\hatboldLambda} \\quad \\hatboldLambda x \\\\\n",
    "\\text{\\hatboldy} \\quad \\hatboldy x \\\\\n",
    "\\text{\\hatboldmu} \\quad \\hatboldmu x \\\\\n",
    "\\text{\\hatboldalpha} \\quad \\hatboldalpha x \\\\\n",
    "\\text{\\hatboldbeta} \\quad \\hatboldbeta x \\\\\n",
    "\\text{\\hatboldgamma} \\quad \\hatboldgamma x \\\\\n",
    "\\text{\\hatboldtheta} \\quad \\hatboldtheta x \\\\\n",
    "\\text{\\hatboldeps} \\quad \\hatboldeps x \\\\\n",
    "\\text{\\hatbolddelta} \\quad \\hatbolddelta x \\\\\n",
    "\\\n",
    "\\text{\\tilboldbeta} \\quad \\tilboldbeta x \\\\\n",
    "\\text{\\tilboldw} \\quad \\tilboldw x \\\\\n",
    "\\text{\\tilboldmu} \\quad \\tilboldmu x \\\\\n",
    "\\\n",
    "\\text{\\xs} \\quad \\xs x \\\\\n",
    "\\text{\\ys} \\quad \\ys x \\\\\n",
    "\\text{\\zs} \\quad \\zs x \\\\\n",
    "\\text{\\Xs} \\quad \\Xs x \\\\\n",
    "\\text{\\Ys} \\quad \\Ys x \\\\\n",
    "\\text{\\Zs} \\quad \\Zs x \\\\\n",
    "\\\n",
    "\\text{\\Ndim} \\quad \\Ndim x \\\\\n",
    "\\text{\\Ddim} \\quad \\Ddim x \\\\\n",
    "\\text{\\Mdim} \\quad \\Mdim x \\\\\n",
    "\\text{\\Kdim} \\quad \\Kdim x \\\\\n",
    "\\text{\\Adim} \\quad \\Adim x \\\\\n",
    "\\text{\\Qdim} \\quad \\Qdim x \\\\\n",
    "\\text{\\Rdim} \\quad \\Rdim x \\\\\n",
    "\\\n",
    "\\text{\\mcalA} \\quad \\mcalA x \\\\\n",
    "\\text{\\mcalB} \\quad \\mcalB x \\\\\n",
    "\\text{\\mcalC} \\quad \\mcalC x \\\\\n",
    "\\text{\\mcalD} \\quad \\mcalD x \\\\\n",
    "\\text{\\mcalE} \\quad \\mcalE x \\\\\n",
    "\\text{\\mcalF} \\quad \\mcalF x \\\\\n",
    "\\text{\\mcalI} \\quad \\mcalI x \\\\\n",
    "\\text{\\mcalL} \\quad \\mcalL x \\\\\n",
    "\\text{\\mcalP} \\quad \\mcalP x \\\\\n",
    "\\text{\\mcalQ} \\quad \\mcalQ x \\\\\n",
    "\\text{\\mcalX} \\quad \\mcalX x \\\\\n",
    "\\text{\\hatmcalB} \\quad \\hatmcalB x \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{\\setA} \\quad \\setA x \\\\\n",
    "\\text{\\setB} \\quad \\setB x \\\\\n",
    "\\text{\\setC} \\quad \\setC x \\\\\n",
    "\\text{\\setE} \\quad \\setE x \\\\\n",
    "\\text{\\setD} \\quad \\setD x \\\\\n",
    "\\text{\\setS} \\quad \\setS x \\\\\n",
    "\\text{\\setT} \\quad \\setT x \\\\\n",
    "\\text{\\setV} \\quad \\setV x \\\\\n",
    "\\text{\\setW} \\quad \\setW x \\\\\n",
    "\\\n",
    "\\text{\\matA} \\quad \\matA x \\\\\n",
    "\\text{\\matB} \\quad \\matB x \\\\\n",
    "\\text{\\matC} \\quad \\matC x \\\\\n",
    "\\text{\\matD} \\quad \\matD x \\\\\n",
    "\\text{\\matE} \\quad \\matE x \\\\\n",
    "\\text{\\matI} \\quad \\matI x \\\\\n",
    "\\text{\\matU} \\quad \\matU x \\\\\n",
    "\\text{\\matV} \\quad \\matV x \\\\\n",
    "\\text{\\matW} \\quad \\matW x \\\\\n",
    "\\text{\\matPhi} \\quad \\matPhi x \\\\\n",
    "\\text{\\matPsi} \\quad \\matPsi x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\Factors} \\quad \\Factors x \\\\\n",
    "\\text{\\Variables} \\quad \\Variables x \\\\\n",
    "\\text{\\Eye} \\quad \\Eye x \\\\\n",
    "\\text{\\Zero} \\quad \\Zero x \\\\\n",
    "\\text{\\Energy} \\quad \\Energy x \\\\\n",
    "\\text{\\Entropy} \\quad \\Entropy x \\\\\n",
    "\\text{\\Fenergy} \\quad \\Fenergy x \\\\\n",
    "\\text{\\Edges} \\quad \\Edges x \\\\\n",
    "\\text{\\edge} \\quad \\edge x \\\\\n",
    "\\text{\\Vertices} \\quad \\Vertices x \\\\\n",
    "\\text{\\vertex} \\quad \\vertex x \\\\\n",
    "\\text{\\Graph} \\quad \\Graph x \\\\\n",
    "\\text{\\Tree} \\quad \\Tree x \\\\\n",
    "\\text{\\Children} \\quad \\Children x \\\\\n",
    "\\text{\\Parents} \\quad \\Parents x \\\\\n",
    "\\text{\\Adjacent} \\quad \\Adjacent x \\\\\n",
    "\\text{\\Pa} \\quad \\Pa x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\state} \\quad \\state x \\\\\n",
    "\\text{\\State} \\quad \\State x \\\\\n",
    "\\text{\\StateR} \\quad \\StateR x \\\\\n",
    "\\\n",
    "\\text{\\Covariance} \\quad \\Covariance x \\\\\n",
    "\\text{\\CovX} \\quad \\CovX x \\\\\n",
    "\\text{\\CovY} \\quad \\CovY x \\\\\n",
    "\\text{\\CovZ} \\quad \\CovZ x \\\\\n",
    "\\text{\\CovXY} \\quad \\CovXY x \\\\\n",
    "\\\n",
    "\\text{\\hatCovariance} \\quad \\hatCovariance x \\\\\n",
    "\\text{\\hatCovX} \\quad \\hatCovX x \\\\\n",
    "\\text{\\hatCovY} \\quad \\hatCovY x \\\\\n",
    "\\text{\\hatCovZ} \\quad \\hatCovZ x \\\\\n",
    "\\text{\\hatCovXY} \\quad \\hatCovXY x \\\\\n",
    "\\\n",
    "\\text{\\tildeCovariance} \\quad \\tildeCovariance x \\\\\n",
    "\\text{\\tildeCovX} \\quad \\tildeCovX x \\\\\n",
    "\\text{\\tildeCovY} \\quad \\tildeCovY x \\\\\n",
    "\\text{\\tildeCovZ} \\quad \\tildeCovZ x \\\\\n",
    "\\text{\\tildeCovXY} \\quad \\tildeCovXY x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\hatState} \\quad \\hatState x \\\\\n",
    "\\text{\\StateNum} \\quad \\StateNum x \\\\\n",
    "\\text{\\StateDim} \\quad \\StateDim x \\\\\n",
    "\\text{\\StateSet} \\quad \\StateSet x \\\\\n",
    "\\text{\\StatesSet} \\quad \\StatesSet x \\\\\n",
    "\\text{\\NumStates} \\quad \\NumStates x \\\\\n",
    "\\text{\\StateToState} \\quad \\StateToState x \\\\\n",
    "\\text{\\StateCov} \\quad \\StateCov x \\\\\n",
    "\\text{\\StateJac} \\quad \\StateJac x \\\\\n",
    "\\\n",
    "\\text{\\hatStateCov} \\quad \\hatStateCov x \\\\\n",
    "\\text{\\StateMean} \\quad \\StateMean x \\\\\n",
    "\\text{\\hatStateMean} \\quad \\hatStateMean x \\\\\n",
    "\\text{\\StateToStateHistory} \\quad \\StateToStateHistory x \\\\\n",
    "\\text{\\StateNoise} \\quad \\StateNoise x \\\\\n",
    "\\text{\\StateNoiseCov} \\quad \\StateNoiseCov x \\\\\n",
    "\\text{\\StateHistory} \\quad \\StateHistory x \\\\\n",
    "\\text{\\StatesHistory} \\quad \\StatesHistory x \\\\\n",
    "\\text{\\StateToObserv} \\quad \\StateToObserv x \\\\\n",
    "\\text{\\StateToobserv} \\quad \\StateToobserv x \\\\\n",
    "\\text{\\StateToObservHistory} \\quad \\StateToObservHistory x \\\\\n",
    "\\\n",
    "\\text{\\DState} \\quad \\DState x \\\\\n",
    "\\text{\\hatDState} \\quad \\hatDState x \\\\\n",
    "\\text{\\DStateMean} \\quad \\DStateMean x \\\\\n",
    "\\text{\\hatDStateMean} \\quad \\hatDStateMean x \\\\\n",
    "\\text{\\DStateCov} \\quad \\DStateCov x \\\\\n",
    "\\text{\\hatDStateCov} \\quad \\hatDStateCov x \\\\\n",
    "\\\n",
    "\\text{\\DObserv} \\quad \\DObserv x \\\\\n",
    "\\text{\\hatDObserv} \\quad \\hatDObserv x \\\\\n",
    "\\\n",
    "\\text{\\observ} \\quad \\observ x \\\\\n",
    "\\text{\\Observ} \\quad \\Observ x \\\\\n",
    "\\text{\\ObservCov} \\quad \\ObservCov x \\\\\n",
    "\\text{\\observMean} \\quad \\observMean x \\\\\n",
    "\\text{\\ObservMean} \\quad \\ObservMean x \\\\\n",
    "\\text{\\hatobserv} \\quad \\hatobserv x \\\\\n",
    "\\text{\\hatObserv} \\quad \\hatObserv x \\\\\n",
    "\\text{\\hatObservCov} \\quad \\hatObservCov x \\\\\n",
    "\\text{\\hatobservMean} \\quad \\hatobservMean x \\\\\n",
    "\\text{\\hatObservMean} \\quad \\hatObservMean x \\\\\n",
    "\\\n",
    "\\text{\\ObservSet} \\quad \\ObservSet x \\\\\n",
    "\\text{\\ObservNum} \\quad \\ObservNum x \\\\\n",
    "\\text{\\ObservDim} \\quad \\ObservDim x \\\\\n",
    "\\text{\\ObservSourceNum} \\quad \\ObservSourceNum x \\\\\n",
    "\\text{\\ObservHistory} \\quad \\ObservHistory x \\\\\n",
    "\\text{\\ObservsHistory} \\quad \\ObservsHistory x \\\\\n",
    "\\text{\\Timestamps} \\quad \\Timestamps x \\\\\n",
    "\\text{\\ObservJac} \\quad \\ObservJac x \\\\\n",
    "% Шум наблюдений\n",
    "\\text{\\observNoise} \\quad \\observNoise x \\\\\n",
    "\\text{\\ObservNoise} \\quad \\ObservNoise x \\\\\n",
    "\\text{\\ObservNoiseCov} \\quad \\ObservNoiseCov x \\\\\n",
    "\\text{\\ObservNoiseCovHistory} \\quad \\ObservNoiseCovHistory x \\\\\n",
    "\\\n",
    "\\\n",
    "\\text{\\control} \\quad \\control x \\\\\n",
    "\\text{\\Control} \\quad \\Control x \\\\\n",
    "\\text{\\ControlNum} \\quad \\ControlNum x \\\\\n",
    "\\text{\\ControToState} \\quad \\ControToState x \\\\\n",
    "\\text{\\ControlToStateHistory} \\quad \\ControlToStateHistory x \\\\\n",
    "\\text{\\ControlHistory} \\quad \\ControlHistory x \\\\\n",
    "\\\n",
    "\\text{\\Jacobian} \\quad \\Jacobian x \\\\\n",
    "\\\n",
    "\\text{\\Kalman} \\quad \\Kalman x \\\\\n",
    "\\text{\\kalman} \\quad \\kalman x \\\\\n",
    "\\\n",
    "\\text{\\vel} \\quad \\vel x \\\\\n",
    "$\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4fa596",
   "metadata": {},
   "source": [
    "## Python syntax <span id=Python_syntax_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db05651",
   "metadata": {},
   "source": [
    "### Fstrings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd858197",
   "metadata": {},
   "source": [
    "f\"{expression.format_spec}\"\n",
    "\n",
    "```\n",
    "format_spec     ::=  [[fill]align][sign][z][#][0][width][grouping_option][.precision][type]\n",
    "fill            ::=  <any character>\n",
    "align           ::=  \"<\" | \">\" | \"=\" | \"^\"\n",
    "sign            ::=  \"+\" | \"-\" | \" \"\n",
    "width           ::=  digit+\n",
    "grouping_option ::=  \"_\" | \",\"\n",
    "precision       ::=  digit+\n",
    "type            ::=  \"b\" | \"c\" | \"d\" | \"e\" | \"E\" | \"f\" | \"F\" | \"g\" | \"G\" | \"n\" | \"o\" | \"s\" | \"x\" | \"X\" | \"%\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ad468b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*3=6\n",
      "__repr__(s) = '123'\n",
      "braces {74}\n",
      "2023-03-20 19:04\n",
      "33.3333\n",
      "0.33333\n",
      "3.333333e-01\n",
      "007\n",
      "  7\n",
      "111\n",
      "000003e8\n",
      "   123\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "s = \"123\"\n",
    "width = 2\n",
    "precision = 6\n",
    "\n",
    "print(\n",
    "    f\"{2*3=}\",\n",
    "    f\"__repr__({s=}\".split(\"=\")[0] + f\") = {s!r}\",\n",
    "    f\"braces {{{70 + 4}}}\",\n",
    "    f\"{now:%Y-%m-%d %H:%M}\",\n",
    "    f\"{100/3:{width}.{precision}}\",\n",
    "    f\"{1 / 3:.5f}\",\n",
    "    f\"{1/3:e}\",\n",
    "    f\"{7:03}\",\n",
    "    f\"{7:3}\",\n",
    "    f\"{7:b}\",\n",
    "    f\"{1000:08x}\",\n",
    "    f\"{s:>6}\",\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025a250",
   "metadata": {},
   "source": [
    "### Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "51a029a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:00:53.210137Z",
     "start_time": "2023-06-04T09:00:53.187529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 94;\n",
       "                var nbb_unformatted_code = \"class Point:\\n    x: int\\n    y: int\\n\\n\\ndef match_point(point):\\n    match point:\\n        case Point(x=0, y=0):\\n            ...\\n        case Point(x=0, y=y):\\n            ...\\n        case Point(x=x, y=0):\\n            ...\\n        case Point(x, y) if x == y:\\n            ...\\n        case Point():\\n            ...\\n        case [Point(0, 0)]:\\n            ...\\n        case [Point(x, y)]:\\n            ...\\n        case [Point(0, y1), Point(0, y2)]:\\n            ...\\n        case (Point(x1, y1), Point(x2, y2) as p2):\\n            ...\\n        case _:\\n            ...\";\n",
       "                var nbb_formatted_code = \"class Point:\\n    x: int\\n    y: int\\n\\n\\ndef match_point(point):\\n    match point:\\n        case Point(x=0, y=0):\\n            ...\\n        case Point(x=0, y=y):\\n            ...\\n        case Point(x=x, y=0):\\n            ...\\n        case Point(x, y) if x == y:\\n            ...\\n        case Point():\\n            ...\\n        case [Point(0, 0)]:\\n            ...\\n        case [Point(x, y)]:\\n            ...\\n        case [Point(0, y1), Point(0, y2)]:\\n            ...\\n        case (Point(x1, y1), Point(x2, y2) as p2):\\n            ...\\n        case _:\\n            ...\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Point:\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "\n",
    "def match_point(point):\n",
    "    match point:\n",
    "        case Point(x=0, y=0):\n",
    "            ...\n",
    "        case Point(x=0, y=y):\n",
    "            ...\n",
    "        case Point(x=x, y=0):\n",
    "            ...\n",
    "        case Point(x, y) if x == y:\n",
    "            ...\n",
    "        case Point():\n",
    "            ...\n",
    "        case [Point(0, 0)]:\n",
    "            ...\n",
    "        case [Point(x, y)]:\n",
    "            ...\n",
    "        case [Point(0, y1), Point(0, y2)]:\n",
    "            ...\n",
    "        case (Point(x1, y1), Point(x2, y2) as p2):\n",
    "            ...\n",
    "        case _:\n",
    "            ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c680a",
   "metadata": {},
   "source": [
    "### Context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3e5aadd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 103;\n",
       "                var nbb_unformatted_code = \"class ContextManager:\\n    def __enter__(self):\\n        ...\\n\\n    def __exit__(self, exc_type, exc_value, exc_tb):\\n        ...\\n        \\nwith (ContextManager() as cm1, ContextManager() as cm2,):\\n    pass\";\n",
       "                var nbb_formatted_code = \"class ContextManager:\\n    def __enter__(self):\\n        ...\\n\\n    def __exit__(self, exc_type, exc_value, exc_tb):\\n        ...\\n\\n\\nwith (\\n    ContextManager() as cm1,\\n    ContextManager() as cm2,\\n):\\n    pass\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ContextManager:\n",
    "    def __enter__(self):\n",
    "        ...\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
    "        ...\n",
    "\n",
    "\n",
    "with (\n",
    "    ContextManager() as cm1,\n",
    "    ContextManager() as cm2,\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d73044",
   "metadata": {},
   "source": [
    "### Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "96e10385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 108;\n",
       "                var nbb_unformatted_code = \"class Iterator:\\n    def __next__(self):\\n        raise StopIteration\\n\\n\\nclass Iterable:\\n    def __iter__(self):\\n        return Iterator()\\n\\n\\nfor _ in Iterable():\\n    ...\";\n",
       "                var nbb_formatted_code = \"class Iterator:\\n    def __next__(self):\\n        raise StopIteration\\n\\n\\nclass Iterable:\\n    def __iter__(self):\\n        return Iterator()\\n\\n\\nfor _ in Iterable():\\n    ...\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Iterator:\n",
    "    def __next__(self):\n",
    "        raise StopIteration\n",
    "\n",
    "\n",
    "class Iterable:\n",
    "    def __iter__(self):\n",
    "        return Iterator()\n",
    "\n",
    "\n",
    "for _ in Iterable():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b76c0f0",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f01dd07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 3, 5]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generator():\n",
    "    x = yield ...\n",
    "    yield x + 1\n",
    "    yield \"end\"\n",
    "    return 0\n",
    "\n",
    "\n",
    "def delegating_generator():\n",
    "    yield from generator()\n",
    "\n",
    "\n",
    "g = delegating_generator()\n",
    "next(g)\n",
    "g.send(3)\n",
    "for i in g:\n",
    "    print(i)\n",
    "\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def async_generator(delay, to):\n",
    "    \"\"\"Yield numbers from 0 to *to* every *delay* seconds.\"\"\"\n",
    "    for i in range(to):\n",
    "        yield i\n",
    "        await asyncio.sleep(delay)\n",
    "\n",
    "\n",
    "[i async for i in async_generator(0.1, 7) if i % 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c2541",
   "metadata": {},
   "source": [
    "### Except*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83308ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caught <class 'ExceptionGroup'> with nested (TypeError(2),)\n",
      "caught <class 'ExceptionGroup'> with nested (OSError(3), OSError(4))\n",
      "caught <class 'ExceptionGroup'> with nested (ValueError(1),)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    raise ExceptionGroup(\"eg\", [ValueError(1), TypeError(2), OSError(3), OSError(4)])\n",
    "except* TypeError as e:\n",
    "    print(f\"caught {type(e)} with nested {e.exceptions}\")\n",
    "except* OSError as e:\n",
    "    print(f\"caught {type(e)} with nested {e.exceptions}\")\n",
    "except* ValueError as e:\n",
    "    print(f\"caught {type(e)} with nested {e.exceptions}\")\n",
    "else:\n",
    "    print(\"No exception\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d43fe",
   "metadata": {},
   "source": [
    "### Type hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b5ac828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"def square(number: int | float) -> int | float:\\n    return number **    2\\n\\nisinstance(1, int | str)\\n\\nimport typing\\n\\nclass MyLock:\\n    def __enter__(self) -> typing.Self:\\n        self.lock()\\n        return self\";\n",
       "                var nbb_formatted_code = \"def square(number: int | float) -> int | float:\\n    return number**2\\n\\n\\nisinstance(1, int | str)\\n\\nimport typing\\n\\n\\nclass MyLock:\\n    def __enter__(self) -> typing.Self:\\n        self.lock()\\n        return self\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def square(number: int | float) -> int | float:\n",
    "    return number**2\n",
    "\n",
    "\n",
    "isinstance(1, int | str)\n",
    "\n",
    "import typing\n",
    "\n",
    "\n",
    "class MyLock:\n",
    "    def __enter__(self) -> typing.Self:\n",
    "        self.lock()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2df042",
   "metadata": {},
   "source": [
    "### Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10925dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      ":=\n"
     ]
    }
   ],
   "source": [
    "print((15).bit_count())\n",
    "zip([1, 2], [3, 4, 5], strict=True)\n",
    "print(walrus := \":=\")\n",
    "breakpoint()\n",
    "\n",
    "\n",
    "def f(a, b, /, c, d, *, e, f):\n",
    "    ...\n",
    "\n",
    "\n",
    "def divmod(a, b, /):\n",
    "    \"Emulate the built in divmod() function -- no keyword arguments.\"\n",
    "    return (a // b, a % b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e085fa59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T10:11:21.916460Z",
     "start_time": "2023-06-01T10:11:21.911154Z"
    }
   },
   "source": [
    "### Styleguide <span id=Styleguide_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6ae4e",
   "metadata": {},
   "source": [
    "https://google.github.io/styleguide/pyguide.html\n",
    "\n",
    "Goes hand in hand with [black](https://black.readthedocs.io/en/stable/), [pylint](https://pylint.readthedocs.io/en/latest/user_guide/usage/index.html), [pyreverse](https://pylint.readthedocs.io/en/latest/pyreverse.html), [pydocstringformatter](https://github.com/DanielNoord/pydocstringformatter), [pytype](https://github.com/google/pytype) and [pydoc](https://docs.python.org/3/library/pydoc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fca71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!black ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f4653",
   "metadata": {},
   "source": [
    "## Jupyter extensions, magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc64cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c21ab",
   "metadata": {},
   "source": [
    "### Enabling extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d583ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jupyter_contrib_nbextensions\n",
    "!python -m jupyter contrib nbextension install --sys-prefix\n",
    "!python -m jupyter nbextension enable execute_time/ExecuteTime --sys-prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a6d6f1",
   "metadata": {},
   "source": [
    "### Configuring extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2f2550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T09:12:28.938465Z",
     "start_time": "2023-06-05T09:12:28.907440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ExecuteTime': {'display_absolute_timestamps': False,\n",
      "                 'highlight': {'use': False},\n",
      "                 'relative_timing_update_period': 5,\n",
      "                 'template': {'executed': '${duration}', 'queued': 'queued'}}}\n"
     ]
    }
   ],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(\n",
    "    ConfigManager().update(\n",
    "        \"notebook\",\n",
    "        {\n",
    "            \"ExecuteTime\": {\n",
    "                \"display_absolute_timestamps\": False,\n",
    "                \"relative_timing_update_period\": 5,\n",
    "                \"highlight\": {\"use\": False},\n",
    "                \"template\": {\"executed\": \"${duration}\", \"queued\": \"queued\"},\n",
    "            }\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f7a05",
   "metadata": {},
   "source": [
    "## Cli <span id=Cli_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb469d6",
   "metadata": {},
   "source": [
    "### Poetry\n",
    "    poetry build\n",
    "    poetry add\n",
    "    poetry publish\n",
    "\n",
    "\n",
    "### Pip\n",
    "    pip freeze > requirements.txt\n",
    "    pip install -r requirements.txt\n",
    "\n",
    "### Tmux\n",
    "    tmux a      #attach to session\n",
    "    Ctrl-a c    #new window\n",
    "    Ctrl-a x    #close window\n",
    "    Ctrl-a -    #split window horizontaly\n",
    "    Ctrl-a |    #split window verticaly\n",
    "    \n",
    "### nvtop, top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ad7e9b",
   "metadata": {},
   "source": [
    "## Utils <span id=Utils_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36268341",
   "metadata": {},
   "source": [
    "### Markdown <span id=Markdown_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75069401",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T10:32:35.280632Z",
     "start_time": "2023-06-05T10:32:35.239862Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_new_markdown_section_with_link(section: str, header_size: int = 2):\n",
    "    header = \"#\" * header_size\n",
    "    section_id = section.replace(\" \", \"_\") + \"_\"\n",
    "    section_link = f\"{header} [{section}](#{section_id})\"\n",
    "    section_header = f\"{header} {section} <span id={section_id}></span>\"\n",
    "    return section_link, section_header\n",
    "\n",
    "\n",
    "import pyperclip\n",
    "\n",
    "\n",
    "def new_section_to_clipboard(section: str, header_size: int = 2):\n",
    "    pyperclip.copy(\"\\n\".join(make_new_markdown_section_with_link(section, header_size)))\n",
    "\n",
    "\n",
    "def make_several_sections(\n",
    "    section_names=(\n",
    "        \"Description\",\n",
    "        \"Research\",\n",
    "        \"Imports\",\n",
    "        \"Globals\",\n",
    "        \"Utils\",\n",
    "        \"Setup\",\n",
    "        \"Data\",\n",
    "        \"Data exploration\",\n",
    "        \"Metrics\",\n",
    "        \"Model\",\n",
    "        \"Training\",\n",
    "        \"Results\",\n",
    "    ),\n",
    "    header_size: int = 2,\n",
    "):\n",
    "    links, headers = zip(\n",
    "        *[make_new_markdown_section_with_link(sn, header_size) for sn in section_names]\n",
    "    )\n",
    "    print(\"\\n\".join(links + (\"\",) + headers))\n",
    "\n",
    "\n",
    "def build_python_libraries_requirements() -> str:\n",
    "    python_version = sys.version\n",
    "    requirements = !pip freeze\n",
    "    requirements = \"\\n\".join(requirements)\n",
    "    requirements = (\n",
    "        f\"<details>\\n\"\n",
    "        f\"\\t<summary> Python requirements </summary>\\n\\n\"\n",
    "        f\"```\\n\"\n",
    "        f\"{python_version}\\n\\n\"\n",
    "        f\"{requirements}\\n\"\n",
    "        f\"```\\n\"\n",
    "        f\"</details>\"\n",
    "    )\n",
    "    return requirements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b177ec",
   "metadata": {},
   "source": [
    "### Terminal <span id=Terminal_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(path, error_if_exists=False):\n",
    "    !mkdir {\"-p\" if not error_if_exists else \"\"} {path}\n",
    "\n",
    "\n",
    "def unzip(zip_path, save_path=None, delete_zip=False):\n",
    "    !unzip {zip_path} {\"-d \"+ save_path if save_path else \"\"}\n",
    "    if delete_zip:\n",
    "        for path in glob.glob(zip_path):\n",
    "            if path.endswith(\".zip\"):\n",
    "                !trash {path}\n",
    "\n",
    "\n",
    "def unzip_to_data_and_delete():\n",
    "    unzip(\"data/*\", \"data\", delete_zip=True)\n",
    "\n",
    "\n",
    "def wget_download_to_filepath(url: str, directory: str = \"\", filename: str = \"\") -> str:\n",
    "    filename = filename or os.path.basename(url)\n",
    "    filename = os.path.join(directory, filename)\n",
    "    !wget -O {filename} {url}\n",
    "    return filename\n",
    "\n",
    "\n",
    "def unzip_all(zip_filepath: str) -> list[str]:\n",
    "    zip_file = zipfile.ZipFile(zip_filepath)\n",
    "    zip_file.extractall()\n",
    "    return zip_file.namelist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc343e9f",
   "metadata": {},
   "source": [
    "### Kaggle <span id=Kaggle_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7137a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def kaggle_competitions_search(search_term):\\n    !kaggle competitions list -s {search_term}\\n\\n\\ndef kaggle_competitions_files(competition):\\n    !kaggle competitions files {competition}\\n\\n\\ndef kaggle_competitions_download(competition, save_path=\\\"data\\\", filename=None):\\n    mkdir(save_path)\\n    !kaggle competitions download -p {save_path} {\\\"-f \\\" + filename if filename else \\\"\\\"} {competition}\\n\\n\\ndef kaggle_competitions_submit(competition, filename, message=\\\"submit\\\"):\\n    !kaggle competitions submit -f {filename} -m {message} {competition}\\n\\n\\ndef kaggle_competitions_submissions(competition):\\n    !kaggle competitions submissions {competition}\";\n",
       "                var nbb_formatted_code = \"def kaggle_competitions_search(search_term):\\n    !kaggle competitions list -s {search_term}\\n\\n\\ndef kaggle_competitions_files(competition):\\n    !kaggle competitions files {competition}\\n\\n\\ndef kaggle_competitions_download(competition, save_path=\\\"data\\\", filename=None):\\n    mkdir(save_path)\\n    !kaggle competitions download -p {save_path} {\\\"-f \\\" + filename if filename else \\\"\\\"} {competition}\\n\\n\\ndef kaggle_competitions_submit(competition, filename, message=\\\"submit\\\"):\\n    !kaggle competitions submit -f {filename} -m {message} {competition}\\n\\n\\ndef kaggle_competitions_submissions(competition):\\n    !kaggle competitions submissions {competition}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def kaggle_competitions_search(search_term):\n",
    "    !kaggle competitions list -s {search_term}\n",
    "\n",
    "\n",
    "def kaggle_competitions_files(competition):\n",
    "    !kaggle competitions files {competition}\n",
    "\n",
    "\n",
    "def kaggle_competitions_download(competition, save_path=\"data\", filename=None):\n",
    "    mkdir(save_path)\n",
    "    !kaggle competitions download -p {save_path} {\"-f \" + filename if filename else \"\"} {competition}\n",
    "\n",
    "    \n",
    "def kaggle_competitions_download_file(competition:str, filename:str, save_path:str):\n",
    "    relative_filename = os.path.join(save_path, filename)\n",
    "    save_path = os.path.join(save_path, os.path.split(filename)[0])\n",
    "    if os.path.exists(relative_filename):\n",
    "        print(f\"File `{relative_filename}` already exists.\")\n",
    "    else:\n",
    "        !kaggle competitions download {competition} -f {filename} -p {save_path}\n",
    "        zip_relative_filename = relative_filename + \".zip\"\n",
    "        if os.path.exists(zip_relative_filename):\n",
    "            unzip(zip_relative_filename, save_path=save_path, delete_zip=True)\n",
    "            \n",
    "            \n",
    "def kaggle_competitions_submit(competition, filename, message=\"submit\"):\n",
    "    !kaggle competitions submit -f {filename} -m {message} {competition}\n",
    "\n",
    "\n",
    "def kaggle_competitions_submissions(competition):\n",
    "    !kaggle competitions submissions {competition}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850ce15",
   "metadata": {},
   "source": [
    "### Environment variables <span id=Environment_variables_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d63a3e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:15:32.596309Z",
     "start_time": "2023-05-09T06:15:32.366728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"def set_tokenizers_parallelism(enable: bool):\\n    os.environ[\\\"TOKENIZERS_PARALLELISM\\\"] = \\\"true\\\" if enable else \\\"false\\\"\\n\\n\\ndef set_torch_device_order_pci_bus():\\n    os.environ[\\\"CUDA_DEVICE_ORDER\\\"] = \\\"PCI_BUS_ID\\\"\\n\\n\\nimport numba\\n\\ndef set_numba_threads(n_threads: int):\\n    numba.config.NUMBA_NUM_THREADS = num_threads\\n    numba.config.THREADING_LAYER = \\\"threadsafe\\\"\\n    numba.set_num_threads(num_threads)\";\n",
       "                var nbb_formatted_code = \"def set_tokenizers_parallelism(enable: bool):\\n    os.environ[\\\"TOKENIZERS_PARALLELISM\\\"] = \\\"true\\\" if enable else \\\"false\\\"\\n\\n\\ndef set_torch_device_order_pci_bus():\\n    os.environ[\\\"CUDA_DEVICE_ORDER\\\"] = \\\"PCI_BUS_ID\\\"\\n\\n\\nimport numba\\n\\n\\ndef set_numba_threads(n_threads: int):\\n    numba.config.NUMBA_NUM_THREADS = num_threads\\n    numba.config.THREADING_LAYER = \\\"threadsafe\\\"\\n    numba.set_num_threads(num_threads)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_tokenizers_parallelism(enable: bool):\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\" if enable else \"false\"\n",
    "\n",
    "\n",
    "def set_torch_device_order_pci_bus():\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "\n",
    "import numba\n",
    "\n",
    "\n",
    "def set_numba_threads(n_threads: int):\n",
    "    numba.config.NUMBA_NUM_THREADS = num_threads\n",
    "    numba.config.THREADING_LAYER = \"threadsafe\"\n",
    "    numba.set_num_threads(num_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345de25f",
   "metadata": {},
   "source": [
    "### Gpu server <span id=Gpu_server_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf793ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:12:07.172733Z",
     "start_time": "2023-05-09T06:12:06.761202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"import os\\nimport pandas as pd\\n\\n\\ndef get_shad_server_username_to_telegram_table_path():\\n    home = os.environ[\\\"HOME\\\"]\\n    return f\\\"{home}/shad_server_username_to_telegram.csv\\\"\\n\\ndef read_shad_server_username_to_telegram_series() -> pd.Series:\\n    df = pd.read_csv(get_shad_server_username_to_telegram_table_path())\\n    series = df.set_index(\\\"server_username\\\")[\\\"telegram_username\\\"]\\n    return series\\n\\ndef update_shad_server_username_to_telegram_series():\\n    s = read_shad_server_username_to_telegram_series()\\n    \\n    s[\\\"sapetrov\\\"] = \\\"@PetrovSt\\\"\\n    s[\\\"okgorbunova\\\"] = \\\"@elyaishere\\\"\\n    s[\\\"jagiljazev\\\"] = \\\"@yulian_g\\\"\\n    s[\\\"aaponomarev\\\"] = \\\"@Lexolordan\\\"\\n    s[\\\"lmmurashov\\\"] = \\\"@leoneat\\\"\\n    s[\\\"bvshelhonov\\\"] = \\\"@Boolean17\\\"\\n    s[\\\"vierinova\\\"] = \\\"@vladlena_ermak\\\"\\n    s[\\\"mdprokudin\\\"] = \\\"@mdprokudin\\\"\\n    s[\\\"dkkoshman\\\"] = \\\"@DimaKoshman\\\"\\n    \\n    s.to_csv(get_shad_server_username_to_telegram_table_path())\\n    \\n\\ndef get_nvidia_smi_pid_column():\\n    nvidia_smi_pid_column = !nvidia-smi | awk '{print $5}'\\n    return nvidia_smi_pid_column\\n\\ndef get_pid_username(pid:int)->str:\\n    username = !ps -o uname= -p {pid}\\n    return username[0]\\n\\ndef get_server_usernames_using_gpu() ->list[str]:\\n    nvidia_smi_pid_column = get_nvidia_smi_pid_column()\\n    pids_using_gpu = []\\n    for row in nvidia_smi_pid_column[::-1]:\\n        if row == \\\"PID\\\":\\n            break\\n        try:\\n            pid = int(row)\\n        except ValueError:\\n            continue\\n        pids_using_gpu.append(int(pid))\\n        \\n    usernames_using_gpu = [get_pid_username(pid) for pid in pids_using_gpu]\\n    usernames_using_gpu = list(set(usernames_using_gpu))\\n    return usernames_using_gpu\\n\\n\\ndef print_telegram_usernames_using_gpu():\\n    server_to_telegram = read_shad_server_username_to_telegram_series()\\n    usernames_using_gpu = get_server_usernames_using_gpu()\\n    \\n    telegram_usernames_using_gpu = []\\n    server_usernames_with_unknown_telegram_id = []\\n    for username in usernames_using_gpu:\\n        if username in server_to_telegram.index:\\n            telegram_usernames_using_gpu.append(server_to_telegram[username])\\n        else:\\n            server_usernames_with_unknown_telegram_id.append(username)\\n    \\n    print(\\\"Telegram ids of users using gpu:\\\")\\n    print(\\\"\\\\n\\\".join(telegram_usernames_using_gpu))\\n    \\n    if server_usernames_with_unknown_telegram_id:\\n        print(\\\"Telegram id is unknown for users:\\\")\\n        print(\\\"\\\\n\\\".join(server_usernames_with_unknown_telegram_id))\\n        \";\n",
       "                var nbb_formatted_code = \"import os\\nimport pandas as pd\\n\\n\\ndef get_shad_server_username_to_telegram_table_path():\\n    home = os.environ[\\\"HOME\\\"]\\n    return f\\\"{home}/shad_server_username_to_telegram.csv\\\"\\n\\n\\ndef read_shad_server_username_to_telegram_series() -> pd.Series:\\n    df = pd.read_csv(get_shad_server_username_to_telegram_table_path())\\n    series = df.set_index(\\\"server_username\\\")[\\\"telegram_username\\\"]\\n    return series\\n\\n\\ndef update_shad_server_username_to_telegram_series():\\n    s = read_shad_server_username_to_telegram_series()\\n\\n    s[\\\"sapetrov\\\"] = \\\"@PetrovSt\\\"\\n    s[\\\"okgorbunova\\\"] = \\\"@elyaishere\\\"\\n    s[\\\"jagiljazev\\\"] = \\\"@yulian_g\\\"\\n    s[\\\"aaponomarev\\\"] = \\\"@Lexolordan\\\"\\n    s[\\\"lmmurashov\\\"] = \\\"@leoneat\\\"\\n    s[\\\"bvshelhonov\\\"] = \\\"@Boolean17\\\"\\n    s[\\\"vierinova\\\"] = \\\"@vladlena_ermak\\\"\\n    s[\\\"mdprokudin\\\"] = \\\"@mdprokudin\\\"\\n    s[\\\"dkkoshman\\\"] = \\\"@DimaKoshman\\\"\\n\\n    s.to_csv(get_shad_server_username_to_telegram_table_path())\\n\\n\\ndef get_nvidia_smi_pid_column():\\n    nvidia_smi_pid_column = !nvidia-smi | awk '{print $5}'\\n    return nvidia_smi_pid_column\\n\\n\\ndef get_pid_username(pid: int) -> str:\\n    username = !ps -o uname= -p {pid}\\n    return username[0]\\n\\n\\ndef get_server_usernames_using_gpu() -> list[str]:\\n    nvidia_smi_pid_column = get_nvidia_smi_pid_column()\\n    pids_using_gpu = []\\n    for row in nvidia_smi_pid_column[::-1]:\\n        if row == \\\"PID\\\":\\n            break\\n        try:\\n            pid = int(row)\\n        except ValueError:\\n            continue\\n        pids_using_gpu.append(int(pid))\\n\\n    usernames_using_gpu = [get_pid_username(pid) for pid in pids_using_gpu]\\n    usernames_using_gpu = list(set(usernames_using_gpu))\\n    return usernames_using_gpu\\n\\n\\ndef print_telegram_usernames_using_gpu():\\n    server_to_telegram = read_shad_server_username_to_telegram_series()\\n    usernames_using_gpu = get_server_usernames_using_gpu()\\n\\n    telegram_usernames_using_gpu = []\\n    server_usernames_with_unknown_telegram_id = []\\n    for username in usernames_using_gpu:\\n        if username in server_to_telegram.index:\\n            telegram_usernames_using_gpu.append(server_to_telegram[username])\\n        else:\\n            server_usernames_with_unknown_telegram_id.append(username)\\n\\n    print(\\\"Telegram ids of users using gpu:\\\")\\n    print(\\\"\\\\n\\\".join(telegram_usernames_using_gpu))\\n\\n    if server_usernames_with_unknown_telegram_id:\\n        print(\\\"Telegram id is unknown for users:\\\")\\n        print(\\\"\\\\n\\\".join(server_usernames_with_unknown_telegram_id))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_shad_server_username_to_telegram_table_path():\n",
    "    home = os.environ[\"HOME\"]\n",
    "    return f\"{home}/shad_server_username_to_telegram.csv\"\n",
    "\n",
    "\n",
    "def read_shad_server_username_to_telegram_series() -> pd.Series:\n",
    "    df = pd.read_csv(get_shad_server_username_to_telegram_table_path())\n",
    "    series = df.set_index(\"server_username\")[\"telegram_username\"]\n",
    "    return series\n",
    "\n",
    "\n",
    "def update_shad_server_username_to_telegram_series():\n",
    "    s = read_shad_server_username_to_telegram_series()\n",
    "\n",
    "    s[\"sapetrov\"] = \"@PetrovSt\"\n",
    "    s[\"okgorbunova\"] = \"@elyaishere\"\n",
    "    s[\"jagiljazev\"] = \"@yulian_g\"\n",
    "    s[\"aaponomarev\"] = \"@Lexolordan\"\n",
    "    s[\"lmmurashov\"] = \"@leoneat\"\n",
    "    s[\"bvshelhonov\"] = \"@Boolean17\"\n",
    "    s[\"vierinova\"] = \"@vladlena_ermak\"\n",
    "    s[\"mdprokudin\"] = \"@mdprokudin\"\n",
    "    s[\"dkkoshman\"] = \"@DimaKoshman\"\n",
    "\n",
    "    s.to_csv(get_shad_server_username_to_telegram_table_path())\n",
    "\n",
    "\n",
    "def get_nvidia_smi_pid_column():\n",
    "    nvidia_smi_pid_column = !nvidia-smi | awk '{print $5}'\n",
    "    return nvidia_smi_pid_column\n",
    "\n",
    "\n",
    "def get_pid_username(pid: int) -> str:\n",
    "    username = !ps -o uname= -p {pid}\n",
    "    return username[0]\n",
    "\n",
    "\n",
    "def get_server_usernames_using_gpu() -> list[str]:\n",
    "    nvidia_smi_pid_column = get_nvidia_smi_pid_column()\n",
    "    pids_using_gpu = []\n",
    "    for row in nvidia_smi_pid_column[::-1]:\n",
    "        if row == \"PID\":\n",
    "            break\n",
    "        try:\n",
    "            pid = int(row)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        pids_using_gpu.append(int(pid))\n",
    "\n",
    "    usernames_using_gpu = [get_pid_username(pid) for pid in pids_using_gpu]\n",
    "    usernames_using_gpu = list(set(usernames_using_gpu))\n",
    "    return usernames_using_gpu\n",
    "\n",
    "\n",
    "def print_telegram_usernames_using_gpu():\n",
    "    server_to_telegram = read_shad_server_username_to_telegram_series()\n",
    "    usernames_using_gpu = get_server_usernames_using_gpu()\n",
    "\n",
    "    telegram_usernames_using_gpu = []\n",
    "    server_usernames_with_unknown_telegram_id = []\n",
    "    for username in usernames_using_gpu:\n",
    "        if username in server_to_telegram.index:\n",
    "            telegram_usernames_using_gpu.append(server_to_telegram[username])\n",
    "        else:\n",
    "            server_usernames_with_unknown_telegram_id.append(username)\n",
    "\n",
    "    print(\"Telegram ids of users using gpu:\")\n",
    "    print(\"\\n\".join(telegram_usernames_using_gpu))\n",
    "\n",
    "    if server_usernames_with_unknown_telegram_id:\n",
    "        print(\"Telegram id is unknown for users:\")\n",
    "        print(\"\\n\".join(server_usernames_with_unknown_telegram_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24930a13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:12:07.278398Z",
     "start_time": "2023-05-09T06:12:07.173920Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/dimakoshman/shad_server_username_to_telegram.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprint_telegram_usernames_using_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 56\u001b[0m, in \u001b[0;36mprint_telegram_usernames_using_gpu\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_telegram_usernames_using_gpu\u001b[39m():\n\u001b[0;32m---> 56\u001b[0m     server_to_telegram \u001b[38;5;241m=\u001b[39m \u001b[43mread_shad_server_username_to_telegram_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     usernames_using_gpu \u001b[38;5;241m=\u001b[39m get_server_usernames_using_gpu()\n\u001b[1;32m     59\u001b[0m     telegram_usernames_using_gpu \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m, in \u001b[0;36mread_shad_server_username_to_telegram_series\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_shad_server_username_to_telegram_series\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries:\n\u001b[0;32m---> 10\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_shad_server_username_to_telegram_table_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     series \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserver_username\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtelegram_username\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\n",
      "File \u001b[0;32m~/YSDA/python3.11_venv/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/YSDA/python3.11_venv/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/YSDA/python3.11_venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/YSDA/python3.11_venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/YSDA/python3.11_venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/YSDA/python3.11_venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/YSDA/python3.11_venv/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/dimakoshman/shad_server_username_to_telegram.csv'"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"print_telegram_usernames_using_gpu()\";\n",
       "                var nbb_formatted_code = \"print_telegram_usernames_using_gpu()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_telegram_usernames_using_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00de84",
   "metadata": {},
   "source": [
    "### Yadisk <span id=Yadisk_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8bd680e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:11:35.063356Z",
     "start_time": "2023-05-09T06:11:35.051966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"def get_yadisk_download_url(\\n    yadisk_url: str,\\n    base_url=\\\"https://cloud-api.yandex.net/v1/disk/public/resources/download?\\\",\\n) -> str:\\n    final_url = base_url + urllib.parse.urlencode(dict(public_key=yadisk_url))\\n    response = requests.get(final_url)\\n    download_url = response.json()[\\\"href\\\"]\\n    return download_url\";\n",
       "                var nbb_formatted_code = \"def get_yadisk_download_url(\\n    yadisk_url: str,\\n    base_url=\\\"https://cloud-api.yandex.net/v1/disk/public/resources/download?\\\",\\n) -> str:\\n    final_url = base_url + urllib.parse.urlencode(dict(public_key=yadisk_url))\\n    response = requests.get(final_url)\\n    download_url = response.json()[\\\"href\\\"]\\n    return download_url\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_yadisk_download_url(\n",
    "    yadisk_url: str,\n",
    "    base_url=\"https://cloud-api.yandex.net/v1/disk/public/resources/download?\",\n",
    ") -> str:\n",
    "    final_url = base_url + urllib.parse.urlencode(dict(public_key=yadisk_url))\n",
    "    response = requests.get(final_url)\n",
    "    download_url = response.json()[\"href\"]\n",
    "    return download_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06a7d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:12:49.581830Z",
     "start_time": "2023-05-09T06:12:49.577720Z"
    }
   },
   "source": [
    "### Web <span id=Web_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_url_response_content_to_file(url: str, filename: str) -> None:\n",
    "    download_response = requests.get(url)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(download_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460ee3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:14:50.054595Z",
     "start_time": "2023-05-09T06:14:50.050652Z"
    }
   },
   "source": [
    "### Bijection <span id=Bijection_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3375fb4",
   "metadata": {},
   "source": [
    "Actually, check out [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Bijection:\n",
    "    keys: list\n",
    "    values: list\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if len(set(self.keys)) != len(set(self.values)):\n",
    "            raise RuntimeError(\"Bijection is not injective.\")\n",
    "\n",
    "        self._series = pd.Series(index=self.keys, data=self.values)\n",
    "        self._inverse_series = pd.Series(index=self.values, data=self.keys)\n",
    "\n",
    "    def loc(self, index) -> np.ndarray:\n",
    "        return self._series.loc[index].values\n",
    "\n",
    "    def inverse_loc(self, index) -> np.ndarray:\n",
    "        return self._inverse_series.loc[index].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "\n",
    "def build_compact_bijection(values):\n",
    "    values = np.unique(values)\n",
    "    return Bijection(keys=np.arange(len(values)), values=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a4980d",
   "metadata": {},
   "source": [
    "### Train test split <span id=Train_test_split_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_index(size, test_fraction: float, seed=None):\n",
    "    test_size = int(size * test_fraction)\n",
    "    np.random.seed(seed=seed)\n",
    "    index = np.random.permutation(size)\n",
    "    train_index = index[test_size:]\n",
    "    test_index = index[:test_size]\n",
    "    return train_index, test_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ed45b",
   "metadata": {},
   "source": [
    "### Cache <span id=Cache_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db12a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T08:07:51.452897Z",
     "start_time": "2023-06-06T08:07:51.391211Z"
    }
   },
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "\n",
    "T = tp.TypeVar(\"T\")\n",
    "\n",
    "\n",
    "def load_if_exists_else_build_and_save(\n",
    "    path: str, load: tp.Callable[[str], T], build_and_save: tp.Callable[[str], T]\n",
    ") -> T:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Reusing file {path}\", file=sys.stderr)\n",
    "        return load(path)\n",
    "    return build_and_save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3ee58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T06:22:01.243719Z",
     "start_time": "2023-05-09T06:22:01.239360Z"
    }
   },
   "source": [
    "### Sparse <span id=Sparse_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a918bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csr_array_like(array):\n",
    "    return scipy.sparse.csr_array(array.shape, dtype=array.dtype)\n",
    "\n",
    "\n",
    "def slice_coo_array_by_entries_index(coo_array, index):\n",
    "    data = coo_array.data[index]\n",
    "    row = coo_array.row[index]\n",
    "    col = coo_array.col[index]\n",
    "    return scipy.sparse.coo_array(\n",
    "        (data, (row, col)), shape=coo_array.shape, dtype=coo_array.dtype\n",
    "    )\n",
    "\n",
    "\n",
    "def take_random_fraction_of_coo_array(coo_array, fraction: float, seed=None):\n",
    "    size = len(coo_array.data)\n",
    "    index = np.random.choice(size, size=int(size * fraction), replace=False)\n",
    "    coo_array = slice_coo_array_by_entries_index(coo_array, index)\n",
    "    return coo_array\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class IndexedCooArray:\n",
    "    coo_array: scipy.sparse.coo_array\n",
    "    row_index: np.ndarray\n",
    "    col_index: np.ndarray\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert self.coo_array.shape == (\n",
    "            len(self.row_index),\n",
    "            len(self.col_index),\n",
    "        ), \"Index shapes don't match.\"\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.coo_array.shape\n",
    "\n",
    "    def get_row_index_series(self):\n",
    "        return pd.Series(index=self.row_index, data=np.arange(self.shape[0]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        coo_array = self.coo_array.tocsr()[index].tocoo()\n",
    "        row_index = self.row_index[index]\n",
    "        col_index = self.col_index\n",
    "        return IndexedCooArray(\n",
    "            coo_array=coo_array, row_index=row_index, col_index=col_index\n",
    "        )\n",
    "\n",
    "\n",
    "def get_user_bool_index_with_at_least_n_interactions(csr_array, n_interactions: int):\n",
    "    index = csr_array.getnnz(axis=1) >= n_interactions\n",
    "    return index\n",
    "\n",
    "\n",
    "def get_item_bool_index_with_at_least_n_interactions(csr_array, n_interactions: int):\n",
    "    index = csr_array.getnnz(axis=0) >= n_interactions\n",
    "    return index\n",
    "\n",
    "\n",
    "def build_filtered_indexed_coo_array(\n",
    "    coo_array,\n",
    "    min_n_user_interactions_for_item: int,\n",
    "    min_n_item_interactions_for_user: int,\n",
    ") -> IndexedCooArray:\n",
    "    csr_array = coo_array.tocsr()\n",
    "    user_index = get_user_bool_index_with_at_least_n_interactions(\n",
    "        csr_array, min_n_item_interactions_for_user\n",
    "    )\n",
    "    item_index = get_item_bool_index_with_at_least_n_interactions(\n",
    "        csr_array, min_n_user_interactions_for_item\n",
    "    )\n",
    "\n",
    "    row_index = np.arange(coo_array.shape[0])[user_index]\n",
    "    col_index = np.arange(coo_array.shape[1])[item_index]\n",
    "\n",
    "    csr_array = csr_array[user_index][:, item_index]\n",
    "    coo_array = csr_array.tocoo()\n",
    "\n",
    "    indexed_coo_array = IndexedCooArray(coo_array, row_index, col_index)\n",
    "    return indexed_coo_array\n",
    "\n",
    "\n",
    "def remove_n_item_interactions_for_each_user(coo_array, n_items, seed=None):\n",
    "    n_interactions = len(coo_array.data)\n",
    "    index = np.arange(n_interactions)\n",
    "    df = pd.DataFrame(dict(row=coo_array.row, col=coo_array.col, index=index))\n",
    "\n",
    "    try:\n",
    "        df = df.groupby(\"row\").sample(n_items, random_state=seed)\n",
    "    except ValueError:\n",
    "        raise RuntimeError(f\"There are users with less than {n_items} interactions.\")\n",
    "\n",
    "    index_to_remove = df[\"index\"].values\n",
    "    index[:] = True\n",
    "    index[index_to_remove] = False\n",
    "    index = index.astype(bool)\n",
    "\n",
    "    coo_array = slice_coo_array_by_entries_index(coo_array, index)\n",
    "    return coo_array\n",
    "\n",
    "\n",
    "def train_test_split(\n",
    "    indexed_coo_array: IndexedCooArray,\n",
    "    n_item_interactions_to_split_as_ground_truth,\n",
    "    seed=None,\n",
    "):\n",
    "    test = copy.deepcopy(indexed_coo_array)\n",
    "\n",
    "    train_coo_array = remove_n_item_interactions_for_each_user(\n",
    "        coo_array=indexed_coo_array.coo_array,\n",
    "        n_items=n_item_interactions_to_split_as_ground_truth,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    train = indexed_coo_array\n",
    "    train.coo_array = train_coo_array\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def torch_tensor_to_scipy_coo(tensor: torch.Tensor) -> scipy.sparse.coo_array:\n",
    "    if tensor.ndim != 2:\n",
    "        raise ValueError(\"Only 2d tensors can be converted to sparse coo arrays.\")\n",
    "\n",
    "    tensor = tensor.detach().cpu().to_sparse_coo().coalesce()\n",
    "    values = tensor.values().numpy()\n",
    "    indices = tensor.indices().numpy()\n",
    "    sparse_coo_array = scipy.sparse.coo_array((values, indices), shape=tensor.shape)\n",
    "    return sparse_coo_array\n",
    "\n",
    "\n",
    "def scipy_coo_to_torch_tensor(coo_array: scipy.sparse.coo_array) -> torch.Tensor:\n",
    "    indices = torch.from_numpy(np.array([coo_array.row, coo_array.col]))\n",
    "    data = torch.from_numpy(coo_array.data)\n",
    "    tensor = torch.sparse_coo_tensor(indices=indices, values=data, size=coo_array.shape)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6e482",
   "metadata": {},
   "source": [
    "### Pandas <span id=Pandas_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b916ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_index(df):\n",
    "    df = df.loc[~df.index.duplicated(keep=\"first\")]\n",
    "    return df\n",
    "\n",
    "def dataframe_heatmap(df,axis=0):\n",
    "    style = df.style.background_gradient(\n",
    "        axis=axis, cmap=plt.colormaps[\"coolwarm\"], low=0.5, high=0.5\n",
    "    )\n",
    "    return style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5810f9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T08:33:06.178819Z",
     "start_time": "2023-05-24T08:33:06.172671Z"
    }
   },
   "source": [
    "### Midjourney images to yadisk <span id=Midjourney_images_to_yadisk_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a2bd0",
   "metadata": {},
   "source": [
    "YaDiskClient library with fixed bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75778e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T07:46:45.343660Z",
     "start_time": "2023-09-10T07:46:45.275079Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from warnings import warn\n",
    "\n",
    "from requests import request\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "class YaDiskException(Exception):\n",
    "    \"\"\"Common exception class for YaDisk. Arg 'code' have code of HTTP Error.\"\"\"\n",
    "\n",
    "    code = None\n",
    "\n",
    "    def __init__(self, code, text):\n",
    "        super(YaDiskException, self).__init__(text)\n",
    "        self.code = code\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{code}. {message}\".format(\n",
    "            code=self.code, message=super(YaDiskException, self).__str__()\n",
    "        )\n",
    "\n",
    "\n",
    "class YaDiskXML(object):\n",
    "    namespaces = {\"d\": \"DAV:\"}\n",
    "\n",
    "    def find(self, node, path):\n",
    "        \"\"\"Wrapper for lxml`s find.\"\"\"\n",
    "\n",
    "        return node.find(path, namespaces=self.namespaces)\n",
    "\n",
    "    def xpath(self, node, path):\n",
    "        \"\"\"Wrapper for lxml`s xpath.\"\"\"\n",
    "\n",
    "        return node.xpath(path, namespaces=self.namespaces)\n",
    "\n",
    "\n",
    "def _check_dst_absolute(dst):\n",
    "    if dst[0] != \"/\":\n",
    "        raise YaDiskException(400, \"Destination path must be absolute\")\n",
    "\n",
    "\n",
    "class YaDisk(object):\n",
    "    \"\"\"Main object for work with Yandex.disk.\"\"\"\n",
    "\n",
    "    token = None\n",
    "    login = None\n",
    "    password = None\n",
    "    url = \"https://webdav.yandex.ru/\"\n",
    "    namespaces = {\"d\": \"DAV:\"}\n",
    "\n",
    "    def set_token(self, token):\n",
    "        self.token = token\n",
    "        self.login = None\n",
    "        self.password = None\n",
    "\n",
    "    def set_auth(self, login, password):\n",
    "        self.token = None\n",
    "        self.login = login\n",
    "        self.password = password\n",
    "\n",
    "    def _sendRequest(self, type, addUrl=\"/\", addHeaders={}, data=None):\n",
    "        if self.token is None and (self.login is None or self.password is None):\n",
    "            raise YaDiskException(\n",
    "                400, \"Specify token or login/password for Yandex.Disk account.\"\n",
    "            )\n",
    "\n",
    "        headers = {\"Accept\": \"*/*\"}\n",
    "        auth = None\n",
    "        if self.token is not None:\n",
    "            headers[\"Authorization\"] = \"OAuth %s\" % self.token\n",
    "        else:\n",
    "            auth = (self.login, self.password)\n",
    "\n",
    "        headers.update(addHeaders)\n",
    "        url = self.url + addUrl\n",
    "        return request(type, url, headers=headers, auth=auth, data=data)\n",
    "\n",
    "    def ls(self, path, offset=None, amount=None):\n",
    "        \"\"\"\n",
    "        Return list of files/directories. Each item is a dict.\n",
    "        Keys: 'path', 'creationdate', 'displayname', 'length', 'lastmodified', 'isDir'.\n",
    "        \"\"\"\n",
    "\n",
    "        def parseContent(content):\n",
    "            result = []\n",
    "            root = ET.fromstring(content)\n",
    "            for response in root.findall(\".//d:response\", namespaces=self.namespaces):\n",
    "                node = {\n",
    "                    \"path\": response.find(\"d:href\", namespaces=self.namespaces).text,\n",
    "                    \"creationdate\": response.find(\n",
    "                        \"d:propstat/d:prop/d:creationdate\", namespaces=self.namespaces\n",
    "                    ).text,\n",
    "                    \"displayname\": response.find(\n",
    "                        \"d:propstat/d:prop/d:displayname\", namespaces=self.namespaces\n",
    "                    ).text,\n",
    "                    \"lastmodified\": response.find(\n",
    "                        \"d:propstat/d:prop/d:getlastmodified\",\n",
    "                        namespaces=self.namespaces,\n",
    "                    ).text,\n",
    "                    \"isDir\": response.find(\n",
    "                        \"d:propstat/d:prop/d:resourcetype/d:collection\",\n",
    "                        namespaces=self.namespaces,\n",
    "                    )\n",
    "                    != None,\n",
    "                }\n",
    "                if not node[\"isDir\"]:\n",
    "                    node[\"length\"] = response.find(\n",
    "                        \"d:propstat/d:prop/d:getcontentlength\",\n",
    "                        namespaces=self.namespaces,\n",
    "                    ).text\n",
    "                    node[\"etag\"] = response.find(\n",
    "                        \"d:propstat/d:prop/d:getetag\", namespaces=self.namespaces\n",
    "                    ).text\n",
    "                    node[\"type\"] = response.find(\n",
    "                        \"d:propstat/d:prop/d:getcontenttype\", namespaces=self.namespaces\n",
    "                    ).text\n",
    "                result.append(node)\n",
    "            return result\n",
    "\n",
    "        url = path\n",
    "        if (offset is not None) and (amount is not None):\n",
    "            url += \"?offset={offset}&amount={amount}\".format(\n",
    "                offset=offset, amount=amount\n",
    "            )\n",
    "        resp = self._sendRequest(\"PROPFIND\", url, {\"Depth\": \"1\"})\n",
    "        if resp.status_code == 207:\n",
    "            return parseContent(resp.content)\n",
    "        else:\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def df(self):\n",
    "        \"\"\"Return dict with size of Ya.Disk. Keys: 'available', 'used'.\"\"\"\n",
    "\n",
    "        def parseContent(content):\n",
    "            root = ET.fromstring(content)\n",
    "            return {\n",
    "                \"available\": root.find(\n",
    "                    \".//d:quota-available-bytes\", namespaces=self.namespaces\n",
    "                ).text,\n",
    "                \"used\": root.find(\n",
    "                    \".//d:quota-used-bytes\", namespaces=self.namespaces\n",
    "                ).text,\n",
    "            }\n",
    "\n",
    "        data = \"\"\"\n",
    "<D:propfind xmlns:D=\"DAV:\">\n",
    "  <D:prop>\n",
    "    <D:quota-available-bytes/>\n",
    "    <D:quota-used-bytes/>\n",
    "  </D:prop>\n",
    "</D:propfind>\n",
    "        \"\"\"\n",
    "        resp = self._sendRequest(\"PROPFIND\", \"/\", {\"Depth\": \"0\"}, data)\n",
    "        if resp.status_code == 207:\n",
    "            return parseContent(resp.content)\n",
    "        else:\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def mkdir(self, path):\n",
    "        \"\"\"Create directory. All part of path must be exists. Raise exception when path already exists.\"\"\"\n",
    "\n",
    "        resp = self._sendRequest(\"MKCOL\", path)\n",
    "        if resp.status_code != 201:\n",
    "            if resp.status_code == 409:\n",
    "                raise YaDiskException(\n",
    "                    409, \"Part of path {} does not exists\".format(path)\n",
    "                )\n",
    "            elif resp.status_code == 405:\n",
    "                raise YaDiskException(405, \"Path {} already exists\".format(path))\n",
    "            else:\n",
    "                raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def rm(self, path):\n",
    "        \"\"\"Delete file or directory.\"\"\"\n",
    "\n",
    "        resp = self._sendRequest(\"DELETE\", path)\n",
    "        # By documentation server must return 200 \"OK\", but I get 204 \"No Content\".\n",
    "        # Anyway file or directory have been removed.\n",
    "        if not (resp.status_code in (200, 204)):\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def cp(self, src, dst):\n",
    "        \"\"\"Copy file or directory.\"\"\"\n",
    "\n",
    "        _check_dst_absolute(dst)\n",
    "        resp = self._sendRequest(\"COPY\", src, {\"Destination\": dst})\n",
    "        if resp.status_code not in (201, 202):\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def mv(self, src, dst):\n",
    "        \"\"\"Move file or directory.\"\"\"\n",
    "\n",
    "        _check_dst_absolute(dst)\n",
    "        resp = self._sendRequest(\"MOVE\", src, {\"Destination\": dst})\n",
    "        if resp.status_code not in (201, 202):\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def upload(self, file, path):\n",
    "        \"\"\"Upload file.\"\"\"\n",
    "\n",
    "        with open(file, \"rb\") as f:\n",
    "            resp = self._sendRequest(\"PUT\", path, data=f)\n",
    "            if resp.status_code not in (201, 202):\n",
    "                raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def download(self, path, file):\n",
    "        \"\"\"Download remote file to disk.\"\"\"\n",
    "\n",
    "        resp = self._sendRequest(\"GET\", path)\n",
    "        if resp.status_code == 200:\n",
    "            with open(file, \"wb\") as f:\n",
    "                f.write(resp.content)\n",
    "        else:\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def publish(self, path):\n",
    "        \"\"\"Publish file or folder and return public url\"\"\"\n",
    "\n",
    "        def parseContent(content):\n",
    "            root = ET.fromstring(content)\n",
    "            prop = root.find(\".//d:prop\", namespaces=self.namespaces)\n",
    "            return prop.find(\"{urn:yandex:disk:meta}public_url\").text.strip()\n",
    "\n",
    "        data = \"\"\"\n",
    "<propertyupdate xmlns=\"DAV:\">\n",
    "  <set>\n",
    "    <prop>\n",
    "      <public_url xmlns=\"urn:yandex:disk:meta\">true</public_url>\n",
    "    </prop>\n",
    "  </set>\n",
    "</propertyupdate>\n",
    "        \"\"\"\n",
    "\n",
    "        _check_dst_absolute(path)\n",
    "        resp = self._sendRequest(\"PROPPATCH\", addUrl=path, data=data)\n",
    "        if resp.status_code == 207:\n",
    "            return parseContent(resp.content)\n",
    "        else:\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def unpublish(self, path):\n",
    "        \"\"\"Make public file or folder private (delete public url)\"\"\"\n",
    "\n",
    "        data = \"\"\"\n",
    "<propertyupdate xmlns=\"DAV:\">\n",
    "  <remove>\n",
    "    <prop>\n",
    "      <public_url xmlns=\"urn:yandex:disk:meta\" />\n",
    "    </prop>\n",
    "  </remove>\n",
    "</propertyupdate>\n",
    "        \"\"\"\n",
    "\n",
    "        _check_dst_absolute(path)\n",
    "        resp = self._sendRequest(\"PROPPATCH\", addUrl=path, data=data)\n",
    "        if resp.status_code == 207:\n",
    "            pass\n",
    "        else:\n",
    "            raise YaDiskException(resp.status_code, resp.content)\n",
    "\n",
    "    def publish_doc(self, path):\n",
    "        warn(\n",
    "            'This method was deprecated in favor method \"publish\"',\n",
    "            DeprecationWarning,\n",
    "            stacklevel=2,\n",
    "        )\n",
    "        return self.publish(path)\n",
    "\n",
    "    def hide_doc(self, path):\n",
    "        warn(\n",
    "            'This method was deprecated in favor method \"unpublish\"',\n",
    "            DeprecationWarning,\n",
    "            stacklevel=2,\n",
    "        )\n",
    "        return self.unpublish(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5abd4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T07:50:18.306064Z",
     "start_time": "2023-09-10T07:50:18.009711Z"
    }
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import tqdm.autonotebook\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "yandex_client_id = \"3d5e193c86ba465f9d737bbdfdb28f33\"\n",
    "yandex_admin_url = f\"https://oauth.yandex.ru/client/{yandex_client_id}\"\n",
    "yandex_get_token_url = f\"https://oauth.yandex.ru/authorize?response_type=token&client_id={yandex_client_id}\"\n",
    "yandex_token = input(prompt=f\"Type in token from {yandex_get_token_url}\\n\")\n",
    "yadisk = YaDisk()\n",
    "yadisk.set_token(yandex_token)\n",
    "yadisk.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba3b6a29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T07:56:51.400741Z",
     "start_time": "2023-09-10T07:56:51.131374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading images from https://www.midjourney.com/showcase/recent/ to yandex disk folder https://disk.yandex.com/client/disk/midjourney/:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee3d42c750a4bd78dc01e29d248f4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "midjourney_showcase = \"https://www.midjourney.com/showcase/recent/\"\n",
    "yadisk_folder = \"/midjourney/\"\n",
    "n_images = 100\n",
    "\n",
    "midjouney_response = requests.get(midjourney_showcase)\n",
    "content = midjouney_response.content.decode(\"utf-8\")\n",
    "image_urls = re.findall(r'\"seedImageURL\":\"(.*?)\"', content)\n",
    "\n",
    "print(\n",
    "    f\"Uploading images from {midjourney_showcase} \"\n",
    "    f\"to yandex disk folder https://disk.yandex.com/client/disk{yadisk_folder}:\"\n",
    ")\n",
    "for image_url in tqdm.autonotebook.tqdm(image_urls[:n_images]):\n",
    "    response = requests.get(image_url, stream=True)\n",
    "    image = PIL.Image.open(response.raw)\n",
    "    tmp_png = \"tmp.png\"\n",
    "    image.save(open(tmp_png, \"wb\"))\n",
    "    image_id = re.match(r\"https://cdn.midjourney.com/(.*?/.*)\", image_url).groups()[0]\n",
    "    image_id = image_id.replace(\"/\", \"_\")\n",
    "    yadisk.upload(tmp_png, yadisk_folder + image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849020f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T10:08:36.175514Z",
     "start_time": "2023-05-24T10:08:36.171120Z"
    }
   },
   "source": [
    "### Clipboard <span id=Clipboard_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30a53390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:23:32.816550Z",
     "start_time": "2023-09-01T08:23:32.813222Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def clipboard_io(function: Callable[[str], str]) -> None:\n",
    "    \"\"\"Take input for function from clipboard and replace it with output.\"\"\"\n",
    "    pyperclip.copy(function(pyperclip.paste()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f24aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T17:55:13.228793Z",
     "start_time": "2023-05-31T17:55:13.196542Z"
    }
   },
   "source": [
    "### Markdown filtered directory tree <span id=Markdown_filtered_directory_tree_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67a24153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:23:56.007756Z",
     "start_time": "2023-09-01T08:23:55.991612Z"
    }
   },
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import os\n",
    "import pyperclip\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Tree:\n",
    "    root: str\n",
    "    filenames: list[str] = dataclasses.field(default_factory=list)\n",
    "    dirnames: dict[str, \"Tree\"] = dataclasses.field(default_factory=dict)\n",
    "\n",
    "    def __bool__(self):\n",
    "        return bool(self.filenames or self.dirnames)\n",
    "\n",
    "\n",
    "def build_filtered_tree(directory, filename_filter, dirname_filter) -> Tree:\n",
    "    tree = Tree(directory)\n",
    "\n",
    "    if not dirname_filter(os.path.split(directory)[1]):\n",
    "        return tree\n",
    "\n",
    "    _, dirnames, filenames = next(os.walk(directory))\n",
    "\n",
    "    for filename in filter(filename_filter, sorted(filenames)):\n",
    "        tree.filenames.append(filename)\n",
    "\n",
    "    for dirname in sorted(dirnames):\n",
    "        if subtree := build_filtered_tree(\n",
    "            os.path.join(directory, dirname), filename_filter, dirname_filter\n",
    "        ):\n",
    "            tree.dirnames[dirname] = subtree\n",
    "\n",
    "    return tree\n",
    "\n",
    "\n",
    "def build_markdown_filename_link(filename):\n",
    "    \"\"\"Assuming jupyter was launched from home directory.\"\"\"\n",
    "\n",
    "    jupyter_launch_dir = os.environ[\"HOME\"]\n",
    "    f = filename_relative_to_home = filename.removeprefix(jupyter_launch_dir)\n",
    "    bare_filename = os.path.splitext(os.path.split(f)[1])[0]\n",
    "    link = f\"[{bare_filename}](</tree{f}>)\"\n",
    "    return link\n",
    "\n",
    "\n",
    "def build_markdown_tree(tree: Tree, prefix=\"- \", dir_indent=\"  \"):\n",
    "    markdown_tree = \"\"\n",
    "\n",
    "    for filename in tree.filenames:\n",
    "        filename = os.path.join(tree.root, filename)\n",
    "        markdown_tree += prefix + build_markdown_filename_link(filename) + \"\\n\"\n",
    "\n",
    "    for dirname, subtree in tree.dirnames.items():\n",
    "        markdown_subtree = build_markdown_tree(subtree, dir_indent + prefix)\n",
    "        if markdown_subtree:\n",
    "            markdown_tree += prefix + dirname + \"\\n\"\n",
    "            markdown_tree += markdown_subtree\n",
    "\n",
    "    return markdown_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03ddcd12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:24:19.495547Z",
     "start_time": "2023-09-01T08:24:19.378669Z"
    }
   },
   "outputs": [],
   "source": [
    "notebook_tree = build_filtered_tree(\n",
    "    directory=\"/Users/dimakoshman/YSDA\",\n",
    "    filename_filter=lambda f: f.endswith(\".ipynb\"),\n",
    "    dirname_filter=lambda d: d not in [\".ipynb_checkpoints\", \"python3.11\"],\n",
    ")\n",
    "\n",
    "markdown_tree = build_markdown_tree(notebook_tree)\n",
    "\n",
    "pyperclip.copy(markdown_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "be2fad3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T18:34:39.098968Z",
     "start_time": "2023-05-31T18:34:39.058804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 153;\n",
       "                var nbb_unformatted_code = \"tree = build_filtered_tree(\\n    directory=\\\"/Users/dimakoshman/CLionProjects/Shad_algorithms_2\\\",\\n    filename_filter=lambda f: f.endswith(\\\".cpp\\\"),\\n    dirname_filter=lambda d: not d.startswith(\\\"cmake-build\\\"),\\n)\\n\\nmarkdown_tree = build_markdown_tree(tree)\\n\\npyperclip.copy(markdown_tree)\";\n",
       "                var nbb_formatted_code = \"tree = build_filtered_tree(\\n    directory=\\\"/Users/dimakoshman/CLionProjects/Shad_algorithms_2\\\",\\n    filename_filter=lambda f: f.endswith(\\\".cpp\\\"),\\n    dirname_filter=lambda d: not d.startswith(\\\"cmake-build\\\"),\\n)\\n\\nmarkdown_tree = build_markdown_tree(tree)\\n\\npyperclip.copy(markdown_tree)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpp_tree = build_filtered_tree(\n",
    "    directory=\"/Users/dimakoshman/CLionProjects/Shad_algorithms_2\",\n",
    "    filename_filter=lambda f: f.endswith(\".cpp\"),\n",
    "    dirname_filter=lambda d: not d.startswith(\"cmake-build\"),\n",
    ")\n",
    "\n",
    "markdown_tree = build_markdown_tree(cpp_tree)\n",
    "\n",
    "pyperclip.copy(markdown_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12a9be2",
   "metadata": {},
   "source": [
    "- Code_review\n",
    "  - [fuzzy_matching](</tree/CLionProjects/Shad_algorithms_2/Code_review/fuzzy_matching.cpp>)\n",
    "  - [my_fuzzy_matching](</tree/CLionProjects/Shad_algorithms_2/Code_review/my_fuzzy_matching.cpp>)\n",
    "- Code_review_2\n",
    "  - [main](</tree/CLionProjects/Shad_algorithms_2/Code_review_2/main.cpp>)\n",
    "  - [main_short](</tree/CLionProjects/Shad_algorithms_2/Code_review_2/main_short.cpp>)\n",
    "- Seminars\n",
    "  - [A](</tree/CLionProjects/Shad_algorithms_2/Seminars/A.cpp>)\n",
    "  - [B](</tree/CLionProjects/Shad_algorithms_2/Seminars/B.cpp>)\n",
    "  - [C](</tree/CLionProjects/Shad_algorithms_2/Seminars/C.cpp>)\n",
    "  - [D](</tree/CLionProjects/Shad_algorithms_2/Seminars/D.cpp>)\n",
    "  - [E](</tree/CLionProjects/Shad_algorithms_2/Seminars/E.cpp>)\n",
    "  - [F](</tree/CLionProjects/Shad_algorithms_2/Seminars/F.cpp>)\n",
    "  - [contest](</tree/CLionProjects/Shad_algorithms_2/Seminars/contest.cpp>)\n",
    "- contest_1\n",
    "  - [A](</tree/CLionProjects/Shad_algorithms_2/contest_1/A.cpp>)\n",
    "  - [B](</tree/CLionProjects/Shad_algorithms_2/contest_1/B.cpp>)\n",
    "  - [C](</tree/CLionProjects/Shad_algorithms_2/contest_1/C.cpp>)\n",
    "  - [D](</tree/CLionProjects/Shad_algorithms_2/contest_1/D.cpp>)\n",
    "- contest_2\n",
    "  - [A](</tree/CLionProjects/Shad_algorithms_2/contest_2/A.cpp>)\n",
    "  - [B](</tree/CLionProjects/Shad_algorithms_2/contest_2/B.cpp>)\n",
    "  - [C](</tree/CLionProjects/Shad_algorithms_2/contest_2/C.cpp>)\n",
    "  - [D](</tree/CLionProjects/Shad_algorithms_2/contest_2/D.cpp>)\n",
    "- contest_3\n",
    "  - [A](</tree/CLionProjects/Shad_algorithms_2/contest_3/A.cpp>)\n",
    "  - [B](</tree/CLionProjects/Shad_algorithms_2/contest_3/B.cpp>)\n",
    "  - [C](</tree/CLionProjects/Shad_algorithms_2/contest_3/C.cpp>)\n",
    "  - [D](</tree/CLionProjects/Shad_algorithms_2/contest_3/D.cpp>)\n",
    "  - [E](</tree/CLionProjects/Shad_algorithms_2/contest_3/E.cpp>)\n",
    "  - [vasya_largest_common_substring](</tree/CLionProjects/Shad_algorithms_2/contest_3/vasya_largest_common_substring.cpp>)\n",
    "- contest_4\n",
    "  - [A](</tree/CLionProjects/Shad_algorithms_2/contest_4/A.cpp>)\n",
    "  - [B](</tree/CLionProjects/Shad_algorithms_2/contest_4/B.cpp>)\n",
    "  - [C](</tree/CLionProjects/Shad_algorithms_2/contest_4/C.cpp>)\n",
    "  - [D](</tree/CLionProjects/Shad_algorithms_2/contest_4/D.cpp>)\n",
    "  - [E](</tree/CLionProjects/Shad_algorithms_2/contest_4/E.cpp>)\n",
    "- contest_5\n",
    "  - [B](</tree/CLionProjects/Shad_algorithms_2/contest_5/B.cpp>)\n",
    "  - [C](</tree/CLionProjects/Shad_algorithms_2/contest_5/C.cpp>)\n",
    "  - [D](</tree/CLionProjects/Shad_algorithms_2/contest_5/D.cpp>)\n",
    "  - [E](</tree/CLionProjects/Shad_algorithms_2/contest_5/E.cpp>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8b17d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T11:33:33.149072Z",
     "start_time": "2023-06-02T11:33:33.113532Z"
    }
   },
   "source": [
    "### Camel case to snake case <span id=Camel_case_to_snake_case_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26301303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def camel_case_to_snake(string):\n",
    "    string = re.sub(\"\\s+\", \"\", string)\n",
    "    words = re.split(r\"(?<=.)(?=[A-Z])\", string)\n",
    "    snake_case = \"_\".join(w.lower() for w in words)\n",
    "    return snake_case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05e3d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T13:08:17.120293Z",
     "start_time": "2023-06-02T13:08:17.115636Z"
    }
   },
   "source": [
    "### Uml diagrams for modules <span id=Uml_diagrams_for_modules_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b39c8643",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T13:16:46.131564Z",
     "start_time": "2023-06-02T13:16:46.106627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 65;\n",
       "                var nbb_unformatted_code = \"import IPython\\nimport graphviz\\nimport os\\n\\n\\ndef build_uml_diagram_in_directory(\\n    package_or_module_path: str, output_directory=\\\"tmp\\\"\\n) -> str:\\n    os.makedirs(output_directory, exist_ok=True)\\n    !pyreverse {package_or_module_path} --output-directory {output_directory}\\n    return output_directory\\n\\n\\ndef load_graphviz_graphs(directory: str) -> list[graphviz.Source]:\\n    graphs = []\\n\\n    for filename in os.listdir(directory):\\n        filename = os.path.join(directory, filename)\\n        graph = graphviz.Source.from_file(filename)\\n        graphs.append(graph)\\n\\n    return graphs\\n\\n\\ndef display_uml_diagrams(package_or_module_path, **kwargs):\\n    directory = build_uml_diagram_in_directory(package_or_module_path, **kwargs)\\n    diagrams = load_graphviz_graphs(directory)\\n    \\n    for diagram in diagrams:\\n        IPython.display.display(diagram.filename)\\n        IPython.display.display(diagram)\";\n",
       "                var nbb_formatted_code = \"import IPython\\nimport graphviz\\nimport os\\n\\n\\ndef build_uml_diagram_in_directory(\\n    package_or_module_path: str, output_directory=\\\"tmp\\\"\\n) -> str:\\n    os.makedirs(output_directory, exist_ok=True)\\n    !pyreverse {package_or_module_path} --output-directory {output_directory}\\n    return output_directory\\n\\n\\ndef load_graphviz_graphs(directory: str) -> list[graphviz.Source]:\\n    graphs = []\\n\\n    for filename in os.listdir(directory):\\n        filename = os.path.join(directory, filename)\\n        graph = graphviz.Source.from_file(filename)\\n        graphs.append(graph)\\n\\n    return graphs\\n\\n\\ndef display_uml_diagrams(package_or_module_path, **kwargs):\\n    directory = build_uml_diagram_in_directory(package_or_module_path, **kwargs)\\n    diagrams = load_graphviz_graphs(directory)\\n\\n    for diagram in diagrams:\\n        IPython.display.display(diagram.filename)\\n        IPython.display.display(diagram)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython\n",
    "import graphviz\n",
    "import os\n",
    "\n",
    "\n",
    "def build_uml_diagram_in_directory(\n",
    "    package_or_module_path: str, output_directory=\"tmp\"\n",
    ") -> str:\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    !pyreverse {package_or_module_path} --output-directory {output_directory}\n",
    "    return output_directory\n",
    "\n",
    "\n",
    "def load_graphviz_graphs(directory: str) -> list[graphviz.Source]:\n",
    "    graphs = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        filename = os.path.join(directory, filename)\n",
    "        graph = graphviz.Source.from_file(filename)\n",
    "        graphs.append(graph)\n",
    "\n",
    "    return graphs\n",
    "\n",
    "\n",
    "def display_uml_diagrams(package_or_module_path, **kwargs):\n",
    "    directory = build_uml_diagram_in_directory(package_or_module_path, **kwargs)\n",
    "    diagrams = load_graphviz_graphs(directory)\n",
    "\n",
    "    for diagram in diagrams:\n",
    "        IPython.display.display(diagram.filename)\n",
    "        IPython.display.display(diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a51014a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-03T14:06:11.933963Z",
     "start_time": "2023-06-03T14:06:06.176258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing /Users/dimakoshman/YSDA/my_tools/my_tools/__init__.py...\r\n",
      "parsing /Users/dimakoshman/YSDA/my_tools/my_tools/extra.py...\r\n",
      "parsing /Users/dimakoshman/YSDA/my_tools/my_tools/models.py...\r\n",
      "parsing /Users/dimakoshman/YSDA/my_tools/my_tools/sandbox_setup.py...\r\n",
      "parsing /Users/dimakoshman/YSDA/my_tools/my_tools/__init__.py...\r\n",
      "parsing /Users/dimakoshman/YSDA/my_tools/my_tools/entrypoint.py...\r\n",
      "parsing /Users/dimakoshman/YSDA/my_tools/my_tools/utils.py...\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tmp/classes.dot'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.5 (20230430.1635)\n",
       " -->\n",
       "<!-- Title: classes Pages: 1 -->\n",
       "<svg width=\"1078pt\" height=\"350pt\"\n",
       " viewBox=\"0.00 0.00 1077.75 350.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 346)\">\n",
       "<title>classes</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-346 1073.75,-346 1073.75,4 -4,4\"/>\n",
       "<!-- my_tools.utils.BuilderMixin -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>my_tools.utils.BuilderMixin</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"82.12,-247.25 82.12,-337.25 203.12,-337.25 203.12,-247.25 82.12,-247.25\"/>\n",
       "<text text-anchor=\"start\" x=\"105.5\" y=\"-319.95\" font-family=\"Times,serif\" font-size=\"14.00\">BuilderMixin</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"82.12,-312.75 203.12,-312.75\"/>\n",
       "<text text-anchor=\"start\" x=\"90.12\" y=\"-295.45\" font-family=\"Times,serif\" font-size=\"14.00\">class_candidates</text>\n",
       "<text text-anchor=\"start\" x=\"90.12\" y=\"-278.95\" font-family=\"Times,serif\" font-size=\"14.00\">module_candidates</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"82.12,-271.75 203.12,-271.75\"/>\n",
       "<text text-anchor=\"start\" x=\"92.75\" y=\"-254.45\" font-family=\"Times,serif\" font-size=\"14.00\">build_class(): Any</text>\n",
       "</g>\n",
       "<!-- my_tools.entrypoint.ConfigDispenser -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>my_tools.entrypoint.ConfigDispenser</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"303.62,-0.5 303.62,-206 541.62,-206 541.62,-0.5 303.62,-0.5\"/>\n",
       "<text text-anchor=\"start\" x=\"376.88\" y=\"-188.7\" font-family=\"Times,serif\" font-size=\"14.00\">ConfigDispenser</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"303.62,-181.5 541.62,-181.5\"/>\n",
       "<text text-anchor=\"start\" x=\"311.62\" y=\"-164.2\" font-family=\"Times,serif\" font-size=\"14.00\">cli_argument_parser</text>\n",
       "<text text-anchor=\"start\" x=\"311.62\" y=\"-147.7\" font-family=\"Times,serif\" font-size=\"14.00\">config_path : str</text>\n",
       "<text text-anchor=\"start\" x=\"311.62\" y=\"-131.2\" font-family=\"Times,serif\" font-size=\"14.00\">extra_config_kwargs : dict</text>\n",
       "<text text-anchor=\"start\" x=\"311.62\" y=\"-114.7\" font-family=\"Times,serif\" font-size=\"14.00\">function : Callable[[dict], Any], Callable</text>\n",
       "<text text-anchor=\"start\" x=\"311.62\" y=\"-98.2\" font-family=\"Times,serif\" font-size=\"14.00\">runs_count : int</text>\n",
       "<text text-anchor=\"start\" x=\"311.62\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">sweep_id : NoneType</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"303.62,-74.5 541.62,-74.5\"/>\n",
       "<text text-anchor=\"start\" x=\"317.25\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">from_cli()</text>\n",
       "<text text-anchor=\"start\" x=\"317.25\" y=\"-40.7\" font-family=\"Times,serif\" font-size=\"14.00\">function_wrapper(config)</text>\n",
       "<text text-anchor=\"start\" x=\"317.25\" y=\"-24.2\" font-family=\"Times,serif\" font-size=\"14.00\">launch(function: Callable[[dict], Any])</text>\n",
       "<text text-anchor=\"start\" x=\"317.25\" y=\"-7.7\" font-family=\"Times,serif\" font-size=\"14.00\">sweep_agent_wrapper()</text>\n",
       "</g>\n",
       "<!-- my_tools.entrypoint.WandbSweepProcessor -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>my_tools.entrypoint.WandbSweepProcessor</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"313,-243 313,-341.5 532.25,-341.5 532.25,-243 313,-243\"/>\n",
       "<text text-anchor=\"start\" x=\"358.88\" y=\"-324.2\" font-family=\"Times,serif\" font-size=\"14.00\">WandbSweepProcessor</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"313,-317 532.25,-317\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"313,-317 532.25,-317\"/>\n",
       "<text text-anchor=\"start\" x=\"321\" y=\"-299.7\" font-family=\"Times,serif\" font-size=\"14.00\">initialize_sweep(config_path, config)</text>\n",
       "<text text-anchor=\"start\" x=\"321\" y=\"-283.2\" font-family=\"Times,serif\" font-size=\"14.00\">is_sweep(config)</text>\n",
       "<text text-anchor=\"start\" x=\"321\" y=\"-266.7\" font-family=\"Times,serif\" font-size=\"14.00\">postprocess_config(config)</text>\n",
       "<text text-anchor=\"start\" x=\"321\" y=\"-250.2\" font-family=\"Times,serif\" font-size=\"14.00\">preprocess_sweep_config(config)</text>\n",
       "</g>\n",
       "<!-- my_tools.entrypoint.ConfigDispenser&#45;&gt;my_tools.entrypoint.WandbSweepProcessor -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>my_tools.entrypoint.ConfigDispenser&#45;&gt;my_tools.entrypoint.WandbSweepProcessor</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M422.62,-205.96C422.62,-215.01 422.62,-223.96 422.62,-232.47\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"419.13,-232.36 422.62,-242.36 426.13,-232.36 419.13,-232.36\"/>\n",
       "</g>\n",
       "<!-- my_tools.entrypoint.LightningConfigBuilder -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>my_tools.entrypoint.LightningConfigBuilder</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-206 285.25,-206 285.25,-0.5 0,-0.5\"/>\n",
       "<text text-anchor=\"start\" x=\"77\" y=\"-188.7\" font-family=\"Times,serif\" font-size=\"14.00\">LightningConfigBuilder</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-181.5 285.25,-181.5\"/>\n",
       "<text text-anchor=\"start\" x=\"90.12\" y=\"-164.2\" font-family=\"Times,serif\" font-size=\"14.00\">class_candidates</text>\n",
       "<text text-anchor=\"start\" x=\"90.12\" y=\"-147.7\" font-family=\"Times,serif\" font-size=\"14.00\">config</text>\n",
       "<text text-anchor=\"start\" x=\"90.12\" y=\"-131.2\" font-family=\"Times,serif\" font-size=\"14.00\">module_candidates</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-124 285.25,-124\"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-106.7\" font-family=\"Times,serif\" font-size=\"14.00\">build_callbacks_dict(): &#39;dict[str, pl.Callback]&#39;</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-90.2\" font-family=\"Times,serif\" font-size=\"14.00\">build_datamodule(): pl.LightningDataModule</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-73.7\" font-family=\"Times,serif\" font-size=\"14.00\">build_lightning_module(): pl.LightningModule</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">build_logger(): &#39;pl_loggers.LightningLoggerBase&#39;</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-40.7\" font-family=\"Times,serif\" font-size=\"14.00\">build_model(): &#39;torch.nn.Module&#39;</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-24.2\" font-family=\"Times,serif\" font-size=\"14.00\">build_profiler(): &#39;pl_profiler.Profiler&#39; or None</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-7.7\" font-family=\"Times,serif\" font-size=\"14.00\">build_trainer(): pl.Trainer</text>\n",
       "</g>\n",
       "<!-- my_tools.entrypoint.LightningConfigBuilder&#45;&gt;my_tools.utils.BuilderMixin -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>my_tools.entrypoint.LightningConfigBuilder&#45;&gt;my_tools.utils.BuilderMixin</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.62,-205.96C142.62,-216.54 142.62,-226.98 142.62,-236.73\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"139.13,-236.42 142.62,-246.42 146.13,-236.42 139.13,-236.42\"/>\n",
       "</g>\n",
       "<!-- my_tools.models.RegularizationGradientHook -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>my_tools.models.RegularizationGradientHook</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"559.25,-66.5 559.25,-140 732,-140 732,-66.5 559.25,-66.5\"/>\n",
       "<text text-anchor=\"start\" x=\"567.25\" y=\"-122.7\" font-family=\"Times,serif\" font-size=\"14.00\">RegularizationGradientHook</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"559.25,-115.5 732,-115.5\"/>\n",
       "<text text-anchor=\"start\" x=\"629.88\" y=\"-98.2\" font-family=\"Times,serif\" font-size=\"14.00\">decay</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"559.25,-91 732,-91\"/>\n",
       "<text text-anchor=\"start\" x=\"643.75\" y=\"-73.7\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "</g>\n",
       "<!-- my_tools.models.StoppingMonitor -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>my_tools.models.StoppingMonitor</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"750.12,-41.75 750.12,-164.75 883.12,-164.75 883.12,-41.75 750.12,-41.75\"/>\n",
       "<text text-anchor=\"start\" x=\"769.75\" y=\"-147.45\" font-family=\"Times,serif\" font-size=\"14.00\">StoppingMonitor</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"750.12,-140.25 883.12,-140.25\"/>\n",
       "<text text-anchor=\"start\" x=\"767.12\" y=\"-122.95\" font-family=\"Times,serif\" font-size=\"14.00\">impatience : int</text>\n",
       "<text text-anchor=\"start\" x=\"767.12\" y=\"-106.45\" font-family=\"Times,serif\" font-size=\"14.00\">lowest_loss : float</text>\n",
       "<text text-anchor=\"start\" x=\"767.12\" y=\"-89.95\" font-family=\"Times,serif\" font-size=\"14.00\">min_delta</text>\n",
       "<text text-anchor=\"start\" x=\"767.12\" y=\"-73.45\" font-family=\"Times,serif\" font-size=\"14.00\">patience</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"750.12,-66.25 883.12,-66.25\"/>\n",
       "<text text-anchor=\"start\" x=\"758.12\" y=\"-48.95\" font-family=\"Times,serif\" font-size=\"14.00\">is_time_to_stop(loss)</text>\n",
       "</g>\n",
       "<!-- my_tools.models.WandbLoggerMixin -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>my_tools.models.WandbLoggerMixin</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"901.5,-78.75 901.5,-127.75 1069.75,-127.75 1069.75,-78.75 901.5,-78.75\"/>\n",
       "<text text-anchor=\"start\" x=\"929.75\" y=\"-110.45\" font-family=\"Times,serif\" font-size=\"14.00\">WandbLoggerMixin</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"901.5,-103.25 1069.75,-103.25\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"901.5,-103.25 1069.75,-103.25\"/>\n",
       "<text text-anchor=\"start\" x=\"909.5\" y=\"-85.95\" font-family=\"Times,serif\" font-size=\"14.00\">log(dict_to_log: dict): None</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x10a355d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'tmp/packages.dot'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.5 (20230430.1635)\n",
       " -->\n",
       "<!-- Title: packages Pages: 1 -->\n",
       "<svg width=\"633pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 633.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>packages</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 629,-112 629,4 -4,4\"/>\n",
       "<!-- my_tools -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>my_tools</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"67,-36 0,-36 0,0 67,0 67,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"33.5\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">my_tools</text>\n",
       "</g>\n",
       "<!-- my_tools.entrypoint -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>my_tools.entrypoint</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"211.62,-36 85.38,-36 85.38,0 211.62,0 211.62,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.5\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">my_tools.entrypoint</text>\n",
       "</g>\n",
       "<!-- my_tools.utils -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>my_tools.utils</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"195.5,-108 101.5,-108 101.5,-72 195.5,-72 195.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.5\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">my_tools.utils</text>\n",
       "</g>\n",
       "<!-- my_tools.entrypoint&#45;&gt;my_tools.utils -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>my_tools.entrypoint&#45;&gt;my_tools.utils</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.5,-36.3C148.5,-44.1 148.5,-53.49 148.5,-62.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"148.5,-71.9 144,-61.9 148.5,-66.9 148.5,-61.9 148.5,-61.9 148.5,-61.9 148.5,-66.9 153,-61.9 148.5,-71.9 148.5,-71.9\"/>\n",
       "</g>\n",
       "<!-- my_tools.extra -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>my_tools.extra</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"327.38,-36 229.62,-36 229.62,0 327.38,0 327.38,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.5\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">my_tools.extra</text>\n",
       "</g>\n",
       "<!-- my_tools.models -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>my_tools.models</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"455.75,-36 345.25,-36 345.25,0 455.75,0 455.75,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"400.5\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">my_tools.models</text>\n",
       "</g>\n",
       "<!-- my_tools.sandbox_setup -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>my_tools.sandbox_setup</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"625,-36 474,-36 474,0 625,0 625,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"549.5\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">my_tools.sandbox_setup</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x10b18f910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 92;\n",
       "                var nbb_unformatted_code = \"display_uml_diagrams(\\\"/Users/dimakoshman/YSDA/my_tools/my_tools\\\")\";\n",
       "                var nbb_formatted_code = \"display_uml_diagrams(\\\"/Users/dimakoshman/YSDA/my_tools/my_tools\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_uml_diagrams(\"/Users/dimakoshman/YSDA/my_tools/my_tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ea834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:07:29.819713Z",
     "start_time": "2023-06-04T09:07:29.787144Z"
    }
   },
   "source": [
    "### Sort arxiv links <span id=Sort_arxiv_links_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea86aab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:22:46.795346Z",
     "start_time": "2023-09-01T08:22:46.784902Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "import re\n",
    "import sys\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def get_arxiv_id(arxiv_link: str) -> int:\n",
    "    arxiv_link_pattern = r\"https://arxiv\\.org/pdf/(?P<id>.+)\\.pdf\"\n",
    "    match = re.search(arxiv_link_pattern, arxiv_link)\n",
    "\n",
    "    if match is None:\n",
    "        message = f'Arxiv link \"{arxiv_link}\" doesn\\'t match expected pattern.'\n",
    "        print(message, file=sys.stderr)\n",
    "\n",
    "    arxiv_id = match.group(\"id\")\n",
    "    arxiv_id = int(arxiv_id.replace(\".\", \"\"))\n",
    "    return arxiv_id\n",
    "\n",
    "\n",
    "def sort_arxiv_links_by_time(arxiv_links: str or list[str]):\n",
    "    if isinstance(arxiv_links, str):\n",
    "        arxiv_links = arxiv_links.splitlines()\n",
    "\n",
    "    sorted_arxiv_links = sorted(arxiv_links, key=get_arxiv_id)\n",
    "    return \"\\n\".join(sorted_arxiv_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faec5832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:21:33.313148Z",
     "start_time": "2023-09-01T08:21:33.261166Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arxiv link \"sort_arxiv_links_by_time\" doesn't match expected pattern.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclipboard_io\u001b[49m\u001b[43m(\u001b[49m\u001b[43msort_arxiv_links_by_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m, in \u001b[0;36mclipboard_io\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclipboard_io\u001b[39m(function: Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     pyperclip\u001b[38;5;241m.\u001b[39mcopy(\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyperclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpaste\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m, in \u001b[0;36msort_arxiv_links_by_time\u001b[0;34m(arxiv_links)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arxiv_links, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     22\u001b[0m     arxiv_links \u001b[38;5;241m=\u001b[39m arxiv_links\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m---> 24\u001b[0m sorted_arxiv_links \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marxiv_links\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_arxiv_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sorted_arxiv_links)\n",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m, in \u001b[0;36mget_arxiv_id\u001b[0;34m(arxiv_link)\u001b[0m\n\u001b[1;32m     12\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArxiv link \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marxiv_link\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt match expected pattern.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(message, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m---> 15\u001b[0m arxiv_id \u001b[38;5;241m=\u001b[39m \u001b[43mmatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m arxiv_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(arxiv_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arxiv_id\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "clipboard_io(sort_arxiv_links_by_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129384cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T10:33:15.951628Z",
     "start_time": "2023-06-05T10:33:15.912638Z"
    }
   },
   "source": [
    "### Batched iterator <span id=Batched_iterator_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ae8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def batched(iterable, n) -> tp.Generator[list, None, None]:\n",
    "    \"\"\"\n",
    "    Batch data into tuples of length n. The last batch may be shorter.\n",
    "\n",
    "    batched('ABCDEFG', 3) --> ABC DEF G\n",
    "    \"\"\"\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be at least one.\")\n",
    "\n",
    "    it = iter(iterable)\n",
    "    while batch := list(itertools.islice(it, n)):\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede644e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T13:34:58.575861Z",
     "start_time": "2023-06-06T13:34:58.573223Z"
    }
   },
   "source": [
    "### Format .py and .ipynb files <span id=Format_.py_and_.ipynb_files_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c82eb97b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:20:43.709053Z",
     "start_time": "2023-09-01T08:20:43.700331Z"
    }
   },
   "outputs": [],
   "source": [
    "def black_format(path=\".\"):\n",
    "    !black {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542ee4fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T14:46:30.453458Z",
     "start_time": "2023-06-06T14:46:30.415711Z"
    }
   },
   "source": [
    "### Redraw figure in IPython <span id=Redraw_figure_in_IPython_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def redraw_figure():\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    IPython.display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26315c3",
   "metadata": {},
   "source": [
    "### Torch training and evaluating pipeline template <span id=Torch_training_and_evaluating_pipeline_template_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "@dataclasses.dataclass(kw_only=True)\n",
    "class Config:\n",
    "    is_debugging:bool = True\n",
    "    ...\n",
    "        \n",
    "        \n",
    "def is_debugging() -> bool:\n",
    "    return Config.is_debugging\n",
    "\n",
    "\n",
    "def metric(...):\n",
    "    ...\n",
    "\n",
    "    \n",
    "class LightningModule(pl.LightningModule):\n",
    "    def __init__(self, ...):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        ...\n",
    "\n",
    "    def forward(self, ...):\n",
    "        preds = ...\n",
    "        return preds\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_id):\n",
    "        preds = self(...)\n",
    "        loss = ...\n",
    "        self.log(\"loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_id):\n",
    "        preds = self(...)\n",
    "        ...\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer\n",
    "    \n",
    "\n",
    "def main(**kwargs):\n",
    "    wandb.init(config= ..., project=...)\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=...,\n",
    "        shuffle=True,\n",
    "        batch_size=...,\n",
    "    )\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=...,\n",
    "        batch_size=...,\n",
    "    )\n",
    "    early_stopping_callback = pl.callbacks.EarlyStopping(\n",
    "        monitor=...,\n",
    "        mode=...,\n",
    "        min_delta=...,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=...,\n",
    "        devices=...,\n",
    "        logger=pl.loggers.WandbLogger(),\n",
    "        callbacks=[\n",
    "            early_stopping_callback,\n",
    "            ...,\n",
    "        ],\n",
    "        val_check_interval=...,\n",
    "        accumulate_grad_batches=...,\n",
    "        fast_dev_run=...,\n",
    "    )\n",
    "    model = LightningModule(...)\n",
    "    trainer.fit(\n",
    "        model=...,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040876d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:29:57.193379Z",
     "start_time": "2023-09-01T08:29:57.163903Z"
    }
   },
   "source": [
    "### Time it <span id=Time_it_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbbb249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def time_it(name: str = \"\", file=sys.stderr):\n",
    "    begin = time.perf_counter()\n",
    "    yield\n",
    "    end = time.perf_counter()\n",
    "    name = name or name + \":\\t\"\n",
    "    delta_ms = 1000 * (end - begin)\n",
    "    print(f\"{name}{delta_ms:.3f} ms\", file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17189d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:33:31.126955Z",
     "start_time": "2023-09-01T08:33:31.091345Z"
    }
   },
   "source": [
    "### Video <span id=Video_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b6182b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:34:08.387589Z",
     "start_time": "2023-09-01T08:34:08.005291Z"
    }
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import imageio\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def build_background_video(\n",
    "    n_frames: int,\n",
    "    width: int = 300,\n",
    "    height: int = 300,\n",
    "    n_channels: int = 3,\n",
    "    color: tuple[int] = (0, 0, 0),\n",
    ") -> np.ndarray:\n",
    "    video = np.full(\n",
    "            shape=[n_frames, width, height, n_channels],\n",
    "            fill_value=color,\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "    return video\n",
    "\n",
    "        \n",
    "def write_gif(uri: str, images: np.ndarray, fps=30) -> None | bytes:\n",
    "    encoded_image = imageio.v3.imwrite(uri, images, loop=0, duration=len(images) / fps)\n",
    "    return encoded_image\n",
    "\n",
    "\n",
    "def display_video(video: np.ndarray) -> None:\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".gif\") as gif:\n",
    "        filename = gif.name\n",
    "        write_gif(filename, video)\n",
    "        IPython.display.display(IPython.display.Image(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80163558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T10:13:06.546842Z",
     "start_time": "2023-10-19T10:13:06.541635Z"
    }
   },
   "source": [
    "### Algorithms <span id=Algorithms_></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d6713e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T10:39:20.564119Z",
     "start_time": "2023-10-19T10:39:20.556122Z"
    }
   },
   "outputs": [],
   "source": [
    "def argsort(values):\n",
    "    return sorted(range(len(values)), key=values.__getitem__)\n",
    "\n",
    "def binsearch(low, high, do_search_less_than):\n",
    "    while low + 1 < high:\n",
    "        mid = (low + high) // 2\n",
    "        if do_search_less_than(mid):\n",
    "            high = mid\n",
    "        else:\n",
    "            low = mid\n",
    "    return low\n",
    "\n",
    "class BinaryIndexedTree:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.tree = [0] * (size + 1)\n",
    "        \n",
    "    def update(self, i, value):\n",
    "        while i <= self.size:\n",
    "            self.tree[i] += value\n",
    "            i += i & -i\n",
    "            \n",
    "    def get_prefix_sum(self, i):\n",
    "        prefix_sum = 0\n",
    "        while i:\n",
    "            prefix_sum += self.tree[i]\n",
    "            i -= i & -i\n",
    "        return prefix_sum\n",
    "    \n",
    "# Todo: quicksort, mergesort, dfs, bfs, trie, balanced search tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52012872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T08:25:29.926671Z",
     "start_time": "2023-05-24T08:25:29.890472Z"
    }
   },
   "source": [
    "## Modules <span id=Modules_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0429f4",
   "metadata": {},
   "source": [
    "### Dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3a448865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T17:54:41.223656Z",
     "start_time": "2023-05-31T17:54:41.215287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 137;\n",
       "                var nbb_unformatted_code = \"from dataclasses import dataclass, field\\n\\n\\n@dataclass\\nclass InventoryItem:\\n    \\\"\\\"\\\"Class for keeping track of an item in inventory.\\\"\\\"\\\"\\n\\n    name: str\\n    unit_price: float\\n    quantity_on_hand: int = 0\\n\\n    def total_cost(self) -> float:\\n        return self.unit_price * self.quantity_on_hand\";\n",
       "                var nbb_formatted_code = \"from dataclasses import dataclass, field\\n\\n\\n@dataclass\\nclass InventoryItem:\\n    \\\"\\\"\\\"Class for keeping track of an item in inventory.\\\"\\\"\\\"\\n\\n    name: str\\n    unit_price: float\\n    quantity_on_hand: int = 0\\n\\n    def total_cost(self) -> float:\\n        return self.unit_price * self.quantity_on_hand\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InventoryItem:\n",
    "    \"\"\"Class for keeping track of an item in inventory.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    unit_price: float\n",
    "    quantity_on_hand: int = 0\n",
    "\n",
    "    def total_cost(self) -> float:\n",
    "        return self.unit_price * self.quantity_on_hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe7252",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T08:34:56.862641Z",
     "start_time": "2023-05-24T08:34:56.855344Z"
    }
   },
   "source": [
    "### Parsimonious <span id=Parsimonious_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446b20f",
   "metadata": {},
   "source": [
    "[Parsimonious](https://github.com/erikrose/parsimonious) - a more explicit `re` alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d3faa4",
   "metadata": {},
   "source": [
    "### Gradio <span id=Gradio_></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b785d423",
   "metadata": {},
   "source": [
    "setting ssh flag:\n",
    "`-L 7860:localhost:7860`\n",
    "enables gradio interfaces from remote machines without share=True, as `7860` is the default port."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b697cff",
   "metadata": {},
   "source": [
    "### graph-tool <span id=graph-tool_></span>\n",
    "\n",
    "Graph based algorithms and operations.\n",
    "\n",
    "https://graph-tool.skewed.de/static/doc/quickstart.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f6523",
   "metadata": {},
   "source": [
    "### Ray <span id=Ray_></span>\n",
    "\n",
    "https://wandb.ai/authors/RayTune-dcgan/reports/Ray-Tune-Distributed-Hyperparameter-Optimization-at-Scale--VmlldzoyMDEwNDY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e559e41d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T09:54:39.094162Z",
     "start_time": "2023-06-01T09:54:39.077817Z"
    }
   },
   "source": [
    "### Seaborn <span id=Seaborn_></span>\n",
    "\n",
    "Higher level matplotlib\n",
    "\n",
    "https://seaborn.pydata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e1a16",
   "metadata": {},
   "source": [
    "### Bokeh <span id=Bokeh_></span>\n",
    "\n",
    "Interactive plots\n",
    "\n",
    "http://bokeh.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7926bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
