{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кошман Дмитрий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OMhb9pZtnQ8P"
   },
   "source": [
    "# Разбор статьи по машинному обучению\n",
    "\n",
    "Количество баллов: 8 баллов\n",
    "\n",
    "В этой лабораторной вам предстоит выбрать и разобрать статью, поделиться с нами тем, что вам удалось понять в ней. Прежде всего, вам предстоит ответить на общие вопросы:\n",
    "\n",
    "1. Какую задачу решают авторы? (не более 200 слов)\n",
    "\n",
    "2. Какова основная идея предлагаемого авторами решения поставленной задачи? (не более 300 слов)\n",
    "\n",
    "3. Каковы результаты, полученные авторами? (оформите в виде списка, не более 200 слов)\n",
    "\n",
    "Разбор должен быть написан на русском языке, при этом требования по числу слов довольно жёсткие: если, например, ответ на первый вопрос будет содержать больше 200 слов, то мы оценим только первые 200) Это требование возникло не потому, что мы не хотим много читать (хотя, наверное, в этом тоже есть своя правда). Но если вы просто переведёте на русский\n",
    "язык исходную статью, это будет для вас не слишком полезно. Пожалуйста, постарайтесь качественно вникнуть в происходящее и не упустить связи между целями авторов, их изобретениями и полученными результатами.\n",
    "\n",
    "Вот несколько примеров того, как надо и как не надо делать:\n",
    "\n",
    " * Сама по себе новая архитектура нейронной сети не является результатом. Это лишь средство для достижения результата. Результат обычно измеряется числами.\n",
    " * Не пишите просто «авторы получили качество в 38 BLEU», ведь не в этом дело. Возможно, им удалось превзойти все существующие архитектуры, или архитектуры из определённого класса, или им не удалось никого превзойти, но они просто хорошо провели время, греясь у работающих GPU (хорошо им!). Авторы явно преследовали какую-то цель, и они должны были показать, что в какой-то мере достигли её, а то бы их статью не приняли на конференцию.\n",
    " * Наверное, иллюстрации мы не будем переводить в слова, так что добавляйте их при необходимости, но это не значит, что мы открываем конкурс «скажи это картинками» :) Картинка должна содержательно иллюстрировать что-то в тексте вашего разбора.\n",
    " * Старайтесь соблюдать баланс между формулами и сутью. С одной стороны, важно, чтобы вы объясняли смыслы, стоящие за формулами. Например, не надо, пожалуйста, определять механизм внимания, как куча формул + непонятная картинка из статьи Bahdanau. Механизм внимания — это в первую очередь способ использовать не только скрытое состояние декодера, но и информацию о каждом токене в исходной последовательности. Поверьте, везде за формулами стоит какая-то (пусть даже порой и немного извращённая) логика, и вам нужно её раскрыть! С другой стороны, одни общие слова без конкретики (которую чаще всего воплощают формулы) тоже бессильны.\n",
    "\n",
    "Помимо общих вопросов, нужно ответить на ряд специфических для каждой статьи вопросов, которые написаны ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Статья 1**\n",
    "\n",
    "Прочитайте статью MobileNets: [Effcient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/pdf/1704.04861.pdf). Опишите структуру __Depthwise Separable Convolution__ слоя и расскажите, сколько в нём параметров. Почему это всё ещё работает, несмотря на очень существенное огрубление тензорных операций?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1. Какую задачу решают авторы?\n",
    "\n",
    "Авторы предлагают новую легковесную и эффективную архитектуру нейросети для компьютерного зрения под названием MobileNet. Они решили заполнить нишу спроса, где скорость стоит на первом месте и существуют сильные ограничения на доступную вычислительную мощность. В первую очередь они видят применение MobileNet на мобильных устройствах для решения задач узнавания, детекции и классификации объектов на изображениях. В общем авторы хотят предоставить максимально практичную нейросеть для данных задач.\n",
    "\t\n",
    "\n",
    "\n",
    "2. Какова основная идея предлагаемого авторами решения поставленной задачи?\n",
    "\n",
    "\t\n",
    "Для достижения эффективности авторы решили факторизовать проверенный опытом сверточный слой на два отдельных - depthwise и pointwise слои.\n",
    "\t\n",
    "Структура по слоям :\n",
    "\t\n",
    "$$DepthwiseConv \\rightarrow BatchNorm \\rightarrow ReLU \\rightarrow PointwiseConv \\rightarrow BatchNorm \\rightarrow ReLU$$\n",
    "\t\n",
    "Depthwise слой имеет ядро размера $in\\_channels \\times K \\times K$ и разбивает входное изображение размера $batch \\times in\\_channels \\times H \\times W$ на группы по каналам и применяет к каждой группе обычную одномерную свертку, затем конкатенирует результаты.\n",
    "\t\n",
    "Pointwise слой -- это обычная свертка с ядром $out\\_channels \\times in\\_channels \\times 1 \\times 1$\n",
    "\t\n",
    "В таком виде количество вычислений падает с $H \\cdot W \\cdot in\\_channels \\cdot out\\_channels \\cdot K^2$ до $H \\cdot W \\cdot in\\_channels \\cdot ( K^2 + out\\_channels) $, то есть примерно в $K^2$ раз.\n",
    "\n",
    "А для достижения практичности авторы  предоставляют два гиперпараметра, дающих контроль над скоростью и размером сети за счет регулирования количества каналов в скрытых слоях и сжатия исходного изображения.\n",
    "\n",
    "Почему это работает, несмотря на огрубление тензорных операций? Потому что здесь используется тот же принцип, за счет которого свертка и показывает хорошие результаты - поиск pattern в изображении и агрегирование результатов поиска по всем каналам в новые, более абстрактные признаки. \n",
    "\n",
    "\n",
    "3. Каковы результаты, полученные авторами?\n",
    "\n",
    "- На данных ImageNet: по сравнению с обычной сверткой получили ускорение и уменьшение в пять раз за счет падения точности на $1\\%$\n",
    "- Экспериментально показали, что глубокая сеть работает немного лучше, чем широкая с тем же количеством параметров.\n",
    "- Показали, что качество модели лог-линейно зависит от количества базовых операций.\n",
    "- Добились одинаково качества с моделью $VGG 16$, затрачивая в 30 раз меньше времени и памяти.\n",
    "- Показали незначительное отставание от лучших моделей за счет значительно уменьшения затрат по задачам геолокации, узнавания лиц, детекции.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Статья 2**\n",
    "\n",
    "Прочитайте статью [Spherical CNNs](https://arxiv.org/pdf/1801.10130.pdf) и ответьте на вопросы:\n",
    "\n",
    "1. В чём смысл понятия эквивариантности? Нет, просто формулу не зачтём :) В чём смысл? Являются ли обычные свёртки эквивариантными к каким-либо преобразованиям?\n",
    "\n",
    "2. Зачем нужны и чем отличаются __Spherical Correlation__ и __Rotation Group Correlation__?\n",
    "\n",
    "3. Если мы хотим решать задачу классификации или регрессии, нам нужно, чтобы голова сети предсказывала числа или логиты. Как это сделать, если внутри сети возникают всякие сферические свёртки?\n",
    "\n",
    "4. Постарайтесь объяснить своими словами, как авторы предлагают эффективно вычислять Spherical Correlation или Rotation Group Correlation (достаточно, если объясните одну из них).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1. Какую задачу решают авторы?\n",
    "\n",
    "Авторы хотят, чтобы в арсенале машинного обучения были эффективные методы работы со сферическими изображениями, которые возникают в таких задачах, как зрение роботов и глобальное предсказание погоды.\n",
    "\n",
    "Сверточные сети, которые хорошо справляются с аналогичными задачами для изображений в прямолинейных координатах, плохо переносятся на сферические изображения, так как не существует изоморфного преобразования для дискретных представлений соответствующих изображений. Поэтому возникает желание перенести принцип, благодаря которому работают сверточные сети - инвариантность класса относительно движений плоскости - на изображения в сферических координатах.\n",
    "\n",
    "Такое обобщение можно сделать с помощью понятия эквивариантности - нахождения таких эквивариантных  преобразований, которые перестановочны с интересуемой нас группой симметрии. В случае с двумерными изображениями таковыми являются свертки относительно движений. Хочется найти соответсвующие сферические свертки относительно ортогональной группы преобразований, сохраняющих ориентацию.\n",
    "\n",
    "\n",
    "2. Какова основная идея предлагаемого авторами решения поставленной задачи?\n",
    "\n",
    "\n",
    "Сначала вводится понятие сферической корреляции и корреляции группы ротаций, а потом полученные чисто математические выводы переносятся на практическую реализацию в виде нейронной сети со сферическими свертками.\n",
    "\n",
    "Как понимать сферическую корреляцию и зачем она нужна? Для двух фиксированных сферических изображений их сферическая корреляция - это функция, отображающая элемент группы ротации в меру похожести изображений, если к первому применить данную ротацию. Она интересна нам тем, что если два изображения содержат один и тот же объект в различных ориентациях, то максимум сферической корреляции достигается в ротации, которая соответствует разнице между истинными ориентациями. Корреляция группы ротаций это то же самое, но не для изображений, а для ротаций. То есть ее максимум для ротаций $R_1$ и $R_2$ достигается в ротации, переводящей $R_1$ в $R_2$. К обеим корреляциями можно применить градиентные методы, позволяющие приближенно находить эти максимумы. Причем если изображения содержат одинаковый объект, то сферическая корреляция будет иметь большой пик в точке, соответствующей истинной ротации, что позволит точно определить, что изображения из одного класса.\n",
    "\n",
    "Как преобразовывать выход сферической свертки в виде числа? Выход слоя сферической свертки - элемент группы $SO(3)$, который дискретно представим в трехмерных угловых координатах Эйлера, то есть обычного тензора, и здесь работают те же методы агрегации, как для обычной свертки.\n",
    "\n",
    "Наивная имплементация ротационной свертки будет работать с трехмерными матрицами, то есть иметь сложность порядка $O(n^6)$.  Авторы показали, что элементы группы ротаций удовлетворяют требованиям теоремы Фурье, что позволяет представить корреляцию в виде скалярного произведения трансформированных преобразований. Используя это, и возможность вычисления преобразования Фурье за $O(n\\log n)$, общая сложность падает до $O(n^4 \\log^2 n)$.\n",
    "\n",
    "\n",
    "3. Каковы результаты, полученные авторами?\n",
    "\n",
    "\n",
    "- Авторы показали, что практически воплощенные модели отличаются от чистых математических на погрешность, растущую логарифмически относительно разрешения изображения и линейно относительно глубины модели.\n",
    "- На данных MNIST, не подвергнутых ротации, сферические свертки показывали такое же качество, как обычные. На повернутых же изображениях сферические свертки сохранили качество, тогда как обычные работали не лучше случайного предсказания.\n",
    "- На данных ShapeNet сферические свертки показали качество немного хуже лидеров, причем не потребовав точного подбора параметров и ad-hoc изменений в архитектуре.\n",
    "- В задаче QM7 сферические свертки хорошо предсказали потенциальную энергию молекулы, уступив по качеству только лидеру, которому потребовалась существенная предобработка данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Статья 3**\n",
    "\n",
    "Прочитайте статью [Swin Transformer](https://arxiv.org/abs/2103.14030)\n",
    "\n",
    "1. Опишите, в чем состоит основное преимущество иерархической структуры трансформера над обычной? Как авторы Swin Transformer делают его иерархическим? Опишите, как полученную архитектуру можно использовать для сегментации изображений, как иерархическая структура тут помогает?\n",
    "\n",
    "2. Опишите модификацию оконного внимания в Swin Transformer. Подробно опишите как это меняет сложность вычисления слоя внимания. За счёт чего при этом получается сохранить глобальные зависимости между разными частями картинки?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1. Какую задачу решают авторы?\n",
    "\n",
    "Авторы отмечают, что на момент написания статьи в доменах компьютерного зрения и лингвистического восприятия доминируют разные модели машинного обучения - сверточные сети и трансформеры соответственно. Эти особенности приводят к тому, что эти две области развиваются относительно параллельно и независимо, и между ними происходит меньше обмена знаниями, чем авторам представляется возможным. Поэтому авторы решают разработать архитектуру Swin Transformer - которая будет основана на трансформерах но быть достаточно гибкой и эффективной, чтобы ее можно было брать за основу для решения большинства задач из области изображений и текста.\n",
    "\n",
    "\n",
    "2. Какова основная идея предлагаемого авторами решения поставленной задачи?\n",
    "\n",
    "Основные две проблемы при использовании обычного трансформера в задачах зрения - это то, что токены в изображениях могут сильно отличаться по шкале, и квадратичная сложность вычисления внимания по размеру изображения.\n",
    "\n",
    "Идея решения первой проблемы - построение модели в виде иерархической структуры, начиная с непересекающихся патчей шириной в несколько пикселей, постепенно сливая соседние патчи, тем самым уменьшая рамширение и переходя к распознаванию все более крупных объектов. Возможность распознавать объекты размером порядка десятка пикселей особенно важна для задач сегментации изображений, а использование обычного трансформера с таким расширением было бы слишком вычислитеьлно затратно.\n",
    "\n",
    "Идея решения второй проблемы - ограничение вычисления внимания внутри каждого окна, состоящего из $M\\times M$ патчей, что приводит к линейной сложности по размеру изображения $H\\times W$:\n",
    "\n",
    "$$\\text{сложность вычисления обычного внимания} \\approx (HW)^2   $$\n",
    "\n",
    "$$\\text{сложность вычисления внимания Swin} \\approx M^2HW   $$\n",
    "\n",
    "\n",
    "А чтобы не терять информацию между непересекающимися окнами, после каждого слоя производится сдвиг окон на половину ширины одного окна, тем самым обеспечивая поток информации между соседними патчами.\n",
    "\n",
    "\n",
    "3. Каковы результаты, полученные авторами?\n",
    "\n",
    "- Swin Transformer показал результаты, сравнимые с текущими лучшими по качеству и времени обучения, на таких задачах, как классификация изображений, детектирование объектов и семантическая сегментация.\n",
    "- На датасете ImageNet-1K стандартная версия Swin Transformer показала точность, сравнимую с оптимизированными версиями DeiT, EfficientNet и RegNet.\n",
    "- На датасете COCO Swin Transformer отличился особенно быстрым временем предсказания, связанным с линейной сложностью по размеру изображений."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bike_Rentals (Regression)",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f98f21f0b58c314391d9edda6a890b43799e7bbdcfa23cfcf4ab03be958beb23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
