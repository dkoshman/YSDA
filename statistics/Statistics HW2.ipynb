{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "801977db",
   "metadata": {},
   "source": [
    "### Кошман Дмитрий\n",
    "\n",
    "$\\newcommand{\\Sum}{\\sum\\limits}\n",
    "\\newcommand{\\Int}{\\int\\limits}\n",
    "\\newcommand{\\Intf}{\\int\\limits_{-\\infty}^{+\\infty}}\n",
    "\\newcommand{\\Prod}{\\prod\\limits}\n",
    "\\newcommand{\\Max}{\\max\\limits}\n",
    "\\newcommand{\\Min}{\\min\\limits}\n",
    "\\newcommand{\\Lim}{\\lim\\limits}\n",
    "\\newcommand{\\Var}{\\mathbb{V}}\n",
    "\\newcommand{\\Exp}{\\mathbb{E}}\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\argmax}{\\arg\\max}\n",
    "\\newcommand{\\Cov}{\\text{Cov}}\n",
    "\\newcommand{\\makebold}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\newcommand{\\mean}[1]{\\overline{#1}}\n",
    "\\newcommand{\\avg}[1]{\\langle #1 \\rangle}\n",
    "\\newcommand{\\angmean}[1]{\\langle #1 \\rangle}\n",
    "\\newcommand{\\Prob}{\\mathcal{P}}\n",
    "\\newcommand{\\se}{\\text{se}}\n",
    "\\newcommand{\\lp}{\\left}\n",
    "\\newcommand{\\rp}{\\right}\n",
    "\\newcommand{\\boldx}{\\boldsymbol{x}}\n",
    "\\newcommand{\\boldy}{\\boldsymbol{y}}\n",
    "\\newcommand{\\boldz}{\\boldsymbol{z}}\n",
    "\\newcommand{\\boldX}{\\boldsymbol{X}}\n",
    "\\newcommand{\\boldY}{\\boldsymbol{Y}}\n",
    "\\newcommand{\\boldZ}{\\boldsymbol{Z}}\n",
    "\\newcommand{\\Poisson}{\\mathrm{Poisson}}\n",
    "\\newcommand{\\Triangle}{\\mathrm{Triangle}}\n",
    "\\newcommand{\\Uniform}{\\mathrm{Uniform}}\n",
    "\\newcommand{\\Binomial}{\\mathrm{Binomial}}\n",
    "\\newcommand{\\Bernoulli}{\\mathrm{Bernoulli}}\n",
    "\\newcommand{\\Gammap}{\\mathrm{Gamma}}\n",
    "\\newcommand{\\Normal}{\\mathcal{N}}\n",
    "\\newcommand{\\LogN}{\\mathrm{LogN}}\n",
    "\\newcommand{\\Exponential}{\\mathrm{Exp}}\n",
    "\\newcommand{\\Erlang}{\\mathrm{Erlang}}\n",
    "\\newcommand{\\Cauchy}{C}\n",
    "\\newcommand{\\Dir}{\\mathrm{Dir}}\n",
    "\\newcommand{\\Beta}{\\mathrm{Beta}}\n",
    "\\newcommand{\\Pareto}{\\mathrm{Pareto}}\n",
    "\\newcommand{\\lf}{\\left\\{}\n",
    "\\newcommand{\\rf}{\\right\\}}\n",
    "\\newcommand{\\lp}{\\left(}\n",
    "\\newcommand{\\rp}{\\right)}\n",
    "\\newcommand{\\Ecdf}[1]{\\hat{F}_n(#1)}\n",
    "\\newcommand{\\OPT}{\\text{OPT}}\n",
    "\\newcommand{\\opt}{\\text{opt}}\n",
    "\\newcommand{\\boot}{\\text{boot}}\n",
    "\\newcommand{\\bias}{\\text{bias}}\n",
    "\\newcommand{\\se}{\\text{se}}\n",
    "\\newcommand{\\MSE}{\\text{MSE}}\n",
    "\\newcommand{\\qm}{\\text{qm}}\n",
    "\\newcommand{\\as}{\\text{as}}\n",
    "\\newcommand{\\trace}{\\text{trace}}\n",
    "\\newcommand{\\esttheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\estlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\estmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\estsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\estalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\estbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\estxi}{\\hat{\\xi}}\n",
    "\\newcommand{\\esttau}{\\hat{\\tau}}\n",
    "\\newcommand{\\estpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\esta}{\\hat{a}}\n",
    "\\newcommand{\\estb}{\\hat{b}}\n",
    "\\newcommand{\\estc}{\\hat{c}}\n",
    "\\newcommand{\\estd}{\\hat{d}}\n",
    "\\newcommand{\\estp}{\\hat{p}}\n",
    "\\newcommand{\\estT}{\\hat{T}}\n",
    "\\newcommand{\\estR}{\\hat{R}}\n",
    "\\newcommand{\\estF}{\\hat{F}}\n",
    "\\newcommand{\\estf}{\\hat{f}}\n",
    "\\newcommand{\\estC}{\\hat{C}}\n",
    "\\newcommand{\\estS}{\\hat{S}}\n",
    "\\newcommand{\\estY}{\\hat{Y}}\n",
    "\\newcommand{\\esty}{\\hat{y}}\n",
    "\\newcommand{\\estVar}{\\hat{\\Var}}\n",
    "\\newcommand{\\estExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\estSe}{\\hat{\\se}}\n",
    "\\newcommand{\\hatp}{\\hat{p}}\n",
    "\\newcommand{\\hatF}{\\hat{F}}\n",
    "\\newcommand{\\hatT}{\\hat{T}}\n",
    "\\newcommand{\\hattheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\hatse}{\\hat{\\se}}\n",
    "\\\n",
    "\\newcommand{\\MLE}{\\text{MLE}}\n",
    "\\newcommand{\\mlexi}{\\xi_{MLE}}\n",
    "\\newcommand{\\mletheta}{\\theta_{MLE}}\n",
    "\\newcommand{\\mlelambda}{\\lambda_{MLE}}\n",
    "\\newcommand{\\mlesigma}{\\sigma_{MLE}}\n",
    "\\newcommand{\\mlepsi}{\\psi_{MLE}}\n",
    "\\newcommand{\\mlemu}{\\mu_{MLE}}\n",
    "\\newcommand{\\mlenu}{\\nu_{MLE}}\n",
    "\\\n",
    "\\newcommand{\\tilx}{\\tilde{x}}\n",
    "\\newcommand{\\tily}{\\tilde{y}}\n",
    "\\newcommand{\\tilX}{\\tilde{X}}\n",
    "\\newcommand{\\tilY}{\\tilde{Y}}\n",
    "\\newcommand{\\tilK}{\\tilde{K}}\n",
    "\\newcommand{\\tilU}{\\tilde{U}}\n",
    "\\newcommand{\\tilV}{\\tilde{V}}\n",
    "\\newcommand{\\tilSigma}{\\tilde{\\Sigma}}\n",
    "\\newcommand{\\tiltau}{\\tilde{\\tau}}\n",
    "\\newcommand{\\tiltheta}{\\tilde{\\theta}}\n",
    "\\newcommand{\\tillambda}{\\tilde{\\lambda}}\n",
    "\\newcommand{\\tilsigma}{\\tilde{\\sigma}}\n",
    "\\newcommand{\\tilpsi}{\\tilde{\\psi}}\n",
    "\\newcommand{\\tilmu}{\\tilde{\\mu}}\n",
    "\\\n",
    "\\newcommand{\\esttheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\estlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\estmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\estsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\estalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\estbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\estxi}{\\hat{\\xi}}\n",
    "\\newcommand{\\esttau}{\\hat{\\tau}}\n",
    "\\newcommand{\\estpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\esta}{\\hat{a}}\n",
    "\\newcommand{\\estb}{\\hat{b}}\n",
    "\\newcommand{\\estc}{\\hat{c}}\n",
    "\\newcommand{\\estd}{\\hat{d}}\n",
    "\\newcommand{\\estf}{\\hat{f}}\n",
    "\\newcommand{\\estp}{\\hat{p}}\n",
    "\\newcommand{\\esty}{\\hat{y}}\n",
    "\\newcommand{\\estT}{\\hat{T}}\n",
    "\\newcommand{\\estR}{\\hat{R}}\n",
    "\\newcommand{\\estF}{\\hat{F}}\n",
    "\\newcommand{\\estC}{\\hat{C}}\n",
    "\\newcommand{\\estS}{\\hat{S}}\n",
    "\\newcommand{\\estY}{\\hat{Y}}\n",
    "\\newcommand{\\estVar}{\\hat{\\Var}}\n",
    "\\newcommand{\\estExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\estSe}{\\hat{\\se}}\n",
    "\\\n",
    "\\newcommand{\\ecdf}{\\hat{F}}\n",
    "\\\n",
    "\\newcommand{\\hata}{\\hat{a}}\n",
    "\\newcommand{\\hatb}{\\hat{b}}\n",
    "\\newcommand{\\hatc}{\\hat{c}}\n",
    "\\newcommand{\\hatd}{\\hat{d}}\n",
    "\\newcommand{\\hatf}{\\hat{f}}\n",
    "\\newcommand{\\hatg}{\\hat{g}}\n",
    "\\newcommand{\\hatk}{\\hat{k}}\n",
    "\\newcommand{\\hatp}{\\hat{p}}\n",
    "\\newcommand{\\hatr}{\\hat{r}}\n",
    "\\newcommand{\\hatt}{\\hat{t}}\n",
    "\\newcommand{\\haty}{\\hat{y}}\n",
    "\\newcommand{\\hatw}{\\hat{w}}\n",
    "\\\n",
    "\\newcommand{\\hatC}{\\hat{C}}\n",
    "\\newcommand{\\hatF}{\\hat{F}}\n",
    "\\newcommand{\\hatJ}{\\hat{J}}\n",
    "\\newcommand{\\hatK}{\\hat{K}}\n",
    "\\newcommand{\\hatP}{\\hat{P}}\n",
    "\\newcommand{\\hatS}{\\hat{S}}\n",
    "\\newcommand{\\hatT}{\\hat{T}}\n",
    "\\newcommand{\\hatY}{\\hat{Y}}\n",
    "\\newcommand{\\hatV}{\\hat{V}}\n",
    "\\newcommand{\\hatU}{\\hat{U}}\n",
    "\\\n",
    "\\newcommand{\\hateps}{\\hat{\\eps}}\n",
    "\\newcommand{\\hatalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\hatbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\hatpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\hatlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\hattheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\hatsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\hatmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\hatnu}{\\hat{\\nu}}\n",
    "\\newcommand{\\hatSigma}{\\hat{\\Sigma}}\n",
    "\\newcommand{\\hatSe}{\\hat{\\se}}\n",
    "\\newcommand{\\hatExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\hatVar}{\\hat{\\Var}}\n",
    "\\\n",
    "\\newcommand{\\RejectRegion}{R}\n",
    "\\newcommand{\\pvalue}{\\text{p-value}}\n",
    "\\newcommand{\\llr}{\\ell}\n",
    "\\newcommand{\\Llr}{\\mathcal{L}}\n",
    "\\\n",
    "\\newcommand{\\Distr}{\\mathsf{D}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f33b7",
   "metadata": {},
   "source": [
    "### [Задача 1 [4 балла]](#Задача-1)\n",
    "\n",
    "Пусть $n_1$ --- количество людей, которые получили лечение по методике 1, а $n_2$ --- количество людей, которые получили лечение по методике 2. Обозначим через $X_1$ --- количество людей, получивших лечение по методике 1, на которых эта методика повлияла положительно. Аналогично, обозначим через $X_2$ --- количество людей, получивших лечение по методике 2, на которых эта методика повлияла положительно. Предположим, что $X_1 \\sim \\Binomial(n_1,p_1)$ и $X_2\\sim \\Binomial(n_2,p_2)$. Положим $\\psi = p_1-p_2$.\n",
    "\n",
    "1. Найдите MLE-оценку $\\mlepsi$ для параметра $\\psi$.\n",
    "1. Найдите информационную матрицу Фишера $I(p_1,p_2)$.\n",
    "1. Используя многопараметрический дельта-метод найдите асимптотическую стандартную ошибку для $\\mlepsi$.\n",
    "1. Допустим, что $n_1=n_2=200$, и конкретные значения случайных величин $X_1$ и $X_2$ равны $160$ и $148$ соответственно. Чему в этом случае равна оценка  $\\mlepsi$. Найдите приблизительный (асимптотический) 90\\%-ый доверительный интервал для $\\psi$, используя (а) многопараметрический дельта-метод и (б) параметрический бутстреп.\n",
    "\n",
    "### [Задача 2 [2 балла]](#Задача-2)\n",
    "\n",
    "Пусть $\\boldX =\\{X_1,\\ldots,X_n\\} \\sim \\Poisson(\\lambda)$.\n",
    "\n",
    "1. Постройте оценки $\\tillambda$ параметра $\\lambda$ с помощью метода моментов с использованием пробных функций $g_1(x) = x$ и $g_2(x) = x^2$.\n",
    "1. Постройте оценку $\\hatlambda$ параметра $\\lambda$ с помощью метода максимального правдоподобия. Найдите информацию Фишера $I_{X}(\\lambda)$. Является ли оценка $\\hatlambda$ эффективной?\n",
    "\n",
    "### [Задача 3 [4 балла]](#Задача-3)\n",
    "Пусть $\\boldX =\\{X_1,\\dots,X_n\\} \\sim \\Pareto(\\theta, \\nu)$, $\\theta > 0$, $\\nu > 0$, с функцией плотности\n",
    "$$\n",
    "f_{\\theta, \\nu}(x) =\n",
    "\\begin{cases}\n",
    "\t\\frac{\\theta\\nu^{\\theta}}{x^{\\theta+1}}, \\quad & x \\ge \\nu,\\\\\n",
    "\t0, \\quad & x < \\nu\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "1. Найдите MLE-оценки $\\hattheta$ и $\\hat \\nu$ для параметров $\\theta$ и $\\nu$.\n",
    "1. Пусть параметр $\\nu$ известен. Найдите истинные значения $\\Exp_{\\theta}[\\hat{\\theta}]$ и $\\Var_{\\theta}[\\hat{\\theta}]$ как функции параметров $\\theta$, $\\nu$ и размера выборки $n$.\n",
    "Подсказка: следует использовать тот факт, что логарифм от случайной величины с распределением Парето имеет экспоненциальное распределение.\n",
    "1. Пусть параметр $\\nu$ известен. Найдите асимптотическое распределение оценки $\\hattheta$ с помощью дельта-метода.\n",
    "1. Пусть параметр $\\nu$ известен. Найдите информацию Фишера $I_X(\\theta)$. Является ли MLE-оценка параметра $\\hat{\\theta}$ эффективной?\n",
    "\n",
    "\n",
    "### [Задача 4 [4 балла]](#Задача-4)\n",
    "Пусть $\\boldX = \\{X_1,\\ldots,X_n\\} \\sim \\Uniform(0,\\theta)$, $Y = \\max\\{X_1,\\ldots,X_n\\}$.  Необходимо протестировать основную гипотезу $H_0:\\theta = 1/2$ против альтернативы $H_1: \\theta > 1/2$. В данном случае нельзя использовать тест Вальда, так как $Y$ при $n\\to\\infty$ не сходится к нормальному распределению. Допустим, что мы будем использовать следующее правило: гипотеза $H_0$ отвергается, если $Y > c$. \n",
    "\n",
    "1. Найдите функцию мощности для данного теста.\n",
    "1. При каком значении параметра $c$ размер теста будет равен $0.05$?\n",
    "1. Каково значение $\\pvalue$, если размер выборки $n = 20$ и $Y = 0.48$? Что можно сказать о гипотезе $H_0$?\n",
    "1. Каково значение $\\pvalue$, если размер выборки $n = 20$ и $Y = 0.52$? Что можно сказать о гипотезе $H_0$?\n",
    "\n",
    "### [Задача 5 [1 балл]](#Задача-5)\n",
    "Пусть $\\boldX = \\{X_1,\\dots,X_n\\} \\sim \\Exponential(\\theta)$. Постройте критерий отношения правдоподобий для проверки гипотезы $H_0: \\theta = \\theta_0$ vs $H_1 : \\theta > \\theta_0$.\n",
    "\n",
    "### [Задача 6 [3 балла]](#Задача-6)\n",
    "Пусть $\\boldX = \\{X_1,\\ldots,X_n\\} \\sim \\Normal(\\mu,\\sigma^2)$, где параметр $\\mu$ известен. Требуется протестировать гипотезу $H_0\\colon \\sigma = \\sigma_0$ против альтернативы $H_1 \\colon \\sigma \\neq \\sigma_0$.\n",
    "\n",
    "1. Постройте критерий отношения правдоподобий для различения гипотез $H_0$ и $H_1$.\n",
    "1. Постройте критерий Вальда для различения гипотез $H_0$ и $H_1$.\n",
    "1. Сравните аналитически полученные критерии. Сравнить (как аналитически, так и экспериментально) полученный тест с тестом Вальда для различения этих гипотез.\n",
    "\n",
    "\n",
    "Примечание. Аналитическое сравнение тестов подразумевает доказательство их (асимптотической) эквивалентности или неэквивалентности, где под эквивалентностью понимается идентичность выносимых тестами решений.\n",
    "\n",
    "### [Задача 7 [2 балла]](#Задача-7)\n",
    "Пусть $\\boldX = \\{X_1,\\dots,X_n\\}$ --- выборка н.о.р. с.в. со следующей функцией плотности:\n",
    "$$\n",
    "f(x, \\theta) = \\begin{cases}\n",
    "\tc(\\theta)d(x), &a \\leqslant x \\leqslant b(\\theta) \\\\\n",
    "\t0, &\\text{ иначе }\n",
    "\\end{cases}\n",
    "$$\n",
    "где $b(\\theta)$ --- монотонно возрастающая функция одного аргумента.\n",
    "\n",
    "\n",
    "1. Построить статистику отношения правдоподобий $\\lambda$ для тестирования гипотезы $H_0: \\theta = \\theta_0$ vs $H_1: \\theta \\neq \\theta_0$\n",
    "1. Найти распределение статистики $\\lambda$ при выполнении $H_0$ для следующей функции плотности:\n",
    "\t$$\n",
    "\tf(x, \\theta) = \\begin{cases}\n",
    "\t\t\\frac{2x}{\\theta^2}, \\quad &0 \\leqslant x \\leqslant \\theta \\\\\n",
    "\t\t0, \\quad &\\text{иначе}\n",
    "\t\\end{cases}\n",
    "\t$$\n",
    "\n",
    "\n",
    "### [Задача 8 [2 балла]](#Задача-8)\n",
    "Найдите наилучшую критическую область (НКО) для проверки гипотезы $H_0 \\colon \\Uniform[-a, a]$ против гипотезы $H_1 \\colon \\Normal(0, \\sigma^2)$ по одному\n",
    "наблюдению $(n = 1)$ при уровне значимости $\\alpha = 0.1$. Найдите мощность полученного критерия.\n",
    "\n",
    "### [Задача 9 [2 балла]](#Задача-9)\n",
    "Проверяются гипотезы о плотности $f$ распределения наблюдений $\\boldX = \\{X_1,\\dots,X_n\\}$: гипотеза $H_0\\colon f = f_0$ против альтернативы $H_1\\colon f = f_1$, где\n",
    "\\begin{gather*}\n",
    "\tf_1(x) = \n",
    "\t\\begin{cases}\n",
    "\t\t1, &x \\in [0,1],\\\\\n",
    "\t\t0, &x \\notin [0, 1],\n",
    "\t\\end{cases}\n",
    "\t\\qquad\n",
    "\tf_2(x)=\n",
    "\t\\begin{cases}\n",
    "\t\t2x, &x \\in [0, 1], \\\\\n",
    "\t\t0, &x \\notin [0, 1].\n",
    "\t\\end{cases}\n",
    "\\end{gather*}\n",
    "Построить наиболее мощный критерий размера $\\alpha$ при $n = 1$ и $n = 2$.\n",
    "\n",
    "### [Задача 10 [2 балла]](#Задача-10)\n",
    "В процессе настольной игры у игроков возникло подозрение, что два кубика, которые шли в комплекте с игрой, несимметричны. Поэтому, начиная с некоторого момента, они начали записывать результаты бросков. В каждом броске участвуют оба кубика. Результаты приведены в таблице.\n",
    "\n",
    "|Сумма очков | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |\n",
    "| - | - | - | - | - | - | - | - | - | - | - | - |\n",
    "|Количество бросков | 2 | 4 | 20 | 18 | 34 | 41 | 32 | 26 | 16 | 9 | 12|\n",
    "\n",
    "Проверьте гипотезу о том, что оба кубика симметричны на уровне значимости $\\alpha = 0.05$. Найдите p-value.\n",
    "\n",
    "### [Задача 11 [2 балла]](#Задача-11)\n",
    "Предположим, что у нас есть 10 статей, написанных автором, скрывающемся под псевдонимом. Мы подозреваем, что эти статьи на самом деле написаны некоторым известным писателем. Чтобы проверить эту гипотезу, мы подсчитали доли четырехбуквенных слов в 8-и сочинениях подозреваемого нами автора:\n",
    "$$\n",
    ".224~ .261~ .216~ .239~ .229~ .228~ .234~ .216~\n",
    "$$\n",
    "В 10 сочинениях, опубликованных под псевдонимом, доли четырехбуквенных слов равны\n",
    "$$\n",
    ".207~ .204~ .195~ .209~ .201~ .206~ .223~ .222~ .219~ .200\n",
    "$$\n",
    "\n",
    "1. Используйте критерий Вальда. Найдите $\\pvalue$ и 95\\%-ый доверительный интервал для разницы средних значений. Какой вывод можно сделать исходя из найденных значений?\n",
    "1. Используйте критерий перестановок. Каково в этом случае значение $\\pvalue$. Какой вывод можно сделать?\n",
    "\n",
    "\n",
    "### [Задача 12 [2 балла]](#Задача-12)\n",
    "Маршрут грузового состава начинается в пункте $A$ и последовательно проходит через пункты $B_0$, $B_1$ и т.д. По прибытии в очередной пункт те составы, которые направлялись в этот пункт, отцепляются. Очередной состав из 500 грузовых вагонов отправился из пункта $A$ вдоль пунктов $B_0$, $B_1$, \\dots. В таблице приведено количество отцепленных составов в каждом из пунктов (последним пунктом в данном случае оказался пункт $B_9$).\n",
    "\n",
    "|Пункт | 0| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |\n",
    "| - | - | - | - | - | - | - | - | - | - | - |\n",
    "|Количество составов | 15 | 55 | 126 | 110 | 113 | 49 | 20 | 9 | 2 | 1 |\n",
    "\n",
    "Возникло предположение, что распределение грузовых составов по пунктам назначения можно описать некоторым дискретным распределением, где $P(X = B_i)$ --- вероятность того, что состав направляется в пункт $B_i$. В рамках данного предположения требуется провести проверку следующих гипотез на уровне значимости $\\alpha = 0.05$ и найти p-value:\n",
    "\n",
    "1. $\\boldX \\sim \\Poisson(\\theta)$, т.е. $P(X = B_j) = e^{-\\theta} \\frac{\\theta^j}{j!}$, где $j \\ge 0$.\n",
    "1. $\\boldX \\sim \\Binomial(m, p)$, т.е. $P(X = B_j) = C^j_m p^j (1-p)^{m - j}$, где $j \\in \\{0, \\dots, 9\\}$ и $m = 9$.\n",
    "\n",
    "Подсказка. Воспользуйтесь параметрическим критерием хи-квадрат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8510e3",
   "metadata": {},
   "source": [
    "#### Notebook formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "2f9452da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 297;\n",
       "                var nbb_unformatted_code = \"import re\\n\\ntext = r\\\"\\\"\\\"\\\"\\\"\\\"\\ntasks = re.split(r\\\"(?=\\u0417\\u0430\\u0434\\u0430\\u0447\\u0430 \\\\d+)\\\", text)[1:]\\n\\n\\ndef create_link(description, section_name):\\n    return f\\\"[{description}](#{section_name.replace(' ', '-')})\\\"\\n\\n\\ndef add_link(task: str):\\n    return re.sub(\\n        r\\\"(\\u0417\\u0430\\u0434\\u0430\\u0447\\u0430 \\\\d+) \\\\[.*?\\\\]\\\",\\n        lambda match: \\\"### \\\" + create_link(match.group(0), match.group(1)),\\n        task,\\n    )\\n\\n\\ndef create_solution_template(task: str):\\n    task = re.sub(r\\\"(\\u0417\\u0430\\u0434\\u0430\\u0447\\u0430 \\\\d+) \\\\[.*?\\\\]\\\", r\\\"### \\\\1\\\", task)\\n    header, *subtasks = re.split(r\\\"(?=1\\\\. )\\\", task)\\n    subtasks = [\\n        subtask.replace(\\\"1. \\\", f\\\"{i}. \\\") for i, subtask in enumerate(subtasks, 1)\\n    ]\\n    if len(subtasks) == 0:\\n        subtasks = [\\\"\\\"]\\n    subtasks = [\\n        \\\"---\\\\n#### \\\" + subtask + \\\"\\\\n$\\\\\\\\displaystyle{\\\\n}$\\\\n\\\\n$\\\\\\\\displaystyle{\\\\n}$\\\\n\\\"\\n        for subtask in subtasks\\n    ]\\n\\n    return header + \\\"\\\".join(subtasks)\\n\\n\\ntasks_with_links = \\\"\\\".join(add_link(task) for task in tasks)\\nsolutions = \\\"\\\".join(create_solution_template(task) for task in tasks)\\n\\nprint(tasks_with_links)\\nprint(solutions)\";\n",
       "                var nbb_formatted_code = \"import re\\n\\ntext = r\\\"\\\"\\\"\\\"\\\"\\\"\\ntasks = re.split(r\\\"(?=\\u0417\\u0430\\u0434\\u0430\\u0447\\u0430 \\\\d+)\\\", text)[1:]\\n\\n\\ndef create_link(description, section_name):\\n    return f\\\"[{description}](#{section_name.replace(' ', '-')})\\\"\\n\\n\\ndef add_link(task: str):\\n    return re.sub(\\n        r\\\"(\\u0417\\u0430\\u0434\\u0430\\u0447\\u0430 \\\\d+) \\\\[.*?\\\\]\\\",\\n        lambda match: \\\"### \\\" + create_link(match.group(0), match.group(1)),\\n        task,\\n    )\\n\\n\\ndef create_solution_template(task: str):\\n    task = re.sub(r\\\"(\\u0417\\u0430\\u0434\\u0430\\u0447\\u0430 \\\\d+) \\\\[.*?\\\\]\\\", r\\\"### \\\\1\\\", task)\\n    header, *subtasks = re.split(r\\\"(?=1\\\\. )\\\", task)\\n    subtasks = [\\n        subtask.replace(\\\"1. \\\", f\\\"{i}. \\\") for i, subtask in enumerate(subtasks, 1)\\n    ]\\n    if len(subtasks) == 0:\\n        subtasks = [\\\"\\\"]\\n    subtasks = [\\n        \\\"---\\\\n#### \\\" + subtask + \\\"\\\\n$\\\\\\\\displaystyle{\\\\n}$\\\\n\\\\n$\\\\\\\\displaystyle{\\\\n}$\\\\n\\\"\\n        for subtask in subtasks\\n    ]\\n\\n    return header + \\\"\\\".join(subtasks)\\n\\n\\ntasks_with_links = \\\"\\\".join(add_link(task) for task in tasks)\\nsolutions = \\\"\\\".join(create_solution_template(task) for task in tasks)\\n\\nprint(tasks_with_links)\\nprint(solutions)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = r\"\"\"\"\"\"\n",
    "tasks = re.split(r\"(?=Задача \\d+)\", text)[1:]\n",
    "\n",
    "\n",
    "def create_link(description, section_name):\n",
    "    return f\"[{description}](#{section_name.replace(' ', '-')})\"\n",
    "\n",
    "\n",
    "def add_link(task: str):\n",
    "    return re.sub(\n",
    "        r\"(Задача \\d+) \\[.*?\\]\",\n",
    "        lambda match: \"### \" + create_link(match.group(0), match.group(1)),\n",
    "        task,\n",
    "    )\n",
    "\n",
    "\n",
    "def create_solution_template(task: str):\n",
    "    task = re.sub(r\"(Задача \\d+) \\[.*?\\]\", r\"### \\1\", task)\n",
    "    header, *subtasks = re.split(r\"(?=1\\. )\", task)\n",
    "    subtasks = [\n",
    "        subtask.replace(\"1. \", f\"{i}. \") for i, subtask in enumerate(subtasks, 1)\n",
    "    ]\n",
    "    if len(subtasks) == 0:\n",
    "        subtasks = [\"\"]\n",
    "    subtasks = [\n",
    "        \"---\\n#### \" + subtask + \"\\n$\\\\displaystyle{\\n}$\\n\\n$\\\\displaystyle{\\n}$\\n\"\n",
    "        for subtask in subtasks\n",
    "    ]\n",
    "\n",
    "    return header + \"\".join(subtasks)\n",
    "\n",
    "\n",
    "tasks_with_links = \"\".join(add_link(task) for task in tasks)\n",
    "solutions = \"\".join(create_solution_template(task) for task in tasks)\n",
    "\n",
    "print(tasks_with_links)\n",
    "print(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1878,
   "id": "80e61dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1877;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n    \\n    \\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return x_1 / n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return x_2 / n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1**3 * (1 - p_1) + p_2**3 * (1 - p_2)) / n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dataclasses\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import torch\n",
    "import types\n",
    "\n",
    "\n",
    "%load_ext nb_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eddd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_centered_interval(mean, radius):\n",
    "    return [mean - radius, mean + radius]\n",
    "\n",
    "def get_asymptoticaly_normal_confidence_interval(\n",
    "    mean, standard_error_of_the_mean, confidence_level=0.95\n",
    "):\n",
    "    alpha = 1 - confidence_level\n",
    "    norm = stats.norm()\n",
    "    ppf = norm.ppf(1 - alpha / 2)\n",
    "    return build_centered_interval(mean, ppf * standard_error_of_the_mean)\n",
    "\n",
    "\n",
    "def get_central_confidence_interval(bootstrap_estimates, confidence_level=0.95):\n",
    "    alpha = 1 - confidence_level\n",
    "    estimate = bootstrap_estimates.mean()\n",
    "    return [\n",
    "        2 * estimate - np.quantile(bootstrap_estimates, 1 - alpha / 2),\n",
    "        2 * estimate - np.quantile(bootstrap_estimates, alpha / 2),\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_percentile_confidence_interval(bootstrap_estimates, confidence_level=0.95):\n",
    "    alpha = 1 - confidence_level\n",
    "    return [\n",
    "        np.quantile(bootstrap_estimates, alpha / 2),\n",
    "        np.quantile(bootstrap_estimates, 1 - alpha / 2),\n",
    "    ]\n",
    "\n",
    "\n",
    "def plot_different_bootstrap_confidence_intervals(\n",
    "    estimate,\n",
    "    bootstrap_samples,\n",
    "    confidence_level=0.95,\n",
    "    interval_y_level=0.04,\n",
    "):\n",
    "    asymptoticaly_normal_confidence_interval = (\n",
    "        get_asymptoticaly_normal_confidence_interval(\n",
    "            mean=estimate,\n",
    "            standard_error_of_the_mean=bootstrap_samples.std(),\n",
    "            confidence_level=confidence_level,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    central_confidence_interval = get_central_confidence_interval(\n",
    "        bootstrap_samples, confidence_level\n",
    "    )\n",
    "\n",
    "    percentile_confidence_interval = get_percentile_confidence_interval(\n",
    "        bootstrap_samples, confidence_level\n",
    "    )\n",
    "\n",
    "    plt.hist(\n",
    "        bootstrap_samples,\n",
    "        bins=30,\n",
    "        density=True,\n",
    "        label=\"bootstrap samples\",\n",
    "        histtype=\"step\",\n",
    "    )\n",
    "    plt.axvline(estimate, c=\"black\", label=\"estimate\")\n",
    "\n",
    "    suffix = f\"{confidence_level:.0%} interval\"\n",
    "    interval_y = np.repeat(interval_y_level, 2)\n",
    "    plt.plot(\n",
    "        asymptoticaly_normal_confidence_interval,\n",
    "        interval_y,\n",
    "        lw=7,\n",
    "        label=\"bootstrap asymptoticaly normal\\n\" + suffix,\n",
    "    )\n",
    "    plt.plot(\n",
    "        central_confidence_interval,\n",
    "        2 * interval_y,\n",
    "        lw=7,\n",
    "        label=\"bootstrap central\\n\" + suffix,\n",
    "    )\n",
    "    plt.plot(\n",
    "        percentile_confidence_interval,\n",
    "        3 * interval_y,\n",
    "        lw=7,\n",
    "        label=\"bootstrap percentile\\n\" + suffix,\n",
    "    )\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2160,
   "id": "2f6a1670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2159;\n",
       "                var nbb_unformatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_formatted_code = \"def grad(function, x):\\n    x = torch.tensor(x, dtype=float, requires_grad=True)\\n    function(x).backward()\\n    return x.grad\\n\\n\\ndef get_learning_rate(optimizer, param_group=0):\\n    return optimizer.param_groups[param_group][\\\"lr\\\"]\\n\\n\\nclass ArgMin:\\n    def __init__(self, scalar_function, callbacks=None):\\n        self.scalar_function = scalar_function\\n        self.optimizer = None\\n        self.schedulers = None\\n        self.value = None\\n        self.ns = types.SimpleNamespace()\\n        self.callbacks = callbacks or []\\n\\n        for callback in self.callbacks:\\n            if isinstance(callback, StoppingCallback):\\n                self.stopping_callback = callback\\n                break\\n        else:\\n            self.stopping_callback = MinDeltaStoppingCallback()\\n            self.callbacks.append(self.stopping_callback)\\n\\n    def optimize_from_starting_point(\\n        self,\\n        starting_point,\\n        optimizer_from_params=lambda params: torch.optim.Rprop(params),\\n        schedulers_from_optimizer=lambda optimizer: [\\n            torch.optim.lr_scheduler.ConstantLR(optimizer),\\n        ],\\n    ):\\n        tensor = starting_point\\n        if not torch.is_tensor(tensor):\\n            tensor = torch.tensor(tensor)\\n        tensor = tensor.to(float).requires_grad_(True)\\n\\n        self.optimizer = optimizer_from_params([tensor])\\n        self.schedulers = schedulers_from_optimizer(self.optimizer)\\n\\n        self.on_epoch_start()\\n        while not self.stopping_callback.is_time_to_stop(self):\\n            self.step(tensor)\\n            self.on_step_end()\\n\\n        self.on_epoch_end()\\n        return tensor.detach()\\n\\n    def step(self, tensor):\\n        def closure():\\n            self.optimizer.zero_grad()\\n            value = self.scalar_function(tensor)\\n            value.backward()\\n            self.value = value.item()\\n            return value\\n\\n        self.optimizer.step(closure)\\n        self.schedulers_step()\\n\\n    def schedulers_step(self):\\n        for scheduler in self.schedulers:\\n            try:\\n                scheduler.step()\\n            except TypeError:\\n                scheduler.step(self.value)\\n\\n    def on_epoch_start(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_start(self)\\n\\n    def on_step_end(self):\\n        for callback in self.callbacks:\\n            callback.on_step_end(self)\\n\\n    def on_epoch_end(self):\\n        for callback in self.callbacks:\\n            callback.on_epoch_end(self)\\n\\n\\nclass Callback:\\n    def on_epoch_start(self, argmin):\\n        pass\\n\\n    def on_step_end(self, argmin):\\n        pass\\n\\n    def on_epoch_end(self, argmin):\\n        pass\\n\\n\\nclass StoppingCallback(Callback):\\n    def is_time_to_stop(self, argmin):\\n        pass\\n\\n\\nclass MinDeltaStoppingCallback(StoppingCallback):\\n    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\\n        self.min_delta = min_delta\\n        self.max_steps = max_steps\\n        self.warmup = warmup\\n        self.patience = patience\\n        self.step = 0\\n        self.last_values = []\\n\\n    def on_epoch_start(self, argmin):\\n        self.step = 0\\n        self.last_values = []\\n\\n    def is_time_to_stop(self, argmin):\\n        if self.step < self.warmup:\\n            return False\\n        elif self.step > self.max_steps:\\n            return True\\n        else:\\n            return np.std(self.last_values) < self.min_delta\\n\\n    def on_step_end(self, argmin):\\n        self.step += 1\\n        self.last_values.append(argmin.value)\\n        self.last_values = self.last_values[-self.patience :]\\n\\n\\nclass ArgMax(ArgMin):\\n    def __init__(self, scalar_function, callbacks=None):\\n        super().__init__(lambda x: -scalar_function(x), callbacks)\\n\\n\\ndef argmin(scalar_function, starting_point):\\n    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\\n\\n\\ndef argmax(scalar_function, starting_point):\\n    return argmin(lambda x: -scalar_function(x), starting_point)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def grad(function, x):\n",
    "    x = torch.tensor(x, dtype=float, requires_grad=True)\n",
    "    function(x).backward()\n",
    "    return x.grad\n",
    "\n",
    "\n",
    "def get_learning_rate(optimizer, param_group=0):\n",
    "    return optimizer.param_groups[param_group][\"lr\"]\n",
    "\n",
    "\n",
    "class ArgMin:\n",
    "    def __init__(self, scalar_function, callbacks=None):\n",
    "        self.scalar_function = scalar_function\n",
    "        self.optimizer = None\n",
    "        self.schedulers = None\n",
    "        self.value = None\n",
    "        self.ns = types.SimpleNamespace()\n",
    "        self.callbacks = callbacks or []\n",
    "\n",
    "        for callback in self.callbacks:\n",
    "            if isinstance(callback, StoppingCallback):\n",
    "                self.stopping_callback = callback\n",
    "                break\n",
    "        else:\n",
    "            self.stopping_callback = MinDeltaStoppingCallback()\n",
    "            self.callbacks.append(self.stopping_callback)\n",
    "\n",
    "    def optimize_from_starting_point(\n",
    "        self,\n",
    "        starting_point,\n",
    "        optimizer_from_params=lambda params: torch.optim.Rprop(params),\n",
    "        schedulers_from_optimizer=lambda optimizer: [\n",
    "            torch.optim.lr_scheduler.ConstantLR(optimizer),\n",
    "        ],\n",
    "    ):\n",
    "        tensor = starting_point\n",
    "        if not torch.is_tensor(tensor):\n",
    "            tensor = torch.tensor(tensor)\n",
    "        tensor = tensor.to(float).requires_grad_(True)\n",
    "\n",
    "        self.optimizer = optimizer_from_params([tensor])\n",
    "        self.schedulers = schedulers_from_optimizer(self.optimizer)\n",
    "\n",
    "        self.on_epoch_start()\n",
    "        while not self.stopping_callback.is_time_to_stop(self):\n",
    "            self.step(tensor)\n",
    "            self.on_step_end()\n",
    "\n",
    "        self.on_epoch_end()\n",
    "        return tensor.detach()\n",
    "\n",
    "    def step(self, tensor):\n",
    "        def closure():\n",
    "            self.optimizer.zero_grad()\n",
    "            value = self.scalar_function(tensor)\n",
    "            value.backward()\n",
    "            self.value = value.item()\n",
    "            return value\n",
    "\n",
    "        self.optimizer.step(closure)\n",
    "        self.schedulers_step()\n",
    "\n",
    "    def schedulers_step(self):\n",
    "        for scheduler in self.schedulers:\n",
    "            try:\n",
    "                scheduler.step()\n",
    "            except TypeError:\n",
    "                scheduler.step(self.value)\n",
    "\n",
    "    def on_epoch_start(self):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_epoch_start(self)\n",
    "\n",
    "    def on_step_end(self):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_step_end(self)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_epoch_end(self)\n",
    "\n",
    "\n",
    "class Callback:\n",
    "    def on_epoch_start(self, argmin):\n",
    "        pass\n",
    "\n",
    "    def on_step_end(self, argmin):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, argmin):\n",
    "        pass\n",
    "\n",
    "\n",
    "class StoppingCallback(Callback):\n",
    "    def is_time_to_stop(self, argmin):\n",
    "        pass\n",
    "\n",
    "\n",
    "class MinDeltaStoppingCallback(StoppingCallback):\n",
    "    def __init__(self, min_delta=1e-5, max_steps=1000, warmup=100, patience=5):\n",
    "        self.min_delta = min_delta\n",
    "        self.max_steps = max_steps\n",
    "        self.warmup = warmup\n",
    "        self.patience = patience\n",
    "        self.step = 0\n",
    "        self.last_values = []\n",
    "\n",
    "    def on_epoch_start(self, argmin):\n",
    "        self.step = 0\n",
    "        self.last_values = []\n",
    "\n",
    "    def is_time_to_stop(self, argmin):\n",
    "        if self.step < self.warmup:\n",
    "            return False\n",
    "        elif self.step > self.max_steps:\n",
    "            return True\n",
    "        else:\n",
    "            return np.std(self.last_values) < self.min_delta\n",
    "\n",
    "    def on_step_end(self, argmin):\n",
    "        self.step += 1\n",
    "        self.last_values.append(argmin.value)\n",
    "        self.last_values = self.last_values[-self.patience :]\n",
    "\n",
    "\n",
    "class ArgMax(ArgMin):\n",
    "    def __init__(self, scalar_function, callbacks=None):\n",
    "        super().__init__(lambda x: -scalar_function(x), callbacks)\n",
    "\n",
    "\n",
    "def argmin(scalar_function, starting_point):\n",
    "    return ArgMin(scalar_function).optimize_from_starting_point(starting_point)\n",
    "\n",
    "\n",
    "def argmax(scalar_function, starting_point):\n",
    "    return argmin(lambda x: -scalar_function(x), starting_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2447,
   "id": "ea1e0082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2446;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        lambda params: torch.optim.SGD(params, lr=lr),\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n                    optimizer, T_0=max_steps // 10\\n                )\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n            ],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n            ],\\n        ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class EpochStats:\n",
    "    optimizer_name: str\n",
    "    scheduler_name: str\n",
    "    values: list = dataclasses.field(default_factory=list)\n",
    "    learning_rates: list = dataclasses.field(default_factory=list)\n",
    "\n",
    "\n",
    "class StatsCallback(Callback):\n",
    "    def __init__(self):\n",
    "        self.epoch_stats: list[EpochStats] = []\n",
    "\n",
    "    def on_epoch_start(self, argmin):\n",
    "        self.epoch_stats.append(\n",
    "            EpochStats(\n",
    "                optimizer_name=argmin.optimizer.__class__.__name__,\n",
    "                scheduler_name=\", \".join(\n",
    "                    s.__class__.__name__ for s in argmin.schedulers\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def on_step_end(self, argmin):\n",
    "        self.epoch_stats[-1].values.append(argmin.value)\n",
    "        self.epoch_stats[-1].learning_rates.append(get_learning_rate(argmin.optimizer))\n",
    "\n",
    "    def plot(self):\n",
    "        fig, ax_values = plt.subplots(figsize=(10, 6))\n",
    "        plt.title(\"Epoch runs optimizer-scheduler pairs comparison\")\n",
    "        ax_values.set(xlabel=\"Step\", ylabel=\"Value\")\n",
    "        if all(v > 0 for es in self.epoch_stats for v in es.values):\n",
    "            ax_values.set(yscale=\"log\")\n",
    "        ax_lr = ax_values.twinx()\n",
    "        ax_lr.set(ylabel=\"Learning rate\", yscale=\"log\")\n",
    "\n",
    "        plot_handles = []\n",
    "        for epoch_stats in sorted(self.epoch_stats, key=lambda es: es.values[-1]):\n",
    "            (p1,) = ax_values.plot(\n",
    "                epoch_stats.values,\n",
    "                \"-\",\n",
    "                label=f\"{epoch_stats.values[-1]:.3E}, {epoch_stats.optimizer_name}\",\n",
    "            )\n",
    "            (p2,) = ax_lr.plot(\n",
    "                epoch_stats.learning_rates,\n",
    "                \"--\",\n",
    "                c=p1.get_color(),\n",
    "                alpha=0.75,\n",
    "                label=epoch_stats.scheduler_name,\n",
    "            )\n",
    "            plot_handles.extend([p1, p2])\n",
    "\n",
    "        plt.legend(handles=plot_handles, loc=\"lower left\")\n",
    "\n",
    "\n",
    "def plot_learning_curve(scalar_function, starting_point):\n",
    "    stats = StatsCallback()\n",
    "    arg = ArgMax(scalar_function, callbacks=[stats]).optimize_from_starting_point(\n",
    "        starting_point\n",
    "    )\n",
    "    stats.plot()\n",
    "    return arg, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2450,
   "id": "14ed8416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2449;\n",
       "                var nbb_unformatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n#         lambda params: torch.optim.Adadelta(params, lr=lr),\\n#         lambda params: torch.optim.Adagrad(params, lr=lr),\\n#         lambda params: torch.optim.Adam(params, lr=lr),\\n#         lambda params: torch.optim.Adamax(params, lr=lr),\\n#         lambda params: torch.optim.AdamW(params, lr=lr),\\n#         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n#         lambda params: torch.optim.NAdam(params, lr=lr),\\n#         lambda params: torch.optim.RAdam(params, lr=lr),\\n#         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n#         lambda params: torch.optim.SGD(params, lr=lr),\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n#                     optimizer, T_0=max_steps // 10\\n#                 )\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n#             ],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n#         ],\\n#         [\\n#             lambda params: torch.optim.SGD(params, lr=lr),\\n#             lambda optimizer: [\\n#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n#             ],\\n#         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_formatted_code = \"def compare_optimizers_schedulers(\\n    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\\n):\\n    stats_callback = StatsCallback()\\n    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\\n\\n    for optimizers_scheduler in optimizers_schedulers:\\n        match optimizers_scheduler:\\n            case [optimizer, scheduler]:\\n                pass\\n            case optimizer:\\n                scheduler = lambda optimizer: [\\n                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\\n                ]\\n        ArgMin(\\n            scalar_function, callbacks=[stats_callback, stopping_callback]\\n        ).optimize_from_starting_point(\\n            starting_point,\\n            optimizer_from_params=optimizer,\\n            schedulers_from_optimizer=scheduler,\\n        )\\n    stats_callback.plot()\\n\\n\\nlr = 1e-2\\nmax_steps = 101\\ncompare_optimizers_schedulers(\\n    scalar_function=lambda x: x**2,\\n    starting_point=100,\\n    optimizers_schedulers=[\\n        #         lambda params: torch.optim.Adadelta(params, lr=lr),\\n        #         lambda params: torch.optim.Adagrad(params, lr=lr),\\n        #         lambda params: torch.optim.Adam(params, lr=lr),\\n        #         lambda params: torch.optim.Adamax(params, lr=lr),\\n        #         lambda params: torch.optim.AdamW(params, lr=lr),\\n        #         lambda params: torch.optim.ASGD(params, lr=lr),\\n        lambda params: torch.optim.LBFGS(params, lr=lr),\\n        #         lambda params: torch.optim.NAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RAdam(params, lr=lr),\\n        #         lambda params: torch.optim.RMSprop(params, lr=lr),\\n        lambda params: torch.optim.Rprop(params, lr=lr),\\n        #         lambda params: torch.optim.SGD(params, lr=lr),\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        [\\n            lambda params: torch.optim.SGD(params, lr=lr),\\n            lambda optimizer: [\\n                torch.optim.lr_scheduler.OneCycleLR(\\n                    optimizer, max_lr=0.1, total_steps=max_steps + 1\\n                )\\n            ],\\n        ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\\n        #                     optimizer, T_0=max_steps // 10\\n        #                 )\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\\n        #             ],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\\n        #         ],\\n        #         [\\n        #             lambda params: torch.optim.SGD(params, lr=lr),\\n        #             lambda optimizer: [\\n        #                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\\n        #             ],\\n        #         ],\\n    ],\\n    max_steps=max_steps,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_optimizers_schedulers(\n",
    "    scalar_function, starting_point, optimizers_schedulers, max_steps=10_000\n",
    "):\n",
    "    stats_callback = StatsCallback()\n",
    "    stopping_callback = MinDeltaStoppingCallback(max_steps=max_steps)\n",
    "\n",
    "    for optimizers_scheduler in optimizers_schedulers:\n",
    "        match optimizers_scheduler:\n",
    "            case [optimizer, scheduler]:\n",
    "                pass\n",
    "            case optimizer:\n",
    "                scheduler = lambda optimizer: [\n",
    "                    torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\n",
    "                ]\n",
    "        ArgMin(\n",
    "            scalar_function, callbacks=[stats_callback, stopping_callback]\n",
    "        ).optimize_from_starting_point(\n",
    "            starting_point,\n",
    "            optimizer_from_params=optimizer,\n",
    "            schedulers_from_optimizer=scheduler,\n",
    "        )\n",
    "    stats_callback.plot()\n",
    "\n",
    "\n",
    "lr = 1e-2\n",
    "max_steps = 101\n",
    "compare_optimizers_schedulers(\n",
    "    scalar_function=lambda x: x**2,\n",
    "    starting_point=100,\n",
    "    optimizers_schedulers=[\n",
    "#         lambda params: torch.optim.Adadelta(params, lr=lr),\n",
    "#         lambda params: torch.optim.Adagrad(params, lr=lr),\n",
    "#         lambda params: torch.optim.Adam(params, lr=lr),\n",
    "#         lambda params: torch.optim.Adamax(params, lr=lr),\n",
    "#         lambda params: torch.optim.AdamW(params, lr=lr),\n",
    "#         lambda params: torch.optim.ASGD(params, lr=lr),\n",
    "        lambda params: torch.optim.LBFGS(params, lr=lr),\n",
    "#         lambda params: torch.optim.NAdam(params, lr=lr),\n",
    "#         lambda params: torch.optim.RAdam(params, lr=lr),\n",
    "#         lambda params: torch.optim.RMSprop(params, lr=lr),\n",
    "        lambda params: torch.optim.Rprop(params, lr=lr),\n",
    "#         lambda params: torch.optim.SGD(params, lr=lr),\n",
    "#         [\n",
    "#             lambda params: torch.optim.SGD(params, lr=lr),\n",
    "#             lambda optimizer: [\n",
    "#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\n",
    "#             ],\n",
    "#         ],\n",
    "        [\n",
    "            lambda params: torch.optim.SGD(params, lr=lr),\n",
    "            lambda optimizer: [\n",
    "                torch.optim.lr_scheduler.OneCycleLR(\n",
    "                    optimizer, max_lr=0.1, total_steps=max_steps + 1\n",
    "                )\n",
    "            ],\n",
    "        ],\n",
    "#         [\n",
    "#             lambda params: torch.optim.SGD(params, lr=lr),\n",
    "#             lambda optimizer: [\n",
    "#                 torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_steps)\n",
    "#             ],\n",
    "#         ],\n",
    "#         [\n",
    "#             lambda params: torch.optim.SGD(params, lr=lr),\n",
    "#             lambda optimizer: [\n",
    "#                 torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "#                     optimizer, T_0=max_steps // 10\n",
    "#                 )\n",
    "#             ],\n",
    "#         ],\n",
    "#         [\n",
    "#             lambda params: torch.optim.SGD(params, lr=lr),\n",
    "#             lambda optimizer: [\n",
    "#                 torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "#             ],\n",
    "#         ],\n",
    "#         [\n",
    "#             lambda params: torch.optim.SGD(params, lr=lr),\n",
    "#             lambda optimizer: [torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)],\n",
    "#         ],\n",
    "#         [\n",
    "#             lambda params: torch.optim.SGD(params, lr=lr),\n",
    "#             lambda optimizer: [\n",
    "#                 torch.optim.lr_scheduler.StepLR(optimizer, step_size=max_steps // 10)\n",
    "#             ],\n",
    "#         ],\n",
    "    ],\n",
    "    max_steps=max_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2147,
   "id": "f9309381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2146;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LogDensity:\n",
    "    def __call__(self, parameter):\n",
    "        if not torch.is_tensor(parameter):\n",
    "            parameter = torch.tensor(parameter)\n",
    "        return self.call(parameter)\n",
    "\n",
    "    def call(self, parameter):\n",
    "        \"\"\"Return log pdf at parameter.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def sample_parameter(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def calculate_analytical_parameter_mle(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def calculate_numerical_parameter_mle(self):\n",
    "        return argmax(self, self.sample_parameter())\n",
    "\n",
    "    def plot_learning_curve(self):\n",
    "        return plot_learning_curve(self, self.sample_parameter())\n",
    "\n",
    "    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\n",
    "        return (\n",
    "            torch.stack(\n",
    "                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\n",
    "            )\n",
    "            .mean(0)\n",
    "            .to(float)\n",
    "        )\n",
    "\n",
    "    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\n",
    "        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\n",
    "        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\n",
    "\n",
    "        assert torch.allclose(\n",
    "            analytical_mean_mle,\n",
    "            numerical_mean_mle,\n",
    "            rtol=rtol,\n",
    "        ), (\n",
    "            f\"Estimates don't match:\\nAnalytical mle\\t{analytical_mean_mle}\\n\"\n",
    "            f\"Numerical mle\\t{numerical_mean_mle}\\n{self}\"\n",
    "        )\n",
    "\n",
    "        if true_parameter is not None:\n",
    "            assert torch.allclose(\n",
    "                true_parameter,\n",
    "                analytical_mean_mle,\n",
    "                rtol=0.5,\n",
    "            ), (\n",
    "                f\"Estimate doesn't match:\\nTrue parameter\\t{true_parameter}\\n\"\n",
    "                f\"Analytical mle\\t{analytical_mean_mle}\\n{self}\"\n",
    "            )\n",
    "            assert torch.allclose(\n",
    "                true_parameter,\n",
    "                numerical_mean_mle,\n",
    "                rtol=0.5,\n",
    "            ), (\n",
    "                f\"Estimate doesn't match:\\nTrue parameter\\t{true_parameter}\\n\"\n",
    "                f\"Numerical mle\\t{numerical_mean_mle}\\n{self}\"\n",
    "            )\n",
    "            \n",
    "def get_apriori_probability():\n",
    "    return torch.distributions.Beta(10, 10).sample().to(float)\n",
    "\n",
    "\n",
    "def get_aprioiri_positive_parameter(mean=10):\n",
    "    return torch.distributions.Poisson(mean).sample().to(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4954412",
   "metadata": {},
   "source": [
    "### Задача 1\n",
    "\n",
    "Пусть $n_1$ --- количество людей, которые получили лечение по методике 1, а $n_2$ --- количество людей, которые получили лечение по методике 2. Обозначим через $X_1$ --- количество людей, получивших лечение по методике 1, на которых эта методика повлияла положительно. Аналогично, обозначим через $X_2$ --- количество людей, получивших лечение по методике 2, на которых эта методика повлияла положительно. Предположим, что $X_1 \\sim \\Binomial(n_1,p_1)$ и $X_2\\sim \\Binomial(n_2,p_2)$. Положим $\\psi = p_1-p_2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6902fd",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. Найдите MLE-оценку $\\mlepsi$ для параметра $\\psi$.\n",
    "\n",
    "${\\displaystyle\n",
    "\\mlepsi =\n",
    "\\argmax_{\\psi = p_1 - p_2} f_1(X_1; p_1) f_2(X_2; p_2) =\n",
    "\\argmax_{p_1} f_1(X_1; p_1) - \\argmax_{p_2}f_2(X_2; p_2) =\\\\=\n",
    "\\argmax_{p_1}C_{n_1}^{X_1}p_1^{X_1}(1-p_1)^{n_1 - X_1} - \\argmax_{p_2}C_{n_2}^{X_2}p_2^{X_2}(1-p_2)^{n_2 - X_2} =\\\\=\n",
    "\\argmax_{p_1}\\big(\\ln C_{n_1}^{X_1} + X_1 \\ln p_1 + (n_1 - X_1)\\ln(1-p_1) \\big) - \n",
    "\\argmax_{p_2}\\big(\\ln C_{n_2}^{X_2} + X_2 \\ln p_2 + (n_2 - X_2)\\ln(1-p_2) \\big)\n",
    "}$\n",
    "\n",
    "${\\displaystyle\n",
    "\\hat p = \\argmax_{p}\\big( X \\ln p + (n - X)\\ln(1-p) \\big) \\Rightarrow\n",
    "\\frac{X}{\\hat p} - \\frac{n-X}{1-\\hat p} = 0 \\Rightarrow\n",
    "\\frac{X(1-\\hat p) - \\hat p(n-X)}{\\hat p(1-\\hat p)} = 0 \\Rightarrow\n",
    "X - \\hat p n = 0 \\Rightarrow\n",
    "\\hatp  = \\frac{X}{n}\n",
    "}$\n",
    "\n",
    "${\\displaystyle\n",
    "\\mlepsi = \\frac{X_1}{n_1} - \\frac{X_2}{n_2}\n",
    "}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2141,
   "id": "48a193fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2140;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter():\\n    return torch.distributions.Poisson(10).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclasses.dataclass()\n",
    "class BinomialLogDensity(LogDensity):\n",
    "    n_positive: int\n",
    "    n: int\n",
    "\n",
    "    def call(self, parameter):\n",
    "        return self.n_positive * torch.log(parameter) + (\n",
    "            self.n - self.n_positive\n",
    "        ) * torch.log(1 - parameter)\n",
    "\n",
    "    def sample_parameter(self):\n",
    "        return get_apriori_probability()\n",
    "\n",
    "    def calculate_analytical_parameter_mle(self):\n",
    "        return torch.tensor(self.n_positive / self.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2143,
   "id": "948f80f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2142;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    true_parameter = get_apriori_probability()\n",
    "    n = np.random.randint(10, 100)\n",
    "    n_positive = int(true_parameter * n)\n",
    "    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\n",
    "    log_density.check(true_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421dcfc",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. Найдите информационную матрицу Фишера $I(p_1,p_2)$.\n",
    "\n",
    "${\\displaystyle\n",
    "I(p_1,p_2)_{i, j} = \n",
    "-\\Exp [\\frac{\\partial^2}{\\partial p_i \\partial p_j} \\ln f(\\boldX; p_1,p_2) | p_1,p_2] =\\\\=\n",
    "\\Exp [\\frac{\\partial^2}{\\partial p_i \\partial p_j}\n",
    "\\big(\n",
    "\\ln C_{n_1}^{X_1} + X_1 \\ln p_1 + (n_1 - X_1)\\ln(1-p_1) + \n",
    "\\ln C_{n_2}^{X_2} + X_2 \\ln p_2 + (n_2 - X_2)\\ln(1-p_2)\n",
    "\\big) | p_1,p_2]\n",
    "=\\\\= \n",
    "-\\Exp [\\frac{\\partial}{\\partial p_j}\n",
    "\\big(\n",
    "\\mathbb{1}[i=1](\\frac{X_1}{p_1} - \\frac{n_1 - X_1}{1 - p_1}) + \n",
    "\\mathbb{1}[i=2](\\frac{X_2}{p_2} - \\frac{n_2 - X_2}{1 - p_2})\n",
    "\\big) | p_1,p_2]\n",
    "=\\\\=\n",
    "-\\Exp [\n",
    "\\big(\n",
    "\\mathbb{1}[i=1, j=1](-\\frac{X_1}{p_1^2} - \\frac{n_1 - X_1}{(1 - p_1)^2}) + \n",
    "\\mathbb{1}[i=2, j=2](-\\frac{X_2}{p_2^2} - \\frac{n_2 - X_2}{(1 - p_2)^2})\n",
    "\\big) | p_1,p_2] =\\\\=\n",
    "\\mathbb{1}[i=1, j=1](\\frac{p_1 n_1}{p_1^2} + \\frac{n_1 - p_1 n_1}{(1 - p_1)^2}) +\n",
    "\\mathbb{1}[i=2, j=2](\\frac{p_2 n_2}{p_2^2} + \\frac{n_2 - p_2 n_2}{(1 - p_2)^2})\n",
    "=\\\\=\n",
    "\\mathbb{1}[i=1, j=1](\\frac{n_1}{p_1} + \\frac{n_1}{1 - p_1}) + \n",
    "\\mathbb{1}[i=2, j=2](\\frac{n_2}{p_2} + \\frac{n_2}{1 - p_2})\n",
    "=\\\\=\n",
    "\\mathbb{1}[i=1, j=1]\\frac{n_1}{p_1(1 - p_1)} + \n",
    "\\mathbb{1}[i=2, j=2]\\frac{n_2}{p_2(1 - p_2)}\n",
    "}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e8087c",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3. Используя многопараметрический дельта-метод найдите асимптотическую стандартную ошибку для $\\mlepsi$.\n",
    "\n",
    "Применим дельта-метод.\n",
    "Мы знаем, что\n",
    "$ \\sqrt{n}(B - \\beta) \\xrightarrow[]{D} \\Normal(0, \\Sigma)\n",
    "$, где \n",
    "$\\\\\n",
    "n = n_1 + n_2;\\,\\,n_1 \\rightarrow \\infty \\text{ и } n_2 \\rightarrow \\infty \\text{ при } n \\rightarrow \\infty\\\\\n",
    "B = \\hat\\theta = (\\frac{X_{1 n}}{n_1}, \\frac{X_{2 n}}{n_2}), \\\\\n",
    "\\beta = \\Exp[\\hat\\theta] = (p_1, p_2), \\\\\n",
    "\\Sigma = I_0(p_1,p_2)^{-1}$\n",
    "\n",
    "$I_0 -$ Информация Фишера в одном наблюдении, $I_0 = I/n$,\n",
    "\n",
    "$\n",
    "\\Sigma = n I(p_1,p_2)^{-1} = n \\cdot\\text{diag}(\\frac{p_1(1-p_1)}{n_1}, \\frac{p_2(1-p_2)}{n_2})\n",
    "$\n",
    "\n",
    "Тогда, используя дельта-метод для функции $h(x, y) = x - y$, получаем:\n",
    "\n",
    "${\\displaystyle\n",
    "\\sqrt{n}(h(B) - h(\\beta)) \\xrightarrow[]{D} \\Normal(0, \\nabla h(\\beta)^T \\cdot \\Sigma \\cdot \\nabla h(\\beta)) \\\\\n",
    "\\sqrt{n}(\\frac{X_{1 n}}{n_1} - \\frac{X_{2 n}}{n_2} - (p_1 - p_2)) \\xrightarrow[]{D}\n",
    "\\Normal(0, n(\\frac{p_1(1-p_1)}{n_1} + \\frac{(-1)p_2(1-p_2)(-1)}{n_2})) \\\\\n",
    "({\\mlepsi}_n - (p_1 - p_2)) \\xrightarrow[]{D}\n",
    "\\Normal(0, \\frac{p_1(1-p_1)}{n_1} + \\frac{p_2(1-p_2)}{n_2})\n",
    "}$\n",
    "\n",
    "Асимптотическая стандартная ошибка $\\mlepsi$ равна $\\sqrt{\\frac{p_1(1-p_1)}{n_1} + \\frac{p_2(1-p_2)}{n_2}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eba92c",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4. Допустим, что $n_1=n_2=200$, и конкретные значения случайных величин $X_1$ и $X_2$ равны $160$ и $148$ соответственно. Чему в этом случае равна оценка  $\\mlepsi$. Найдите приблизительный (асимптотический) 90\\%-ый доверительный интервал для $\\psi$, используя (а) многопараметрический дельта-метод и (б) параметрический бутстреп.\n",
    "\n",
    "$\\mlepsi = \n",
    "\\frac{X_1}{n_1} - \\frac{X_2}{n_2} =\n",
    "\\frac{160}{200} - \\frac{148}{200} = 0.06\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1699,
   "id": "9b5372ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical mle\t0.06000\n",
      "Numerical mle\t0.06000\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1698;\n",
       "                var nbb_unformatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\\nbin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\\nprint(\\n    f\\\"\\\"\\\"Analytical mle\\\\t{\\n    bin_log_density_first.calculate_analytical_parameter_mle()\\n    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\\\n\\n    Numerical mle\\\\t{\\n    bin_log_density_first.calculate_numerical_parameter_mle()\\n    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\\\"\\\"\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_log_density_first = BinomialLogDensity(n_positive=160, n=200)\n",
    "bin_log_density_second = BinomialLogDensity(n_positive=148, n=200)\n",
    "print(\n",
    "    f\"\"\"Analytical mle\\t{\n",
    "    bin_log_density_first.calculate_analytical_parameter_mle()\n",
    "    - bin_log_density_second.calculate_analytical_parameter_mle():.5f}\\nNumerical mle\\t{\n",
    "    bin_log_density_first.calculate_numerical_parameter_mle()\n",
    "    - bin_log_density_second.calculate_numerical_parameter_mle():.5f}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b7dfd",
   "metadata": {},
   "source": [
    "\n",
    "$\\hatse = \n",
    "\\sqrt{\\frac{p_1(1-p_1)}{n_1} + \\frac{p_2(1-p_2)}{n_2}} =\n",
    "\\sqrt{\\frac{0.8(1-0.8) + 0.74(1-0.74)}{200}} \\approx 0.042\n",
    "$\n",
    "\n",
    "Ассимптотические интервалы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2176,
   "id": "fed8c9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2175;\n",
       "                var nbb_unformatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_formatted_code = \"@dataclasses.dataclass\\nclass Psi:\\n    x_1: int\\n    x_2: int\\n    n: int\\n\\n    @property\\n    def p_1_estimate(self):\\n        return self.x_1 / self.n\\n\\n    @property\\n    def p_2_estimate(self):\\n        return self.x_2 / self.n\\n\\n    @property\\n    def mle_estimate(self):\\n        return self.p_1_estimate - self.p_2_estimate\\n\\n    @property\\n    def standard_error_estimate(self):\\n        p_1 = self.p_1_estimate\\n        p_2 = self.p_2_estimate\\n        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\\n\\n    def rvs(self, n_samples=1):\\n        first_binom = stats.binom(self.n, self.p_1_estimate)\\n        second_binom = stats.binom(self.n, self.p_2_estimate)\\n        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\\n\\n\\npsi = Psi(x_1=160, x_2=148, n=200)\\nconfidence_level = 0.90\\n\\ndelta_method_interval = get_asymptoticaly_normal_confidence_interval(\\n    mean=psi.mle_estimate,\\n    standard_error_of_the_mean=psi.standard_error_estimate,\\n    confidence_level=confidence_level,\\n)\\n\\n\\nplt.figure(figsize=(8, 4))\\nplt.xlim([-0.1, 0.3])\\ninterval_y_level = 0.4\\n\\nplt.plot(\\n    delta_method_interval,\\n    [4 * interval_y_level] * 2,\\n    lw=7,\\n    label=f\\\"delta method\\\\n{confidence_level:.0%} interval\\\",\\n)\\n\\nplot_different_bootstrap_confidence_intervals(\\n    estimate=psi.mle_estimate,\\n    bootstrap_samples=psi.rvs(1000),\\n    confidence_level=confidence_level,\\n    interval_y_level=interval_y_level,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class Psi:\n",
    "    x_1: int\n",
    "    x_2: int\n",
    "    n: int\n",
    "\n",
    "    @property\n",
    "    def p_1_estimate(self):\n",
    "        return self.x_1 / self.n\n",
    "\n",
    "    @property\n",
    "    def p_2_estimate(self):\n",
    "        return self.x_2 / self.n\n",
    "\n",
    "    @property\n",
    "    def mle_estimate(self):\n",
    "        return self.p_1_estimate - self.p_2_estimate\n",
    "\n",
    "    @property\n",
    "    def standard_error_estimate(self):\n",
    "        p_1 = self.p_1_estimate\n",
    "        p_2 = self.p_2_estimate\n",
    "        return ((p_1 * (1 - p_1) + p_2 * (1 - p_2)) / self.n) ** 0.5\n",
    "\n",
    "    def rvs(self, n_samples=1):\n",
    "        first_binom = stats.binom(self.n, self.p_1_estimate)\n",
    "        second_binom = stats.binom(self.n, self.p_2_estimate)\n",
    "        return (first_binom.rvs(n_samples) - second_binom.rvs(n_samples)) / self.n\n",
    "\n",
    "\n",
    "psi = Psi(x_1=160, x_2=148, n=200)\n",
    "confidence_level = 0.90\n",
    "\n",
    "delta_method_interval = get_asymptoticaly_normal_confidence_interval(\n",
    "    mean=psi.mle_estimate,\n",
    "    standard_error_of_the_mean=psi.standard_error_estimate,\n",
    "    confidence_level=confidence_level,\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.xlim([-0.1, 0.3])\n",
    "interval_y_level = 0.4\n",
    "\n",
    "plt.plot(\n",
    "    delta_method_interval,\n",
    "    [4 * interval_y_level] * 2,\n",
    "    lw=7,\n",
    "    label=f\"delta method\\n{confidence_level:.0%} interval\",\n",
    ")\n",
    "\n",
    "plot_different_bootstrap_confidence_intervals(\n",
    "    estimate=psi.mle_estimate,\n",
    "    bootstrap_samples=psi.rvs(1000),\n",
    "    confidence_level=confidence_level,\n",
    "    interval_y_level=interval_y_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747d6204",
   "metadata": {},
   "source": [
    "### Задача 2\n",
    "\n",
    "Пусть $\\boldX =\\{X_1,\\ldots,X_n\\} \\sim \\Poisson(\\lambda)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b7191",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. Постройте оценки $\\tillambda$ параметра $\\lambda$ с помощью метода моментов с использованием пробных функций $g_1(x) = x$ и $g_2(x) = x^2$.\n",
    "\n",
    "Оценка $\\tilde\\lambda_1$ согласно моменту $g_1$ :\n",
    "\n",
    "${\\displaystyle\n",
    "\\Exp(g_1(X)) = \\mean{g_1(\\boldX)}\\\\\n",
    "\\tilde\\lambda_1 = \\mean{\\boldX}\n",
    "}$\n",
    "\n",
    "Оценка $\\tilde\\lambda_2$ согласно моменту $g_2$ :\n",
    "\n",
    "${\\displaystyle\n",
    "\\Exp(g_2(X)) = \\mean{g_2(\\boldX)}\\\\\n",
    "\\Exp(X^2) = \\mean{\\boldX ^2}\\\\\n",
    "\\tilde\\lambda_2 + \\tilde\\lambda_2^2 = \\mean{\\boldX ^2}\\\\\n",
    "\\tilde\\lambda_2 = \\frac{-1 + \\sqrt{1 + 4\\mean{\\boldX ^2}}}{2}\n",
    "}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54514153",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. Постройте оценку $\\hatlambda$ параметра $\\lambda$ с помощью метода максимального правдоподобия. Найдите информацию Фишера $I_{X}(\\lambda)$. Является ли оценка $\\hatlambda$ эффективной?\n",
    "\n",
    "Оценка с помощью метода максимального правдоподобия:\n",
    "\n",
    "${\\displaystyle\n",
    "\\tilde\\lambda_\\text{mle} =\n",
    "\\argmax_\\lambda \\prod_i f(X_i; \\lambda) =\n",
    "\\argmax_\\lambda \\prod_i \\frac{\\lambda^{X_i} e^{-\\lambda}}{X_i!} =\n",
    "\\argmax_\\lambda \\sum_i \\ln (\\lambda^{X_i} e^{-\\lambda}) =\n",
    "\\argmax_\\lambda \\sum_i (X_i\\ln \\lambda -\\lambda) =\n",
    "\\argmax_\\lambda (-n \\lambda + \\ln \\lambda\\sum_i X_i) \n",
    "}\\\\\n",
    "$\n",
    "\n",
    "${\\displaystyle\n",
    "(-n \\lambda + \\ln \\lambda\\sum_i X_i)'_\\lambda = 0\\\\\n",
    "-n + \\frac{1}{\\lambda}\\sum_i X_i = 0\\\\\n",
    "\\tilde\\lambda_\\text{mle} = \\mean{\\boldX}\n",
    "}$\n",
    "\n",
    "Информация Фишера $\\mathcal I_{X}(\\lambda)$:\n",
    "\n",
    "$\n",
    "{\\displaystyle\n",
    "\\mathcal I_{X}(\\lambda) = \n",
    "-\\Exp [\\frac{\\partial^2}{\\partial \\lambda ^2} \\ln f(X; \\lambda) | \\lambda] =\n",
    "-\\Exp [\\frac{\\partial^2}{\\partial \\lambda ^2} \\ln \\frac{\\lambda^{X} e^{-\\lambda}}{X!} | \\lambda] =\n",
    "-\\Exp [\\frac{\\partial^2}{\\partial \\lambda ^2} (X\\ln\\lambda - \\lambda - \\ln X!) | \\lambda] =\\\\=\n",
    "-\\Exp [\\frac{\\partial}{\\partial \\lambda} (\\frac{X}{\\lambda} - 1) | \\lambda] =\n",
    "-\\Exp [-\\frac{X}{\\lambda^2} | \\lambda] =\n",
    "\\frac{\\Exp [X|\\lambda]}{\\lambda^2} =\n",
    "\\frac{1}{\\lambda}\n",
    "}\n",
    "$\n",
    "\n",
    "Вследствие аддитивности информации Фишера, которую содержат независимые случайные величины о параметре, в целом выборка $\\boldX$ содержит столько информации:\n",
    "\n",
    "$\\mathcal I_{\\boldX}(\\lambda) = \\frac{n}{\\lambda}$\n",
    "\n",
    "Поскольку эффективность несмещенной оценки определяется как \n",
    "\n",
    "${\\displaystyle e(\\tilde \\lambda)={\\frac {1/{\\mathcal {I}}(\\lambda )}{\\operatorname {var} (\\tilde\\lambda)}}}$, то\n",
    "\n",
    "${\\displaystyle\n",
    "e(\\tilde\\lambda_\\text{mle})={\\frac {\\lambda / n}{\\operatorname {var} (\\tilde\\lambda_\\text{mle})}} =\n",
    "{\\frac {\\lambda / n}{\\operatorname {var} (\\mean{\\boldX})}} =\n",
    "{\\frac {\\lambda / n}{\\lambda / n}} = 1\n",
    "}$\n",
    "\n",
    "и оценка $\\tilde\\lambda_\\text{mle}$ является несмещенной, то она также является эффективной с точки зрения информации Фишера, то есть она имеет наименьшую возможную дисперсию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2144,
   "id": "74816d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2143;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    true_parameter = get_apriori_probability()\\n    n = np.random.randint(10, 100)\\n    n_positive = int(true_parameter * n)\\n    log_density = BinomialLogDensity(n_positive=n_positive, n=n)\\n    log_density.check(true_parameter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclasses.dataclass()\n",
    "class PoissonLogDensity(LogDensity):\n",
    "    samples: torch.FloatTensor\n",
    "\n",
    "    def call(self, parameter):\n",
    "        return (\n",
    "            -len(self.samples) * parameter + torch.log(parameter) * self.samples.sum()\n",
    "        )\n",
    "\n",
    "    def sample_parameter(self):\n",
    "        return get_aprioiri_positive_parameter()\n",
    "\n",
    "    def calculate_analytical_parameter_mle(self):\n",
    "        return self.samples.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2146,
   "id": "6bb78cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2145;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = PoissonLogDensity(\\n        samples=torch.distributions.Poisson(parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    parameter = get_aprioiri_positive_parameter()\n",
    "    log_density = PoissonLogDensity(\n",
    "        samples=torch.distributions.Poisson(parameter).sample((100,))\n",
    "    )\n",
    "    log_density.check(true_parameter=parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5b7f96",
   "metadata": {},
   "source": [
    "### Задача 3\n",
    "Пусть $\\boldX =\\{X_1,\\dots,X_n\\} \\sim \\Pareto(\\theta, \\nu)$, $\\theta > 0$, $\\nu > 0$, с функцией плотности\n",
    "$$\n",
    "f_{\\theta, \\nu}(x) =\n",
    "\\begin{cases}\n",
    "\t\\frac{\\theta\\nu^{\\theta}}{x^{\\theta+1}}, \\quad & x \\ge \\nu,\\\\\n",
    "\t0, \\quad & x < \\nu\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "1. Найдите MLE-оценки $\\hattheta$ и $\\hat \\nu$ для параметров $\\theta$ и $\\nu$.\n",
    "1. Пусть параметр $\\nu$ известен. Найдите истинные значения $\\Exp_{\\theta}[\\hat{\\theta}]$ и $\\Var_{\\theta}[\\hat{\\theta}]$ как функции параметров $\\theta$, $\\nu$ и размера выборки $n$.\n",
    "Подсказка: следует использовать тот факт, что логарифм от случайной величины с распределением Парето имеет экспоненциальное распределение.\n",
    "1. Пусть параметр $\\nu$ известен. Найдите асимптотическое распределение оценки $\\hattheta$ с помощью дельта-метода.\n",
    "1. Пусть параметр $\\nu$ известен. Найдите информацию Фишера $I_X(\\theta)$. Является ли MLE-оценка параметра $\\hat{\\theta}$ эффективной?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d6074",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. Найдите MLE-оценки $\\hattheta$ и $\\hat \\nu$ для параметров $\\theta$ и $\\nu$\n",
    "\n",
    "$\n",
    "{\\displaystyle\n",
    "(\\hattheta, \\hat \\nu) =\n",
    "\\argmax_{\\theta, \\nu} \\prod_i \\frac{\\theta\\nu^{\\theta}}{X_i^{\\theta+1}}\\mathbb{1}[X_i \\geq \\nu] =\n",
    "\\argmax_{\\theta, \\nu}\\mathbb{1}[X_{(1)} \\geq \\nu] \\prod_i \\frac{\\theta\\nu^{\\theta}}{X_i^{\\theta+1}} =\n",
    "\\argmax_{\\theta, \\nu \\leq X_{(1)}} \\sum_i( \\ln\\theta + \\theta\\ln\\nu - (\\theta + 1) \\ln X_i) =\\\\=\n",
    "\\argmax_{\\theta, \\nu \\leq X_{(1)}} \\big(n\\ln\\theta + n\\theta\\ln\\nu - (\\theta + 1) \\sum_i\\ln X_i\\big)\n",
    "}\n",
    "$\n",
    "\n",
    "${\\displaystyle\n",
    "\\left[\\begin{aligned}\n",
    "    &\\begin{cases}\n",
    "        \\nu = X_{(1)} \\\\\n",
    "        \\big(n\\ln\\theta + n\\theta\\ln\\nu - (\\theta + 1) \\sum_i\\ln X_i\\big)'_\\theta = 0\\\\\n",
    "    \\end{cases}\\\\\n",
    "    &\\begin{cases}\n",
    "        \\nu < X_{(1)} \\\\\n",
    "        \\big(n\\ln\\theta + n\\theta\\ln\\nu - (\\theta + 1) \\sum_i\\ln X_i\\big)'_\\theta = 0\\\\\n",
    "        \\big(n\\ln\\theta + n\\theta\\ln\\nu - (\\theta + 1) \\sum_i\\ln X_i\\big)'_\\nu = 0\n",
    "    \\end{cases}\\\\\n",
    "\\end{aligned}\\right.\n",
    "\\Rightarrow\n",
    "\\left[\\begin{aligned}\n",
    "    &\\begin{cases}\n",
    "        \\nu = X_{(1)} \\\\\n",
    "        n/\\theta + n\\ln \\nu - \\sum_i\\ln X_i = 0\\\\\n",
    "    \\end{cases}\\\\\n",
    "    &\\begin{cases}\n",
    "        \\nu < X_{(1)} \\\\\n",
    "        n/\\theta + n\\ln \\nu - \\sum_i\\ln X_i = 0\\\\\n",
    "        n\\theta/\\nu = 0\n",
    "    \\end{cases}\\\\\n",
    "  \\end{aligned}\\right.\n",
    "\\Rightarrow\n",
    "\\begin{cases}\n",
    "    \\nu = X_{(1)} \\\\\n",
    "    1/\\theta = \\mean{\\ln\\boldX} - \\ln \\nu\n",
    "\\end{cases}\n",
    "\\Rightarrow\n",
    "\\begin{cases}\n",
    "    \\nu = X_{(1)} \\\\\n",
    "    \\theta = 1/(\\mean{\\ln\\boldX} - \\ln \\nu)\n",
    "\\end{cases}\n",
    "}$\n",
    "\n",
    "$${\\displaystyle\n",
    "\\hat \\nu = X_{(1)}\\\\\n",
    "\\hattheta = \\frac{1}{\\mean{\\ln\\boldX} - \\ln X_{(1)}}\n",
    "}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2148,
   "id": "d1cc1dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2147;\n",
       "                var nbb_unformatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n            \\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_formatted_code = \"class LogDensity:\\n    def __call__(self, parameter):\\n        if not torch.is_tensor(parameter):\\n            parameter = torch.tensor(parameter)\\n        return self.call(parameter)\\n\\n    def call(self, parameter):\\n        \\\"\\\"\\\"Return log pdf at parameter.\\\"\\\"\\\"\\n        raise NotImplementedError\\n\\n    def sample_parameter(self):\\n        raise NotImplementedError\\n\\n    def calculate_analytical_parameter_mle(self):\\n        raise NotImplementedError\\n\\n    def calculate_numerical_parameter_mle(self):\\n        return argmax(self, self.sample_parameter())\\n\\n    def plot_learning_curve(self):\\n        return plot_learning_curve(self, self.sample_parameter())\\n\\n    def calculate_mean_numerical_parameter_mle(self, n_runs=10):\\n        return (\\n            torch.stack(\\n                [self.calculate_numerical_parameter_mle() for _ in range(n_runs)]\\n            )\\n            .mean(0)\\n            .to(float)\\n        )\\n\\n    def check(self, true_parameter=None, rtol=1e-1, n_runs=10):\\n        analytical_mean_mle = self.calculate_analytical_parameter_mle().to(float)\\n        numerical_mean_mle = self.calculate_mean_numerical_parameter_mle(n_runs)\\n\\n        assert torch.allclose(\\n            analytical_mean_mle,\\n            numerical_mean_mle,\\n            rtol=rtol,\\n        ), (\\n            f\\\"Estimates don't match:\\\\nAnalytical mle\\\\t{analytical_mean_mle}\\\\n\\\"\\n            f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n        )\\n\\n        if true_parameter is not None:\\n            assert torch.allclose(\\n                true_parameter,\\n                analytical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Analytical mle\\\\t{analytical_mean_mle}\\\\n{self}\\\"\\n            )\\n            assert torch.allclose(\\n                true_parameter,\\n                numerical_mean_mle,\\n                rtol=0.5,\\n            ), (\\n                f\\\"Estimate doesn't match:\\\\nTrue parameter\\\\t{true_parameter}\\\\n\\\"\\n                f\\\"Numerical mle\\\\t{numerical_mean_mle}\\\\n{self}\\\"\\n            )\\n\\n\\ndef get_apriori_probability():\\n    return torch.distributions.Beta(10, 10).sample().to(float)\\n\\n\\ndef get_aprioiri_positive_parameter(mean=10):\\n    return torch.distributions.Poisson(mean).sample().to(float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclasses.dataclass()\n",
    "class ParetoLogDensity(LogDensity):\n",
    "    samples: torch.FloatTensor\n",
    "\n",
    "    def call(self, parameter):\n",
    "        theta, nu = parameter\n",
    "        if self.samples.min() < nu:\n",
    "            return -100 * nu\n",
    "        return (\n",
    "            len(self.samples) * (torch.log(theta) + theta * torch.log(nu))\n",
    "            - (theta + 1) * torch.log(self.samples).sum()\n",
    "        )\n",
    "\n",
    "    def sample_parameter(self):\n",
    "        return torch.tensor(\n",
    "            [\n",
    "                get_aprioiri_positive_parameter(),\n",
    "                get_aprioiri_positive_parameter() + self.samples.min(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def calculate_analytical_parameter_mle(self):\n",
    "        return torch.tensor(\n",
    "            [\n",
    "                1 / (torch.log(self.samples).mean() - torch.log(self.samples.min())),\n",
    "                self.samples.min(),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2155,
   "id": "e2b87de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2154;\n",
       "                var nbb_unformatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_formatted_code = \"log_density.plot_learning_curve()[1].epoch_stats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    parameter = torch.tensor(\n",
    "        [\n",
    "            get_aprioiri_positive_parameter(),\n",
    "            get_aprioiri_positive_parameter(),\n",
    "        ]\n",
    "    ).to(float)\n",
    "    log_density = ParetoLogDensity(\n",
    "        samples=torch.distributions.Pareto(*parameter.flip(0)).sample((10,))\n",
    "    )\n",
    "    log_density.check(true_parameter=parameter, rtol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc607a6",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. Пусть параметр $\\nu$ известен. Найдите истинные значения $\\Exp_{\\theta}[\\hat{\\theta}]$ и $\\Var_{\\theta}[\\hat{\\theta}]$ как функции параметров $\\theta$, $\\nu$ и размера выборки $n$.\n",
    "Подсказка: следует использовать тот факт, что логарифм от случайной величины с распределением Парето имеет экспоненциальное распределение.\n",
    "\n",
    "${\\displaystyle\n",
    "\\Exp_{\\theta}[\\hat{\\theta}] =\n",
    "\\Exp_{\\theta}\\left[\\frac{1}{\\mean{\\ln\\boldX} - \\ln \\nu}\\right] =\n",
    "\\int_{\\nu}^\\infty \\dots \\int_{\\nu}^\\infty \\frac{1}{\\mean{\\ln\\boldX} - \\ln \\nu} \\prod_i\\frac{\\theta\\nu^{\\theta}}{X_i^{\\theta+1}} d X_i =\n",
    "\\int_{\\nu}^\\infty \\dots \\int_{\\nu}^\\infty \\frac{n}{\\sum_j\\ln X_j - n\\ln \\nu} \\frac{\\theta^n \\nu^{n\\theta}}{\\prod_i X_i^{\\theta}} d \\ln X_i \\stackrel{Y_i := \\ln X_i}{=}\n",
    "}$\n",
    "\n",
    "${\\displaystyle=\n",
    "n\\theta^n \\nu^{n\\theta} \\int_{\\ln\\nu}^\\infty \\dots \\int_{\\ln\\nu}^\\infty \\frac{1}{\\sum_j Y_j - n\\ln \\nu} \\frac{1}{e^{\\theta\\sum_j Y_j}}\\prod_i d Y_i \\stackrel{Y_i := Z_i/\\theta + \\ln\\nu}{=}\n",
    "n\\theta^n \\nu^{n\\theta} \\int_{0}^\\infty \\dots \\int_{0}^\\infty \\frac{1}{\\sum_j Z_j/\\theta} \\frac{1}{e^{n\\theta\\ln\\nu + \\sum_j Z_j}} \\prod_i \\frac{dZ_i}{\\theta} =\n",
    "}$\n",
    "\n",
    "${\\displaystyle=\n",
    "\\frac{n\\theta^{n} \\nu^{n\\theta}\\theta}{e^{n\\theta\\ln\\nu}\\theta^{n}} \\int_{0}^\\infty \\dots \\int_{0}^\\infty \\frac{1}{\\sum_j Z_j} \\frac{1}{e^{\\sum_j Z_j}} \\prod_i dZ_i =\n",
    "\\theta nC_n\n",
    "}$,\n",
    "\n",
    "где\n",
    "\n",
    "${\\displaystyle\n",
    "C_n =\\int_{0}^\\infty \\dots \\int_{0}^\\infty \\frac{1}{\\sum_j^n Z_j} \\frac{1}{e^{\\sum_j^n Z_j}} dZ_1 \\dots dZ_n\n",
    "}$\n",
    "\n",
    "${\\displaystyle\n",
    "\\Var_{\\theta}[\\hat{\\theta}] =\n",
    "\\Exp_{\\theta}[\\hat{\\theta}^2] - (\\theta nC_n)^2 =\n",
    "\\theta n^2 D_n - (\\theta nC_n)^2 =\n",
    "\\theta n^2(D_n - \\theta C_n^2)\n",
    "}$,\n",
    "\n",
    "где\n",
    "\n",
    "${\\displaystyle\n",
    "D_n =\\int_{0}^\\infty \\dots \\int_{0}^\\infty \\frac{1}{(\\sum_j Z_j)^2} \\frac{1}{e^{\\sum_j Z_j}} dZ_1 \\dots dZ_n\n",
    "}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ec686",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3. Пусть параметр $\\nu$ известен. Найдите асимптотическое распределение оценки $\\hattheta$ с помощью дельта-метода.\n",
    "Воспользуемся тем, что случайные величины $Y_i = \\ln X_i - \\ln\\nu$ распределены экспоненциально с параметром $\\theta$:\n",
    "\n",
    "${\\displaystyle\n",
    "\\hattheta = \n",
    "\\frac{1}{\\mean{\\ln\\boldX} - \\ln \\nu} =\n",
    "\\frac{1}{\\mean{\\boldY}}\n",
    "}$\n",
    "\n",
    "Теперь применим дельта-метод.\n",
    "\n",
    "$\\displaystyle{\n",
    "\\sqrt{n}(\\mean{\\boldY} - \\Exp[Y]) \\xrightarrow[]{D} \\Normal(0, \\Var[Y])\\\\\n",
    "\\sqrt{n}(\\mean{\\boldY} - \\frac{1}{\\theta}) \\xrightarrow[]{D} \\Normal(0, \\frac{1}{\\theta^2})\n",
    "}$\n",
    "\n",
    "Возьмем функцию $h(x) = \\frac{1}{x}$.\n",
    "\n",
    "$\\displaystyle{\n",
    "\\sqrt{n}(h(\\mean{\\boldY}) - h(\\frac{1}{\\theta})) \\xrightarrow[]{D} \\Normal(0, h(\\frac{1}{\\theta})''\\frac{1}{\\theta^2})\\\\\n",
    "\\sqrt{n}(\\frac{1}{\\mean{\\boldY}} - \\theta) \\xrightarrow[]{D} \\Normal(0,\\left(\\frac{1}{-\\frac{1}{\\theta^2}}\\right)^2\\frac{1}{\\theta^2})\\\\\n",
    "\\sqrt{n}(\\frac{1}{\\mean{\\boldY}} - \\theta) \\xrightarrow[]{D} \\Normal(0, \\theta^2)\n",
    "}\n",
    "$\n",
    "\n",
    "И тогда ассимптотическое распределение равно\n",
    "\n",
    "$\\displaystyle{\n",
    "\\hattheta = \\frac{1}{\\mean{\\boldY}} \\sim \\Normal(\\theta,\\frac{\\theta^2}{n})\n",
    "}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033ffc1",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4. Пусть параметр $\\nu$ известен. Найдите информацию Фишера $I_X(\\theta)$. Является ли MLE-оценка параметра $\\hat{\\theta}$ эффективной?\n",
    "\n",
    "$\\displaystyle{\n",
    "\\mathcal I_{X}(\\theta) = \n",
    "-\\Exp [\\frac{\\partial^2}{\\partial \\theta ^2} \\ln f(X; \\theta) | \\theta] =\n",
    "-\\Exp [-\\frac{1}{\\theta^2} | \\theta] =\n",
    "\\frac{1}{\\theta^2}\n",
    "}$\n",
    "\n",
    "Поскольку оценка $\\hat{\\theta}$ является смещенной, то она не эффективна. Но ассимтотически она не смещена, а также $\\displaystyle{\\mathcal I_{\\boldX}(\\theta) = n\\mathcal I_{X}(\\theta) = \\frac{n}{\\theta^2} = \\frac{1}{\\Var_{\\theta}[\\hat{\\theta}] }} $, значит ассимтотически оценка эффективна."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c8d71",
   "metadata": {},
   "source": [
    "### Задача 4\n",
    "Пусть $\\boldX = \\{X_1,\\ldots,X_n\\} \\sim \\Uniform(0,\\theta)$, $Y = \\max\\{X_1,\\ldots,X_n\\}$.  Необходимо протестировать основную гипотезу $H_0:\\theta = 1/2$ против альтернативы $H_1: \\theta > 1/2$. В данном случае нельзя использовать тест Вальда, так как $Y$ при $n\\to\\infty$ не сходится к нормальному распределению. Допустим, что мы будем использовать следующее правило: гипотеза $H_0$ отвергается, если $Y > c$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0517ad13",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. Найдите функцию мощности для данного теста.\n",
    "\n",
    "*Критическая область* - подмножество $\\mathbb{R}$, в котором должны оказаться значения статистики (критерия), чтобы отвергнуть нулевую гипотезу. Обычно это множество берется из определенного семейства, в данном случае это семейство множеств, параметризованных числом $c$: $\\mathcal{R}_c = \\{x\\in\\mathbb{R} | x > c\\}$.\n",
    "\n",
    "*Функция мощности критерия*, то есть вероятность отвергнуть нулевую гипотезу в зависимости от параметра распределения наблюдаемых случайных величин:\n",
    "\n",
    "$\\displaystyle{\n",
    "\\beta_\\mathcal{R}(\\theta) = \\beta(\\theta) := \n",
    "P_\\theta(Y \\in \\mathcal{R}) =\n",
    "P_\\theta(Y > c) =\n",
    "P_\\theta(\\max\\{X_1,\\ldots,X_n\\} > c) =\n",
    "1 - P_\\theta(\\max\\{X_1,\\ldots,X_n\\} \\leq c) =\\\\=\n",
    "1 - \\prod_i P_\\theta(X_i \\leq c) =\n",
    "1 - \\prod_i (\\max(0,\\min(1,\\frac{c}{\\theta})) =\n",
    "1 - \\max(0,\\min(1,\\frac{c}{\\theta}))^n\n",
    "}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d3aea",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. При каком значении параметра $c$ размер теста будет равен $0.05$?\n",
    "\n",
    "*Размер теста (критерия)* - (максимальная) вероятность ошибки первого рода, или вероятность некорректно отвергнуть нулевую гипотезу:\n",
    "\n",
    "$\\displaystyle{\n",
    "\\alpha(\\mathcal{R}) = \n",
    "\\alpha := \n",
    "\\sup_{H_0} \\beta_\\mathcal{R}(\\theta) =\n",
    "\\sup_{H_0} P_\\theta(Y \\in \\mathcal{R}) =\n",
    "1 - \\max(0,\\min(1,\\frac{c}{1/2}))^n =\n",
    "1 - (2c)^n =\n",
    "0.05\\\\\n",
    "c = \\frac{0.95^{1/n}}{2}\n",
    "}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f560197",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3. Каково значение $\\pvalue$, если размер выборки $n = 20$ и $Y = 0.48$? Что можно сказать о гипотезе $H_0$?\n",
    "\n",
    "Общее определение p-value можно сформулировать, как наименьший размер критерия в зависимости от критической области, при условии, что критерий от данной реализации выборки $x^n$ лежит в этой критической области, и критическая область лежит в данном семействе:\n",
    "\n",
    "$\\displaystyle{\n",
    "\\pvalue = \n",
    "\\inf_{\\mathcal{R} \\in R}\\{\\alpha(\\mathcal{R}): T(x^n) \\in \\mathcal{R}\\}\n",
    "}$\n",
    "\n",
    "Чтобы такое определение можно было применять, нужно уточнить, какие семейства имеются в виду. Обычно это семейства всевозможных одно- или двунаправленных лучей. Если $R = \\{\\mathcal{R}_c\\} = \\{\\{x\\in\\mathbb{R} | x \\geq c\\}|\\forall c \\in \\mathbb{R}\\}$, то с учетом того, что $\\alpha(\\mathcal{R}_{c_1}) \\geq \\alpha(\\mathcal{R}_{c_2})$, если $c_1 \\leq c_2$ определение можно упростить:\n",
    "\n",
    "$\\displaystyle{\n",
    "\\pvalue = \n",
    "\\inf_{\\mathcal{R}_c}\\{\\alpha(\\mathcal{R}_c): T(x^n) \\in \\mathcal{R}_c\\} =\n",
    "\\alpha(\\mathcal{R}_{T(x^n)})=\n",
    "\\sup_{\\lnot H_0} P_\\theta(T(\\boldX) \\geq T(x^n)) \n",
    "}$\n",
    "\n",
    "и, если $H_0 : \\displaystyle{ \\theta = \\theta_0}$ и распределение непрерывно,\n",
    "\n",
    "$\\displaystyle{\n",
    "\\pvalue = P_{\\theta_0}(T(\\boldX) \\geq T(x^n))\n",
    "}$\n",
    "\n",
    "Получилось, что p-value - это вероятность того, что значение критерия от выборки будет не менее экстремальным (с точки зрения семейства критических областей), чем критерий от данной реализации выборки, или интуитивно - показатель того, насколько типична реализации выборки для нулевой гипотезы.\n",
    "\n",
    "$\\displaystyle{\n",
    "\\pvalue = \n",
    "P_{\\theta=1/2}(X_{(n)} \\geq 0.48) = \n",
    "1 - (\\frac{0.48}{1/2})^{20} \\approx\n",
    "0.558\n",
    "}$\n",
    "\n",
    "Такое высокое значение $\\pvalue$ показывает, что данная реализация выборки довольно типична для нулевой гипотезы, и ее отвергать не стоит."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed8269",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4. Каково значение $\\pvalue$, если размер выборки $n = 20$ и $Y = 0.52$? Что можно сказать о гипотезе $H_0$?\n",
    "\n",
    "$\\displaystyle{\n",
    "\\pvalue = \n",
    "1 - \\max(0,\\min(1, \\frac{0.52}{1/2}))^{20} =\n",
    "1 - 1 = 0\n",
    "}$\n",
    "\n",
    "Такое низкое значение $\\pvalue$ показывает, что данная реализация невозможна для нулевой гипотезы, и следует ее отвергнуть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a239036",
   "metadata": {},
   "source": [
    "### Задача 5\n",
    "Пусть $\\boldX = \\{X_1,\\dots,X_n\\} \\sim \\Exponential(\\theta)$. Постройте критерий отношения правдоподобий для проверки гипотезы $H_0: \\theta = \\theta_0$ vs $H_1 : \\theta > \\theta_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e21a5",
   "metadata": {},
   "source": [
    "Правдоподобие:\n",
    "\n",
    "$\\displaystyle{\n",
    "L(\\theta) = \n",
    "\\prod_{i=1}^n f_\\theta(X_i) =\n",
    "\\prod_{i=1}^n \\theta e^{-\\theta X_i} =\n",
    "\\theta^n e^{-\\theta \\sum_{i=1}^n X_i}\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "\\ln L(\\theta) = \n",
    "n \\ln\\theta  -\\theta \\sum_{i=1}^n X_i =\n",
    "n (\\ln\\theta  -\\mean{\\boldX})\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "\\theta^\\text{mle} = \n",
    "\\argmax_{\\theta \\geq \\theta_0} L(\\theta)= \n",
    "\\argmax_{\\theta \\geq \\theta_0} \\ln L(\\theta) =\n",
    "\\argmax_{\\theta \\geq \\theta_0} n (\\ln\\theta  -\\mean{\\boldX}) =\n",
    "\\left[\\begin{aligned}\n",
    "&\\mean{\\boldX},\\,\\,\\, \\mean{\\boldX} > \\theta_0 \\\\\n",
    "&\\theta_0\\,\\,\\,\\,\\,\\,\\, \\text{иначе}\n",
    "\\end{aligned}\\right.\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "\\theta_0^\\text{mle} = \\argmax_{\\theta =\\theta_0} L(\\theta) = \\theta_0\n",
    "}$\n",
    "\n",
    "Критерий отношения правдоподобий:\n",
    "\n",
    "$\\displaystyle{\n",
    "\\lambda := \n",
    "2\\left(\\ln L(\\theta^\\text{mle}) - \\ln L(\\theta_0^\\text{mle})\\right) =\n",
    "2\\left(n (\\ln\\theta^\\text{mle}  -\\mean{\\boldX}) - n (\\ln\\theta_0^\\text{mle}  -\\mean{\\boldX}))\\right) =\n",
    "\\left[\\begin{aligned}\n",
    "&2n\\left(\\ln\\mean{\\boldX} - \\ln\\theta_0\\right), \\,\\,\\mean{\\boldX} > \\theta_0 \\\\\n",
    "&0\\,\\,\\,\\,\\,\\,\\, \\text{иначе}\n",
    "\\end{aligned}\\right.\n",
    "}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c6f3b4",
   "metadata": {},
   "source": [
    "### Задача 6\n",
    "Пусть $\\boldX = \\{X_1,\\ldots,X_n\\} \\sim \\Normal(\\mu,\\sigma^2)$, где параметр $\\mu$ известен. Требуется протестировать гипотезу $H_0\\colon \\sigma = \\sigma_0$ против альтернативы $H_1 \\colon \\sigma \\neq \\sigma_0$.\n",
    "\n",
    "---\n",
    "#### 1. Постройте критерий отношения правдоподобий для различения гипотез $H_0$ и $H_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47911d4e",
   "metadata": {},
   "source": [
    "Введем обозначение $Y_i = X_i -\\mu$.\n",
    "\n",
    "$\\displaystyle{\n",
    "L(\\sigma) = \n",
    "\\prod_{i=1}^n f_\\sigma(Y_i) =\n",
    "\\prod_{i=1}^n \\frac {1}{\\sigma {\\sqrt {2\\pi }}}}e^{-{\\frac {1}{2}}\\left({\\frac {Y_i}{\\sigma }}\\right)^{2}\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "\\sigma^\\text{mle} = \n",
    "\\argmax_{\\sigma} L(\\sigma)=\n",
    "\\argmax_{\\sigma} \\ln L(\\sigma)=\n",
    "\\argmax_{\\sigma} \\sum_{i=1}^n\\left(\n",
    "\\ln \\frac {1} {\\sigma\\sqrt {2\\pi }} -{\\frac {1}{2}}\\left({\\frac {Y_i}{\\sigma }}\\right)^{2}\n",
    "\\right)=\n",
    "\\argmax_{\\sigma} \\left(-n\\ln \\sigma -\n",
    "\\sum_{i=1}^n{\\frac {1}{2}}\\left({\\frac {Y_i}{\\sigma }}\\right)^{2}\\right)\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "-\\frac{n}{\\sigma^\\text{mle}} - \n",
    "\\sum_{i=1}^n \\frac {-2}{2}\n",
    "\\left({\\frac{(X_i-\\mu )^2}{(\\sigma^\\text{mle}) ^3 }}\\right)} = 0\\\\\n",
    "-n (\\sigma^\\text{mle}) ^2 + \n",
    "\\sum_{i=1}^n (Y_i)^2 = 0\\\\\n",
    "\\sigma^\\text{mle} = \\sqrt{\\frac{\\sum_{i=1}^n(Y_i)^2}{n}} = \\sqrt{\\mean{\\boldY^2}}\n",
    "$\n",
    "\n",
    "$\\displaystyle{\n",
    "\\sigma_0^\\text{mle} = \n",
    "\\argmax_{\\sigma =\\sigma_0} L(\\sigma)= \\sigma_0\n",
    "}$\n",
    "\n",
    "Критерий отношения правдоподобий:\n",
    "\n",
    "$\\displaystyle{\n",
    "\\lambda := \n",
    "2\\left(\\ln L(\\sigma^\\text{mle}) - \\ln L(\\sigma_0^\\text{mle})\\right) =\n",
    "2\\left(\n",
    "\\left(-n\\ln \\sigma^\\text{mle} -\\sum_{i=1}^n{\\frac {1}{2}}\\left({\\frac {Y_i}{\\sigma^\\text{mle} }}\\right)^{2}\\right) - \n",
    "\\left(-n\\ln \\sigma_0^\\text{mle} - \\sum_{i=1}^n{\\frac {1}{2}}\\left({\\frac {Y_i}{\\sigma_0^\\text{mle} }}\\right)^{2}\\right)\n",
    "\\right) =\\\\=\n",
    "2\\left(\n",
    "\\left(-n\\ln \\sqrt{\\mean{(\\boldY)^2}} -\\sum_{i=1}^n{\\frac {1}{2}}\\left({\\frac {Y_i}{\\sqrt{\\mean{(\\boldY)^2}} }}\\right)^{2}\\right) - \n",
    "\\left(-n\\ln \\sigma_0 - \\sum_{i=1}^n{\\frac {1}{2}}\\left({\\frac {Y_i}{\\sigma_0 }}\\right)^{2}\\right)\n",
    "\\right) =\\\\=\n",
    "2\\left(\n",
    "-n\\ln \\sqrt{\\mean{(\\boldY)^2}} -\\frac {n\\sum_{i=1}^n(Y_i)^2}{2\\sum_{i=1}^n Y_i^2} +\n",
    "n\\ln \\sigma_0 + {n\\frac {\\mean{(\\boldY)^2}}{2\\sigma_0^2}}\n",
    "\\right) =\\\\=\n",
    "2n\\left(\n",
    "-\\frac{\\ln \\mean{(\\boldY)^2}}{2} -\\frac {1}{2} +\n",
    "\\ln \\sigma_0 + {\\frac {\\mean{\\boldY^2}}{2\\sigma_0^2}}\n",
    "\\right)=\\\\=\n",
    "n\\left(\n",
    "-\\ln \\mean{(\\boldY)^2} -1 +\n",
    "\\ln \\sigma_0^2 + {\\frac {\\mean{\\boldY^2}}{\\sigma_0^2}}\n",
    "\\right)=\\\\=\n",
    "n\\left( {\\frac {\\mean{\\boldY^2}}{\\sigma_0^2}} - \\ln {\\frac {\\mean{\\boldY^2}}{\\sigma_0^2} - 1}\n",
    "\\right)\n",
    "}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b34573",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. Постройте критерий Вальда для различения гипотез $H_0$ и $H_1$.\n",
    "\n",
    "${\\displaystyle\n",
    "W^2 := \n",
    "\\frac{(\\sigma^\\text{mle}-\\sigma_0)^2}{\\hat{\\operatorname{var}} (\\sigma^\\text{mle})} \n",
    "}$\n",
    "\n",
    "Оценим дисперсию $\\sigma^\\text{mle}$ как $\\cfrac{1}{I(\\sigma^\\text{mle})}$,\n",
    "\n",
    "${\\displaystyle\n",
    "I(\\sigma) =\n",
    "-\\Exp [\\frac{\\partial^2}{\\partial \\sigma ^2} \\ln f(\\boldY; \\sigma) | \\sigma] =\n",
    "-\\Exp \\left[\\frac{\\partial^2}{\\partial \\sigma ^2}\\left(-n\\ln \\sigma -\\frac {1}{2\\sigma^2}\\sum_{i=1}^n Y_i^{2}\\right) \\big| \\sigma\\right] =\\\\\n",
    "=\\Exp \\left[\\left(-\\frac{n}{\\sigma^2} +\\frac{3}{\\sigma^4}\\sum_{i=1}^n Y_i^{2}\\right) \\big| \\sigma\\right] =\n",
    "-\\frac{n}{\\sigma^2} +\\frac{3}{\\sigma^4}(n\\sigma^2) =\n",
    "\\frac{2n}{\\sigma^2}\n",
    "}$\n",
    "\n",
    "${\\displaystyle\n",
    "W^2 =\n",
    "(\\sigma^\\text{mle}-\\sigma_0)^2 \\frac{2n}{(\\sigma^\\text{mle})^2} =\n",
    "2n\\left( 1 - \\frac{\\sigma_0}{\\sigma^\\text{mle}}\\right)^2 =\n",
    "2n\\left( 1 - \\frac{\\sigma_0}{\\sqrt{\\mean{\\boldY^2}}}\\right)^2\n",
    "}$\n",
    "\n",
    "${\\displaystyle\n",
    "W =\n",
    "\\sqrt{2n}\\left( 1 - \\frac{\\sigma_0}{\\sqrt{\\mean{\\boldY^2}}}\\right)\n",
    "}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33c6d3",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3. Сравните аналитически полученные критерии. Сравнить (как аналитически, так и экспериментально) полученный тест с тестом Вальда для различения этих гипотез.\n",
    "\n",
    "\n",
    "*Примечание. Аналитическое сравнение тестов подразумевает доказательство их (асимптотической) эквивалентности или неэквивалентности, где под эквивалентностью понимается идентичность выносимых тестами решений.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c0a89e",
   "metadata": {},
   "source": [
    "Поскольку и критерий Вальда, и критерий отношения правдоподобий сравниваются с квантилями одного и того же распределения - хи-квадрат с одной степенью свободы, но при этом они принимают разные значения на одних и тех же выборках, то они не эквивалентны. Но ассимптотически они сходятся, покажем это:\n",
    "\n",
    "Пусть $x = \\sqrt{\\cfrac {\\mean{\\boldY^2}}{\\sigma_0^2}}$, тогда значения критериев соответственно равны \n",
    "\n",
    "${\\displaystyle\n",
    "\\lambda = n (x^2 - \\ln x^2 -1),\\\\\n",
    "W^2 = 2n(1 - \\frac{1}{x})^2\n",
    "}$\n",
    "\n",
    "При условии выполнения нулевой гипотезы $x\\rightarrow 1$. Найдем предел отношения критериев с помощью правила Лопиталя:\n",
    "\n",
    "${\\displaystyle \n",
    "\\lim_{n \\rightarrow \\infty} \\frac{\\lambda}{W^2} =\n",
    "\\lim_{n \\rightarrow \\infty} \\frac{x^2 - \\ln x^2 -1}{2(1 - \\frac{1}{x})^2} =\n",
    "\\lim_{n \\rightarrow \\infty} \\frac{2x - 2\\frac{1}{x}}{4(1 - \\frac{1}{x})\\frac{1}{x^2}} =\n",
    "\\lim_{n \\rightarrow \\infty} \\frac{x^4 - x^2}{2(x - 1)} =\n",
    "\\lim_{n \\rightarrow \\infty} \\frac{4x^3 - 2x}{2} =\n",
    "\\frac{4 - 2}{2} = 1\n",
    "}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80217da9",
   "metadata": {},
   "source": [
    "Также хочется привести формулу критерия Вальда для нелинейных ограничений:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637e18f9",
   "metadata": {},
   "source": [
    "${\\displaystyle\n",
    "H_{0}:c(\\theta )=0\\\\\n",
    "H_{1}:c(\\theta )\\neq0\\\\\n",
    "}$\n",
    "\n",
    "${\\displaystyle\n",
    "W^2 = \n",
    "\\frac{c(\\hat\\theta)^2}{(c(\\theta)')^2 \\hat{\\operatorname{var}}\\hat\\theta}\n",
    "}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48899f90",
   "metadata": {},
   "source": [
    "Нетрудно увидеть, что критерий отношения правдоподобий инвариантен относительно алгебраически эквивалентных ограничений на параметры, которые устанавливает нулевая гипотеза. Например, вместо ограничения $\\sigma -\\sigma_0 = 0$ можно было рассмотреть аналогичное ограничение $(\\sigma - \\sigma_0)^2 = 0$, и получить одинаковые значения критерия отношения правдоподобий, что ожидаемо и интуитивно. С другой стороны, значение критерия Вальда в таком случае изменится, что показывает его нестабильность на малых выборках, и служит напоминанием, что его следует использовать в основном на выборках большого объема."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2181,
   "id": "4758f808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2180;\n",
       "                var nbb_unformatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_formatted_code = \"for _ in range(5):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclasses.dataclass()\n",
    "class NormalLogDensity(LogDensity):\n",
    "    samples: torch.FloatTensor\n",
    "\n",
    "    def call(self, sigma):\n",
    "        return (\n",
    "            -len(self.samples) * torch.log(sigma)\n",
    "            - 1 / (2 * sigma**2) * (self.samples**2).sum()\n",
    "        )\n",
    "\n",
    "    def sample_parameter(self):\n",
    "        return get_aprioiri_positive_parameter()\n",
    "\n",
    "    def calculate_analytical_parameter_mle(self):\n",
    "        return (self.samples**2).mean() ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2188,
   "id": "50102e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2187;\n",
       "                var nbb_unformatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_formatted_code = \"for _ in range(10):\\n    parameter = get_aprioiri_positive_parameter()\\n    log_density = NormalLogDensity(\\n        samples=torch.distributions.Normal(0, parameter).sample((100,))\\n    )\\n    log_density.check(true_parameter=parameter, rtol=1e-10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    parameter = get_aprioiri_positive_parameter()\n",
    "    log_density = NormalLogDensity(\n",
    "        samples=torch.distributions.Normal(0, parameter).sample((100,))\n",
    "    )\n",
    "    log_density.check(true_parameter=parameter, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2191,
   "id": "cb6b2a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2190;\n",
       "                var nbb_unformatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0 ** 2\\n1+1\";\n",
       "                var nbb_formatted_code = \"def likelihood_ratio_test(samples, sigma_0):\\n    x = (samples**2).mean() / sigma_0**2\\n\\n\\n1 + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def likelihood_ratio_test(samples, sigma_0):\n",
    "    x = (samples**2).mean() / sigma_0**2\n",
    "    return len(samples) * (x - torch.log(x) - 1)\n",
    "\n",
    "\n",
    "def wald_test(samples, sigma_0):\n",
    "    z = sigma_0 / (samples**2).mean() ** 0.5\n",
    "    return 2 * len(samples) * (1 - z) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2262,
   "id": "53725bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2261;\n",
       "                var nbb_unformatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n    \\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_formatted_code = \"def plot_chi2(begin=0.05, end=5):\\n    linspace = torch.linspace(begin, end, 1000)\\n    plt.plot(\\n        linspace.numpy(),\\n        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\\n        label=\\\"chi2\\\",\\n    )\\n\\n\\nparameter = get_aprioiri_positive_parameter()\\nn_samples_range = [10, 100, 1000, 1000]\\n\\n\\nfig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\\n\\nfor axis, n_samples in zip(fig.axes, n_samples_range):\\n    plt.sca(axis)\\n    axis.set(xlim=[0, 5])\\n    plt.title(\\n        f\\\"Likelihood and Wald test distributions\\\\n\\\"\\n        f\\\"when null hypothesis is true, {n_samples} samples.\\\"\\n    )\\n    likelihood_ratio_tests = []\\n    wald_tests = []\\n    for _ in range(1000):\\n        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\\n        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\\n        wald_tests.append(wald_test(samples, parameter))\\n\\n    plt.hist(\\n        likelihood_ratio_tests,\\n        density=True,\\n        label=\\\"likelihood\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plt.hist(\\n        wald_tests,\\n        density=True,\\n        label=\\\"wald\\\",\\n        histtype=\\\"step\\\",\\n        bins=50,\\n    )\\n    plot_chi2()\\n    plt.legend()\\n\\nplt.tight_layout()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_chi2(begin=0.05, end=5):\n",
    "    linspace = torch.linspace(begin, end, 1000)\n",
    "    plt.plot(\n",
    "        linspace.numpy(),\n",
    "        torch.exp(torch.distributions.Chi2(1).log_prob(linspace)).numpy(),\n",
    "        label=\"chi2\",\n",
    "    )\n",
    "\n",
    "\n",
    "parameter = get_aprioiri_positive_parameter()\n",
    "n_samples_range = [5, 10, 20, 100]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2, len(n_samples_range) // 2, figsize=(8, 6))\n",
    "\n",
    "for axis, n_samples in zip(fig.axes, n_samples_range):\n",
    "    plt.sca(axis)\n",
    "    axis.set(xlim=[0, 5])\n",
    "    plt.title(\n",
    "        f\"Likelihood and Wald test distributions\\n\"\n",
    "        f\"when null hypothesis is true, {n_samples} samples.\"\n",
    "    )\n",
    "    likelihood_ratio_tests = []\n",
    "    wald_tests = []\n",
    "    for _ in range(1000):\n",
    "        samples = torch.distributions.Normal(0, parameter).sample((n_samples,))\n",
    "        likelihood_ratio_tests.append(likelihood_ratio_test(samples, parameter))\n",
    "        wald_tests.append(wald_test(samples, parameter))\n",
    "\n",
    "    plt.hist(\n",
    "        likelihood_ratio_tests,\n",
    "        density=True,\n",
    "        label=\"likelihood\",\n",
    "        histtype=\"step\",\n",
    "        bins=50,\n",
    "    )\n",
    "    plt.hist(\n",
    "        wald_tests,\n",
    "        density=True,\n",
    "        label=\"wald\",\n",
    "        histtype=\"step\",\n",
    "        bins=50,\n",
    "    )\n",
    "    plot_chi2()\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1fef2f",
   "metadata": {},
   "source": [
    "### Задача 7\n",
    "Пусть $\\boldX = \\{X_1,\\dots,X_n\\}$ --- выборка н.о.р. с.в. со следующей функцией плотности:\n",
    "$$\n",
    "f(x, \\theta) = \\begin{cases}\n",
    "\tc(\\theta)d(x), &a \\leqslant x \\leqslant b(\\theta) \\\\\n",
    "\t0, &\\text{ иначе }\n",
    "\\end{cases}\n",
    "$$\n",
    "где $b(\\theta)$ --- монотонно возрастающая функция одного аргумента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928c042d",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. Построить статистику отношения правдоподобий $\\lambda$ для тестирования гипотезы $H_0: \\theta = \\theta_0$ vs $H_1: \\theta \\neq \\theta_0$\n",
    "\n",
    "${\\displaystyle\n",
    "}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb33e51",
   "metadata": {},
   "source": [
    "$\\displaystyle{\n",
    "l(\\theta) = \n",
    "\\ln\\prod_{i=1}^n f_\\theta(X_i) =\n",
    "\\sum_{i=1}^n \\ln\\mathbb{1}[a\\leq X_i \\leq b(\\theta)]c(\\theta)d(X_i) =\n",
    "-\\infty\\sum_{i=1}^n\\mathbb{1}[a\\leq X_i \\leq b(\\theta)] + n\\ln c(\\theta) + \\sum_{i=1}^n\\ln d(X_i)\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "\\theta^\\text{mle} = \n",
    "\\argmax_{\\theta} l(\\theta)=\n",
    "\\argmax_{\\theta} \\left(\n",
    "-\\infty\\sum_{i=1}^n\\mathbb{1}[a\\leq X_i \\leq b(\\theta)] + n\\ln c(\\theta) + \\sum_{i=1}^n\\ln d(X_i)\n",
    "\\right)=\n",
    "\\argmax_{\\theta: X_{(n)} \\leq b(\\theta)} \\left(n\\ln c(\\theta)\n",
    "\\right)=\\\\=\n",
    "\\argmax_{\\theta: \\theta \\geq b^{-1}(X_{(n)})} c(\\theta)\n",
    "}$\n",
    "\n",
    "Учитывая то, что $f$ есть функция плотности:\n",
    "\n",
    "$\\displaystyle{\n",
    "\\int_a^{b(\\theta)} c(\\theta)d(x)dx = 1\\\\\n",
    "c(\\theta) = \\frac{1}{\\int_a^{b(\\theta)}d(x)dx}\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "c'(\\theta) = \n",
    "-\\frac{(\\int_a^{b(\\theta)}d(x)dx)_{\\theta}'}{(\\int_a^{b(\\theta)}d(x)dx)^2} =\n",
    "-c(\\theta)^2\\left(F_d(b(\\theta)) - F_d(a)\\right)'_{\\theta} =\n",
    "-c(\\theta)^2F_d'(b(\\theta))b'(\\theta) =\n",
    "-c(\\theta)^2d(b(\\theta))b'(\\theta)\n",
    "}$\n",
    "\n",
    "Поскольку $c(\\theta) >0$ при $b(\\theta) \\geq X_{(n)}$ и $b$ есть монотонная функция,\n",
    "\n",
    "$\\displaystyle{\n",
    "c'(\\theta) = 0 \\Rightarrow d(b(\\theta)) = 0\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "\\theta^\\text{mle} = \n",
    "\\argmax_{\\theta \\in \\Theta} c(\\theta),\n",
    "\\Theta = \\{\\theta | \n",
    "\\theta = b^{-1}(X_{(n)}) \\text{ или } \n",
    "\\theta = \\infty \\text{ или }\n",
    "d(b(\\theta)) = 0 \\text{ и } \\theta > b^{-1}(X_{(n)}) \\}\n",
    "}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914a1214",
   "metadata": {},
   "source": [
    "Критерий отношения правдоподобий:\n",
    "\n",
    "$\\displaystyle{\n",
    "\\lambda = \n",
    "2\\left(l(\\theta^\\text{mle}) - l(\\theta_0)\\right) =\n",
    "2n\\left(\\ln c(\\theta^\\text{mle}) - \\ln c(\\theta_0)\\right), \\text{ при } \\theta_0 \\geq b^{-1}(X_{(n)}), \\text{ и }\\infty \\text{ иначе.}\n",
    "}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2896419",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. Найти распределение статистики $\\lambda$ при выполнении $H_0$ для следующей функции плотности:\n",
    "$$\n",
    "f(x, \\theta) = \\begin{cases}\n",
    "    \\frac{2x}{\\theta^2}, \\quad &0 \\leqslant x \\leqslant \\theta \\\\\n",
    "    0, \\quad &\\text{иначе}\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a73b01",
   "metadata": {},
   "source": [
    "${\\displaystyle\n",
    "a=0\\\\\n",
    "b(\\theta) = \\theta\\\\\n",
    "c(\\theta) = \\frac{2}{\\theta^2}\\\\\n",
    "d(x) = x\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "\\theta^\\text{mle} = b^{-1}(X_{(n)}) = X_{(n)}\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "\\lambda = \n",
    "2\\left(l(X_{(n)}) - l(\\theta_0)\\right) =\n",
    "2n\\left(\\ln c(X_{(n)}) - \\ln c(\\theta_0)\\right) =\n",
    "2n\\left(\\ln 2 -2\\ln X_{(n)} - \\ln2 + 2\\ln \\theta_0\\right) =\n",
    "4n\\left(\\ln \\theta_0 - \\ln X_{(n)}\\right) \n",
    ", \\text{ при } \\theta_0 \\geq X_{(n)}, \\text{ и }\\infty \\text{ иначе.}\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "P(\\lambda < x) =\n",
    "P(4n\\left(\\ln \\theta_0 - \\ln X_{(n)}\\right) < x) =\n",
    "P(-\\ln X_{(n)} < \\frac{x}{4n} - \\ln \\theta_0) =\n",
    "P(\\ln X_{(n)} > \\ln \\theta_0 - \\frac{x}{4n}) =\\\\=\n",
    "P(X_{(n)} > \\theta_0 e^{-\\frac{x}{4n}}) =\n",
    "1 - P(X_{(n)} < \\theta_0 e^{-\\frac{x}{4n}}) =\n",
    "1 - \\prod_i P(X_i < \\theta_0 e^{-\\frac{x}{4n}}) =\n",
    "1 - \\prod_i  \\int_0^{\\theta_0 e^{-\\frac{x}{4n}}} \\frac{2y}{\\theta_0^2}dy =\\\\=\n",
    "1 -  \\prod_i \\frac{1}{\\theta_0^{2}} y^2\\Big|_0^{\\theta_0 e^{-\\frac{x}{4n}}} =\n",
    "1 -  \\prod_i \\frac{1}{\\theta_0^{2}} (\\theta_0 e^{-\\frac{x}{4n}})^2 =\n",
    "1 -  e^{-\\frac{2nx}{4n}} =\n",
    "1 -  e^{-\\frac{x}{2}}\n",
    "}$\n",
    "\n",
    "То есть $\\lambda$ распределена по хи-квадрат распределению с двумя степенями свободы. Но по теореме Вилкеса, статистика должна была бы быть асимптотически распределена со степенью свободы, равной одному - разнице в размерности полного пространства параметров и ограниченного подпространства. Видимо, здесь не выполняются некоторые условия теоремы, но в данном случае было бы простительно пользоваться и теоретически неверным ассимптотическим распределением, поскольку оно близко к рельному.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bcb196",
   "metadata": {},
   "source": [
    "### Задача 8\n",
    "Найдите наилучшую критическую область (НКО) для проверки гипотезы $H_0 \\colon \\Uniform[-a, a]$ против гипотезы $H_1 \\colon \\Normal(0, \\sigma^2)$ по одному\n",
    "наблюдению $(n = 1)$ при уровне значимости $\\alpha = 0.1$. Найдите мощность полученного критерия."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d87d3",
   "metadata": {},
   "source": [
    "---\n",
    "Наилучшая критическая область при уровень значимости $\\alpha$ - такая критическая область, которая максимизирует вероятность корректно отклонить гипотезу при вероятности некорректно отклонить гипотезу равной $\\alpha$:\n",
    "\n",
    "$\\displaystyle{\n",
    "\\hat{\\mathcal{R}} =\n",
    "\\argmax_{\\mathcal{R}: P(\\theta \\in \\mathcal{R}| H_0) = \\alpha} P(\\theta \\in \\mathcal{R}| H_1)\n",
    "}$\n",
    "\n",
    "Примем за критерий само наблюдение: $\\theta = X$.\n",
    "\n",
    "$\\displaystyle{\n",
    "P(X \\in \\mathcal{R}| H_0) =\n",
    "\\int_\\mathcal{R} \\frac{1}{2a}\\mathbb{1}[x \\in [-a, a]] dx =\n",
    "\\frac{1}{2a} |\\mathcal{R} \\cap [-a, a]| = \\alpha\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "P(X \\in \\mathcal{R}| H_1) =\n",
    "\\int_\\mathcal{R} {\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}e^{-{\\frac {1}{2}}\\left({\\frac {x}{\\sigma }}\\right)^{2}} dx =\n",
    "{\\frac {1}{\\sigma {\\sqrt {2\\pi }}}} \\int \\mathbb{1}[x \\in \\mathcal{R}]e^{-{\\frac {1}{2}}\\left({\\frac {x}{\\sigma }}\\right)^{2}} dx =\\\\=\n",
    "{\\frac {1}{\\sigma {\\sqrt {2\\pi }}}} \\int \\mathbb{1}[x \\in \\mathcal{R}]e^{-{\\frac {1}{2}}\\left({\\frac {x}{\\sigma }}\\right)^{2}} d(\\frac {x}{\\sigma }) \\sigma = \n",
    "{\\frac {1}{ {\\sqrt {2\\pi }}}} \\int \\mathbb{1}[\\sigma y \\in \\mathcal{R}]e^{-{\\frac {y^2}{2}}} dy\n",
    "}$\n",
    "\n",
    "Нетрудно увидеть, что наилучшая критическая область будет иметь вид \n",
    "$\\hat{\\mathcal{R}} = (-\\infty, -a)\\cup [-\\alpha, \\alpha] \\cup (a, \\infty)$.\n",
    "\n",
    "*Мощность критерия* - вероятность корректно отвергнуть нулевую гипотезу:\n",
    "\n",
    "$\\displaystyle{\n",
    "P(X \\in \\hat{\\mathcal{R}}| H_1) =\n",
    "\\beta_{\\hat{\\mathcal{R}}}(X|H_1) = \n",
    "{\\frac {1}{ {\\sqrt {2\\pi }}}} \n",
    "\\int \\mathbb{1}[\\sigma y \\in (-\\infty, -a)\\cup [-\\alpha, \\alpha] \\cup (a, \\infty)]e^{-{\\frac {y^2}{2}}} dy =\\\\=\n",
    "{\\frac {1}{ {\\sqrt {2\\pi }}}} \n",
    "\\int \\mathbb{1}[y \\in (-\\infty, -a/\\sigma)\\cup [-\\alpha/\\sigma, \\alpha/\\sigma] \\cup (a/\\sigma, \\infty)]e^{-{\\frac {y^2}{2}}} dy = \\\\=\n",
    "2\\left(\\Phi(-a/\\sigma) + (\\Phi(0) - \\Phi(-\\alpha/\\sigma)) \\right) =\n",
    "1 - 2\\left(\\Phi(-\\alpha/\\sigma) - \\Phi(-a/\\sigma) \\right)\n",
    "}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ec22d3",
   "metadata": {},
   "source": [
    "### Задача 9\n",
    "Проверяются гипотезы о плотности $f$ распределения наблюдений $\\boldX = \\{X_1,\\dots,X_n\\}$: гипотеза $H_0\\colon f = f_0$ против альтернативы $H_1\\colon f = f_1$, где\n",
    "\\begin{gather*}\n",
    "\tf_0(x) = \n",
    "\t\\begin{cases}\n",
    "\t\t1, &x \\in [0,1],\\\\\n",
    "\t\t0, &x \\notin [0, 1],\n",
    "\t\\end{cases}\n",
    "\t\\qquad\n",
    "\tf_1(x)=\n",
    "\t\\begin{cases}\n",
    "\t\t2x, &x \\in [0, 1], \\\\\n",
    "\t\t0, &x \\notin [0, 1].\n",
    "\t\\end{cases}\n",
    "\\end{gather*}\n",
    "Построить наиболее мощный критерий размера $\\alpha$ при $n = 1$ и $n = 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c38d3a",
   "metadata": {},
   "source": [
    "---\n",
    "1. $n=1$, критерий равен наблюдению.\n",
    "\n",
    "$\\displaystyle{\n",
    "\\alpha = \n",
    "\\sup_{H_0} P(X_1 \\in \\mathcal{R}) =\n",
    "\\int_0^1 \\mathbb{1}[x \\in  \\mathcal{R}] dx =\n",
    "|\\mathcal{R} \\cap[0,1]|\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "\\hat{\\mathcal{R}} =\n",
    "\\argmax_{\\mathcal{R}: |\\mathcal{R} \\cap[0,1]| = \\alpha} P(X_1 \\in \\mathcal{R}| H_1) =\n",
    "\\argmax_{\\mathcal{R}: |\\mathcal{R} \\cap[0,1]| = \\alpha} \\int_0^1 \\mathbb{1}[x \\in  \\mathcal{R}]2xdx =\n",
    "[1 - \\alpha, 1]\n",
    "}$\n",
    "\n",
    "2. $n=2$, критерий в общем виде - это бинарная функция $g: \\mathbb{R}^2 \\rightarrow \\{0, 1\\}$, 1 означает отклонение гипотезы.\n",
    "\n",
    "$\\displaystyle{\n",
    "\\alpha = \n",
    "\\sup_{H_0} P(g(X_1, X_2) == 1) =\n",
    "\\int_0^1\\int_0^1 g(x_1, x_2) dx_1dx_2 =\n",
    "|g^{-1}(1) \\cap \\{[0,1] \\times [0,1]\\}|\n",
    "}$\n",
    "\n",
    "Без ограничения общности будем считать, что $g(x_1,x_2) = 0, (x_1,x_2) \\notin \\{[0,1] \\times [0,1]\\}$,\n",
    "тогда $\\alpha = |g^{-1}(1)|$.\n",
    "\n",
    "$\\displaystyle{\n",
    "\\hat{g} =\n",
    "\\argmax_{g: \\alpha} P(g(x_1, x_2) == 1| H_1) =\n",
    "\\argmax_{g: \\alpha} \\int_0^1\\int_0^1 g(x_1, x_2) 2x_1 dx_1 2x_2 dx_2 =\\\\=\n",
    "\\argmax_{g} \\int_{g^{-1}(1)} 2x_1 dx_1 2x_2 dx_2 =\n",
    "\\argmax_{g} \\int_{g^{-1}(1)} h(x_1,x_2)dx_1dx_2\n",
    "}$\n",
    "\n",
    "Где $h(x_1, x_2) = 4x_1x_2$. Получается, что нам нужно максимизировать объем под графиком функции $h$ на области фиксированной площади и внутри единичного квадрата. Из гладкости и монотонности $h$ и соображений оптимальности, это должна быть связная область как можно дальше от нуля, и на границе области приращения объема должны быть равны:\n",
    "\n",
    "$\\displaystyle{\n",
    "4x_1x_2 = 4x_1'x_2'\n",
    "}$\n",
    "\n",
    "Значит, граница задается уравнением $x_1x_2 = c$. Получаем:\n",
    "\n",
    "$\\displaystyle{\n",
    "\\alpha = \n",
    "\\int_0^1\\int_0^1 g(x_1, x_2) dx_1dx_2 =\n",
    "\\int_0^1\\int_0^1 \\mathbb{1}[x_1x_2 \\geq c] dx_1dx_2 =\n",
    "\\int_0^1\\int_0^1 \\mathbb{1}[x_1 \\geq c/x_2] dx_1dx_2 =\\\\=\n",
    "\\int_0^1\\int_{c/x_2}^1\\mathbb{1}[1 \\geq c/x_2] dx_1dx_2 =\n",
    "\\int_0^1(1 - c/x_2)\\mathbb{1}[1 \\geq c/x_2]dx_2 =\n",
    "\\int_c^1(1 - c/x_2)dx_2 =\n",
    "(x_2 - c\\ln x_2)|_c^1 =\n",
    "1 - (c - c\\ln c)\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "c(1 - \\ln c) = 1 - \\alpha\n",
    "}$\n",
    "\n",
    "Получаем критерий $g(x_1,x_2) = \\mathbb{1}[x_1x_2 \\geq c \\land (x_1,x_2) \\in \\{[0,1] \\times [0,1]\\}]$, где $c(1 - \\ln c) = 1 - \\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7d18c",
   "metadata": {},
   "source": [
    "### Задача 10\n",
    "В процессе настольной игры у игроков возникло подозрение, что два кубика, которые шли в комплекте с игрой, несимметричны. Поэтому, начиная с некоторого момента, они начали записывать результаты бросков. В каждом броске участвуют оба кубика. Результаты приведены в таблице.\n",
    "\n",
    "|Сумма очков | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |\n",
    "| - | - | - | - | - | - | - | - | - | - | - | - |\n",
    "|Количество бросков | 2 | 4 | 20 | 18 | 34 | 41 | 32 | 26 | 16 | 9 | 12|\n",
    "\n",
    "Проверьте гипотезу о том, что оба кубика симметричны на уровне значимости $\\alpha = 0.05$. Найдите p-value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be7a7d9",
   "metadata": {},
   "source": [
    "---\n",
    "Есть выборка $\\boldX = \\{X_2 \\dots X_{12}\\}$, где $X_i =\\sum_j^{\\sum X_k} \\mathbb{1}[Y^j_1 + Y^j_2 == i]$; $Y_1^j\\sim Y^1$ и $Y_2^j\\sim Y^2$ независимы и имеют образ $\\{1,2,3,4,5,6\\}$. Нужно проверить гипотезу $H_0$, что $Y^1,Y^2 \\sim {\\mathcal  {U}}\\{1, 6\\}$. Случайная величина $X$ при нулевой гипотезе распределена по мультиномиальному закону c $\\sum X_k$ экспериментами, $11$ исходами и вероятностями исходов $\\displaystyle{P(x) = \\frac{\\min(x -1, 13 - x)}{36}}, x = 2\\dots 12$. Для определения соответствия наблюдаемой выборки мультиномиальному распределению подойдет статистика Пирсона:\n",
    "\n",
    "\n",
    "$\\displaystyle{\n",
    "\\chi ^{2} =\\sum_{k=2}^{11}\\frac{(O_k-E_k)^2}{E_k}\n",
    "}$\n",
    "\n",
    "Где $E_k$ - матожидание количества реализаций $k$-ого класса в выборке данного размера, $O_k$ - количество реализаций $k$-ого класса в выборке.\n",
    "\n",
    "$\\displaystyle{\n",
    "E_k = n\\frac{\\min(k - 1, 13 - k)}{36}\n",
    "}$\n",
    "\n",
    "Значение статистики Пирсона следует сравнить с квантилем $\\chi ^{2}_{K-1,\\alpha}$, где $K$ = 11 - количество классов, $\\alpha - $ уровень значимости, а $p-value$ будет равно 1 - функция распределения в значении статистики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2419,
   "id": "41d3386c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2418;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class PearsonTest:\n",
    "    def __init__(self, class_means, class_observations, n_parameters=0):\n",
    "        assert len(class_means) == len(class_observations)\n",
    "        self.class_means = np.array(class_means)\n",
    "        self.class_observations = np.array(class_observations)\n",
    "        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\n",
    "\n",
    "    def statistic(self):\n",
    "        return (\n",
    "            (self.class_observations - self.class_means) ** 2 / self.class_means\n",
    "        ).sum()\n",
    "\n",
    "    def should_reject(self, confidence_level):\n",
    "        return self.statistic() > self.chi2.ppf(confidence_level)\n",
    "\n",
    "    def p_value(self):\n",
    "        return 1 - self.chi2.cdf(self.statistic())\n",
    "\n",
    "\n",
    "def class_probability(class_id):\n",
    "    k = class_id + 2\n",
    "    return min(k - 1, 13 - k) / 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2420,
   "id": "71078023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2419;\n",
       "                var nbb_unformatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_formatted_code = \"class PearsonTest:\\n    def __init__(self, class_means, class_observations, n_parameters=0):\\n        assert len(class_means) == len(class_observations)\\n        self.class_means = np.array(class_means)\\n        self.class_observations = np.array(class_observations)\\n        self.chi2 = stats.chi2(df=len(class_means) - n_parameters - 1)\\n\\n    def statistic(self):\\n        return (\\n            (self.class_observations - self.class_means) ** 2 / self.class_means\\n        ).sum()\\n\\n    def should_reject(self, confidence_level):\\n        return self.statistic() > self.chi2.ppf(confidence_level)\\n\\n    def p_value(self):\\n        return 1 - self.chi2.cdf(self.statistic())\\n\\n\\ndef class_probability(class_id):\\n    k = class_id + 2\\n    return min(k - 1, 13 - k) / 36\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\n",
    "n_observations = sum(class_observations)\n",
    "class_means = [\n",
    "    class_probability(i) * n_observations for i in range(len(class_observations))\n",
    "]\n",
    "pearson_test = PearsonTest(class_means, class_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2421,
   "id": "3afc1d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject null hypothesis.\n",
      "P-value 0.049.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2420;\n",
       "                var nbb_unformatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_formatted_code = \"class_observations = [2, 4, 20, 18, 34, 41, 32, 26, 16, 9, 12]\\nn_observations = sum(class_observations)\\nclass_means = [\\n    class_probability(i) * n_observations for i in range(len(class_observations))\\n]\\npearson_test = PearsonTest(class_means, class_observations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\n",
    "    (\"Reject\" if pearson_test.should_reject(confidence_level=0.05) else \"Don't reject\")\n",
    "    + \" null hypothesis.\"\n",
    ")\n",
    "print(f\"P-value {pearson_test.p_value():.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae418f",
   "metadata": {},
   "source": [
    "### Задача 11\n",
    "Предположим, что у нас есть 10 статей, написанных автором, скрывающемся под псевдонимом. Мы подозреваем, что эти статьи на самом деле написаны некоторым известным писателем. Чтобы проверить эту гипотезу, мы подсчитали доли четырехбуквенных слов в 8-и сочинениях подозреваемого нами автора:\n",
    "$$\n",
    ".224~ .261~ .216~ .239~ .229~ .228~ .234~ .216~\n",
    "$$\n",
    "В 10 сочинениях, опубликованных под псевдонимом, доли четырехбуквенных слов равны\n",
    "$$\n",
    ".207~ .204~ .195~ .209~ .201~ .206~ .223~ .222~ .219~ .200\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f730aac9",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. Используйте критерий Вальда. Найдите $\\pvalue$ и 95\\%-ый доверительный интервал для разницы средних значений. Какой вывод можно сделать исходя из найденных значений?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675cf365",
   "metadata": {},
   "source": [
    "Гипотеза $H_0$ состоит в том, что вероятность четырехбуквенных слов во второй группе сочинений такая же, как в первой: $\\theta = \\theta_0 = \\mean{\\boldX_0}$, тогда как без ограничений мы бы оценили ее как $\\theta^\\text{mle} = \\mean{\\boldX_1}$\n",
    "\n",
    "$\\displaystyle{\n",
    "\\hat{\\operatorname{var}} (\\theta^\\text{mle}) = \n",
    "\\hat{\\operatorname{var}} (\\mean{\\boldX_1}) = \n",
    "\\frac{\\hat{\\operatorname{var}} (X_1)}{n_1} =\n",
    "\\frac{\\sum_i (X_i^1 - \\mean{\\boldX_1})^2}{n_1(n_1-1)}\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "W^2 = \n",
    "\\frac{(\\theta^\\text{mle}-\\theta_0)^2}{\\hat{\\operatorname{var}} (\\theta^\\text{mle})} =\n",
    "\\frac{n_1(n_1-1)(\\mean{\\boldX_1}-\\mean{\\boldX_0})^2}{\\sum_i (X_i^1 - \\mean{\\boldX_1})^2}\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "\\hat{\\operatorname{var}} (\\mean{\\boldX_1}-\\mean{\\boldX_0}) = \n",
    "\\frac{\\sum_i (X_i^1 - \\mean{\\boldX_1})^2}{n_1(n_1-1)} + \n",
    "\\frac{\\sum_i (X_i^0 - \\mean{\\boldX_0})^2}{n_0(n_0-1)}\n",
    "}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2422,
   "id": "5bf3cad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value 3.318456620604593e-13.\n",
      "95% confidence interval[-0.03401445212112404, -0.01053554787887588].\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2421;\n",
       "                var nbb_unformatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"print(\\n    (\\\"Reject\\\" if pearson_test.should_reject(confidence_level=0.05) else \\\"Don't reject\\\")\\n    + \\\" null hypothesis.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\n",
    "group_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\n",
    "mean_0 = group_0.mean()\n",
    "mean_1 = group_1.mean()\n",
    "n_0 = len(group_0)\n",
    "n_1 = len(group_1)\n",
    "mean_var_0 = group_0.var(ddof=1) / n_0\n",
    "mean_var_1 = group_1.var(ddof=1) / n_1\n",
    "\n",
    "\n",
    "wald = (mean_1 - mean_0) ** 2 / mean_var_1\n",
    "p_value = 1 - stats.chi2(1).cdf(wald)\n",
    "\n",
    "interval = get_asymptoticaly_normal_confidence_interval(\n",
    "    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\n",
    ")\n",
    "\n",
    "print(f\"P-value {p_value}.\\n95% confidence interval{interval}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac7ad9",
   "metadata": {},
   "source": [
    "Низкое значение P-value и полностью негативный интервал позволяют отвергнуть нулевую гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa53c81",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. Используйте критерий перестановок. Каково в этом случае значение $\\pvalue$. Какой вывод можно сделать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2423,
   "id": "09adb39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2422;\n",
       "                var nbb_unformatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_formatted_code = \"group_0 = np.array([0.224, 0.261, 0.216, 0.239, 0.229, 0.228, 0.234, 0.216])\\ngroup_1 = np.array([0.207, 0.204, 0.195, 0.209, 0.201, 0.206, 0.223, 0.222, 0.219, 0.2])\\nmean_0 = group_0.mean()\\nmean_1 = group_1.mean()\\nn_0 = len(group_0)\\nn_1 = len(group_1)\\nmean_var_0 = group_0.var(ddof=1) / n_0\\nmean_var_1 = group_1.var(ddof=1) / n_1\\n\\n\\nwald = (mean_1 - mean_0) ** 2 / mean_var_1\\np_value = 1 - stats.chi2(1).cdf(wald)\\n\\ninterval = get_asymptoticaly_normal_confidence_interval(\\n    mean_1 - mean_0, (mean_var_0 + mean_var_1) ** 0.5\\n)\\n\\nprint(f\\\"P-value {p_value}.\\\\n95% confidence interval{interval}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class PermutationStatistic:\n",
    "    def __init__(self, class_1_size, class_2_size):\n",
    "        self.class_1_size = class_1_size\n",
    "        self.class_2_size = class_2_size\n",
    "\n",
    "    def __call__(self, permutation):\n",
    "        return abs(\n",
    "            permutation[: self.class_1_size].mean()\n",
    "            - permutation[self.class_1_size :].mean()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2424,
   "id": "ba0e7103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation statistic p-value 0.00077.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2423;\n",
       "                var nbb_unformatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n        \\n    def __call__(self, permutation):\\n        return abs(permutation[:self.class_1_size].mean() - permutation[self.class_1_size:].mean())\";\n",
       "                var nbb_formatted_code = \"class PermutationStatistic:\\n    def __init__(self, class_1_size, class_2_size):\\n        self.class_1_size = class_1_size\\n        self.class_2_size = class_2_size\\n\\n    def __call__(self, permutation):\\n        return abs(\\n            permutation[: self.class_1_size].mean()\\n            - permutation[self.class_1_size :].mean()\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groups = np.concatenate([group_0, group_1])\n",
    "statistic = PermutationStatistic(n_0, n_1)\n",
    "observed_statistic = statistic(groups)\n",
    "n_permutations = 100_000\n",
    "n_permutations_with_greater_statistic = 0\n",
    "\n",
    "for _ in range(n_permutations):\n",
    "    if statistic(np.random.permutation(groups)) > observed_statistic:\n",
    "        n_permutations_with_greater_statistic += 1\n",
    "\n",
    "p_value = n_permutations_with_greater_statistic / n_permutations\n",
    "print(f\"Permutation statistic p-value {p_value}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96fb14",
   "metadata": {},
   "source": [
    "Опять же отвергаем гипотезу в силу малого p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799531b2",
   "metadata": {},
   "source": [
    "### Задача 12\n",
    "Маршрут грузового состава начинается в пункте $A$ и последовательно проходит через пункты $B_0$, $B_1$ и т.д. По прибытии в очередной пункт те составы, которые направлялись в этот пункт, отцепляются. Очередной состав из 500 грузовых вагонов отправился из пункта $A$ вдоль пунктов $B_0$, $B_1$, $\\dots$ В таблице приведено количество отцепленных составов в каждом из пунктов (последним пунктом в данном случае оказался пункт $B_9$).\n",
    "\n",
    "|Пункт | 0| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |\n",
    "| - | - | - | - | - | - | - | - | - | - | - |\n",
    "|Количество составов | 15 | 55 | 126 | 110 | 113 | 49 | 20 | 9 | 2 | 1 |\n",
    "\n",
    "Возникло предположение, что распределение грузовых составов по пунктам назначения можно описать некоторым дискретным распределением, где $P(X = B_i)$ --- вероятность того, что состав направляется в пункт $B_i$. В рамках данного предположения требуется провести проверку следующих гипотез на уровне значимости $\\alpha = 0.05$ и найти p-value:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fff6f1",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. $\\boldX \\sim \\Poisson(\\theta)$, т.е. $P(X = B_j) = e^{-\\theta} \\frac{\\theta^j}{j!}$, где $j \\ge 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6bb06",
   "metadata": {},
   "source": [
    "$\\displaystyle{\n",
    "\\theta^{\\text{mle}} =\n",
    "\\argmax_\\theta \\prod_i P_\\theta(X_i) =\n",
    "\\argmax_\\theta \\prod_k \\prod_{i, B(X_i) =k} e^{-\\theta} \\frac{\\theta^{k}}{k!} =\n",
    "\\argmax_\\theta \\sum_k B_k (-\\theta + k \\ln\\theta - \\ln k!) =\n",
    "\\argmax_\\theta \\sum_k B_k (-\\theta + k \\ln\\theta)\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "0 = -\\sum_k B_k + \\frac{\\sum_k k B_k}{\\theta^{\\text{mle}}}\\\\\n",
    "\\theta^{\\text{mle}} = \\frac{\\sum_k k B_k}{\\sum_k B_k}\n",
    "}$\n",
    "\n",
    "Воспользуемся статистикой Пирсона:\n",
    "\n",
    "$\\displaystyle{\n",
    "\\chi ^{2} =\\sum_{k=0}^{9}\\frac{(O_k-E_k)^2}{E_k}\\\\\n",
    "E_k =\n",
    "e^{-\\theta^{\\text{mle}}} \\frac{(\\theta^{\\text{mle}})^{k}}{k!}n\n",
    "}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2427,
   "id": "2fd24ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject null hypothesis at confidence level 0.05.\n",
      "P-value 0.005.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2426;\n",
       "                var nbb_unformatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_formatted_code = \"observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\\ntheta = (np.arange(len(observations)) * observations).sum() / observations.sum()\\npoisson = stats.poisson(theta)\\nclass_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\\npearson_test = PearsonTest(class_means, observations, n_parameters=2)\\nconfidence_level = 0.05\\n\\nprint(\\n    (\\n        \\\"Reject\\\"\\n        if pearson_test.should_reject(confidence_level=confidence_level)\\n        else \\\"Don't reject\\\"\\n    )\\n    + f\\\" null hypothesis at confidence level {confidence_level}.\\\"\\n)\\nprint(f\\\"P-value {pearson_test.p_value():.3f}.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "observations = np.array([15, 55, 126, 110, 113, 49, 20, 9, 2, 1])\n",
    "theta = (np.arange(len(observations)) * observations).sum() / observations.sum()\n",
    "poisson = stats.poisson(theta)\n",
    "class_means = [poisson.pmf(i) * observations.sum() for i in range(len(observations))]\n",
    "pearson_test = PearsonTest(class_means, observations, n_parameters=1)\n",
    "confidence_level = 0.05\n",
    "\n",
    "print(\n",
    "    (\n",
    "        \"Reject\"\n",
    "        if pearson_test.should_reject(confidence_level=confidence_level)\n",
    "        else \"Don't reject\"\n",
    "    )\n",
    "    + f\" null hypothesis at confidence level {confidence_level}.\"\n",
    ")\n",
    "print(f\"P-value {pearson_test.p_value():.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7d0c7",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. $\\boldX \\sim \\Binomial(m, p)$, т.е. $P(X = B_j) = C^j_m p^j (1-p)^{m - j}$, где $j \\in \\{0, \\dots, 9\\}$ и $m = 9$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa45328",
   "metadata": {},
   "source": [
    "$\\displaystyle{\n",
    "p^{\\text{mle}} =\n",
    "\\argmax_p \\prod_i P_p(X_i) =\n",
    "\\argmax_p \\prod_k \\prod_{i, B(X_i) =k}  C^k_m p^k (1-p)^{m - k} =\\\\=\n",
    "\\argmax_p \\sum_k B_k (\\ln C^k_m + k \\ln p +(m-k) \\ln (1-p)) =\n",
    "\\argmax_p \\sum_k B_k (k \\ln p +(m-k) \\ln (1-p))\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "0 = \n",
    "\\sum_k B_k (\\frac{k}{p} -\\frac{m-k}{1-p}) =\n",
    "\\sum_k B_k \\frac{k(1-p) - (m-k)p}{p(1-p)} =\n",
    "\\sum_k B_k \\frac{k - mp}{p(1-p)}\\\\\n",
    "mp\\sum_k B_k =\\sum_k B_k k\\\\\n",
    "p^{\\text{mle}} =\\frac{\\sum_k B_k k}{m\\sum_k B_k}\n",
    "}$\n",
    "\n",
    "$\\displaystyle{\n",
    "E_k =\n",
    "C^k_m (p^{\\text{mle}})^k (1-p^{\\text{mle}})^{m - k} n\n",
    "}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2434,
   "id": "afe8a39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject null hypothesis at confidence level 0.05.\n",
      "P-value 0.0000001809.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2433;\n",
       "                var nbb_unformatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_formatted_code = \"pearson_test.statistic()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = theta / 9\n",
    "binom = stats.binom(9, p)\n",
    "binom_class_means = [\n",
    "    binom.pmf(i) * observations.sum() for i in range(len(observations))\n",
    "]\n",
    "pearson_test = PearsonTest(binom_class_means, observations, n_parameters=1)\n",
    "confidence_level = 0.05\n",
    "\n",
    "print(\n",
    "    (\n",
    "        \"Reject\"\n",
    "        if pearson_test.should_reject(confidence_level=confidence_level)\n",
    "        else \"Don't reject\"\n",
    "    )\n",
    "    + f\" null hypothesis at confidence level {confidence_level}.\"\n",
    ")\n",
    "print(f\"P-value {pearson_test.p_value():.10f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2418,
   "id": "be25d6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2417;\n",
       "                var nbb_unformatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend();\";\n",
       "                var nbb_formatted_code = \"plt.plot(observations, label=\\\"observations\\\")\\nplt.plot(class_means, label=\\\"poisson estimations\\\")\\nplt.plot(binom_class_means, label=\\\"binomial estimations\\\")\\nplt.title(\\\"Different distributions fit\\\")\\nplt.legend()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(observations, label=\"observations\")\n",
    "plt.plot(class_means, label=\"poisson estimations\")\n",
    "plt.plot(binom_class_means, label=\"binomial estimations\")\n",
    "plt.title(\"Different distributions fit\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8126f",
   "metadata": {},
   "source": [
    "Довольно странно видить такие низкие p-value, тогда как графики весьма похожи. Но это объясняется чувствительностью  теста Пирсона к редким классам - в знаменателе слагаемых критерия стоит оценка вероятности классов, и такие дроби нестабильны. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5059db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
